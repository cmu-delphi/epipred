[{"path":"https://cmu-delphi.github.io/epipredict/dev/DEVELOPMENT.html","id":"setting-up-the-development-environment","dir":"","previous_headings":"","what":"Setting up the development environment","title":"NA","text":"","code":"install.packages(c('devtools', 'pkgdown', 'styler', 'lintr')) # install dev dependencies devtools::install_deps(dependencies = TRUE) # install package dependencies devtools::document() # generate package meta data and man files devtools::build() # build package"},{"path":"https://cmu-delphi.github.io/epipredict/dev/DEVELOPMENT.html","id":"validating-the-package","dir":"","previous_headings":"","what":"Validating the package","title":"NA","text":"","code":"styler::style_pkg() # format code lintr::lint_package() # lint code  devtools::test() # test package devtools::check() # check package for errors"},{"path":"https://cmu-delphi.github.io/epipredict/dev/DEVELOPMENT.html","id":"developing-the-documentation-site","dir":"","previous_headings":"","what":"Developing the documentation site","title":"NA","text":"documentation site built main branch. dev version site available https://cmu-delphi.github.io/epipredict/dev. documentation site can previewed locally running R main version available file:///<local path>/epidatr/epipredict/index.html dev file:///<local path>/epipredict/docs/dev/index.html. can also build docs manually launch site python. terminal, looks like","code":"pkgdown::build_site(preview=TRUE) R -e 'pkgdown::clean_site()' R -e 'devtools::document()' R -e 'pkgdown::build_site()' python -m http.server -d docs"},{"path":"https://cmu-delphi.github.io/epipredict/dev/DEVELOPMENT.html","id":"versioning","dir":"","previous_headings":"","what":"Versioning","title":"NA","text":"Please follow guidelines PR template document.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/DEVELOPMENT.html","id":"release-process","dir":"","previous_headings":"","what":"Release process","title":"NA","text":"TBD","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2022 epipredict authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/arx-classifier.html","id":"load-required-packages","dir":"Articles","previous_headings":"","what":"Load required packages","title":"Auto-regressive classifier","text":"","code":"library(dplyr) library(purrr) library(ggplot2) library(epipredict)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/arx-classifier.html","id":"introducing-the-arx-classifier","dir":"Articles","previous_headings":"","what":"Introducing the ARX classifier","title":"Auto-regressive classifier","text":"arx_classifier() autoregressive classification model epi_df data used predict discrete class case consideration. direct forecaster estimates classes specific horizon ahead value. get sense arx_classifier() works, let’s consider simple example minimal inputs. , use built-case_death_rate_subset contains confirmed COVID-19 cases deaths JHU CSSE states Dec 31, 2020 Dec 31, 2021. , ’ll take subset data five states June 4, 2021 December 31, 2021. objective predict whether case rates increasing considering 0, 7 14 day case rates: key takeaway predictions two prediction classes: (-Inf, 0.25] (0.25, Inf). goal classification classes must discrete. discretization real-valued outcome controlled breaks argument, defaults 0.25. breaks automatically extended cover entire real line. example, default break 0.25 silently extended breaks = c(-Inf, .25, Inf) , therefore, results two classes: [-Inf, 0.25] (0.25, Inf). two classes used discretize outcome. conversion outcome classes handled internally. discrete classes already exist outcome epi_df, recommend code classifier scratch using epi_workflow framework control. trainer parsnip model describing type estimation mode = \"classification\" enforced. two typical trainers used parsnip::logistic_reg() two classes parsnip::multinom_reg() two classes. parsnip model specification, can see trainer used logistic regression, expected binary outcome. complicated trainers like parsnip::naive_Bayes() parsnip::rand_forest() may also used (however, stick basics gentle introduction classifier). use default trainer logistic regression binary classification decide using default break 0.25, input one break two classification bins properly dichotomize outcome. example, let’s set break 0.5 instead relying default 0.25. can passing 0.5 breaks argument arx_class_args_list() follows: Indeed, can observe two .pred_class now (-Inf, 0.5] (0.5, Inf). See help(arx_class_args_list) available modifications. Additional arguments may supplied arx_class_args_list() include expected lags ahead arguments autoregressive-type model. default values 0, 7, 14 days lags predictors 7 days ahead forecast date predicting outcome. also n_training indicate upper bound number training rows per key. like practice using , remove filtering command obtain data within “2021-06-04” “2021-12-31” instead set n_training number days two dates, inclusive end points. end results . addition n_training, forecast_date target_date specify date forecast created intended, respectively. dwell arguments unique classifier absolutely essential understanding operates. remaining arguments discussed organically, needed serve purposes. information remaining arguments discussed , please see function documentation complete list definitions.","code":"jhu <- case_death_rate_subset %>%   filter(     time_value >= \"2021-06-04\",     time_value <= \"2021-12-31\",     geo_value %in% c(\"ca\", \"fl\", \"tx\", \"ny\", \"nj\")   )  out <- arx_classifier(jhu, outcome = \"case_rate\", predictors = \"case_rate\")  out$predictions #> # A tibble: 5 × 4 #>   geo_value .pred_class forecast_date target_date #>   <chr>     <fct>       <date>        <date>      #> 1 ca        (-Inf,0.25] 2021-12-31    2022-01-07  #> 2 fl        (-Inf,0.25] 2021-12-31    2022-01-07  #> 3 nj        (-Inf,0.25] 2021-12-31    2022-01-07  #> 4 ny        (-Inf,0.25] 2021-12-31    2022-01-07  #> 5 tx        (-Inf,0.25] 2021-12-31    2022-01-07 workflows::extract_spec_parsnip(out$epi_workflow) #> Logistic Regression Model Specification (classification) #>  #> Computational engine: glm out_break_0.5 <- arx_classifier(   jhu,   outcome = \"case_rate\",   predictors = \"case_rate\",   args_list = arx_class_args_list(     breaks = 0.5   ) )  out_break_0.5$predictions #> # A tibble: 5 × 4 #>   geo_value .pred_class forecast_date target_date #>   <chr>     <fct>       <date>        <date>      #> 1 ca        (-Inf,0.5]  2021-12-31    2022-01-07  #> 2 fl        (-Inf,0.5]  2021-12-31    2022-01-07  #> 3 nj        (-Inf,0.5]  2021-12-31    2022-01-07  #> 4 ny        (-Inf,0.5]  2021-12-31    2022-01-07  #> 5 tx        (-Inf,0.5]  2021-12-31    2022-01-07"},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/arx-classifier.html","id":"example-of-using-the-arx-classifier","dir":"Articles","previous_headings":"","what":"Example of using the ARX classifier","title":"Auto-regressive classifier","text":"Now, demonstrate power utility built-arx classifier, loosely adapt classification example written scratch vignette(\"preprocessing--models\"). However, keep things simple merely direct translation, consider two prediction categories leave extension three exercise reader. motivate example, major use autoregressive classification models predict upswings downswings like hotspot prediction models anticipate direction outcome (see McDonald, Bien, Green, Hu, et al. (2021) ). case, one simple question models can help answer … expect future increased case rates relative present? answer question, can create predictive model upswings downswings case rates rather raw case rates . situation, target predict whether increase case rates . Following McDonald, Bien, Green, Hu, et al.(2021), look relative change Yl,tY_{l,t} Yl,t+aY_{l, t+}, former case rate location ll time tt latter rate location time t++. Using variables, define categorical response variable two classes Zl,t={,Yl,tΔ>0.25not ,otherwise\\begin{align} Z_{l,t} = \\left\\{\\begin{matrix} \\text{,} & \\text{} Y_{l,t}^\\Delta > 0.25\\\\ \\text{,} & \\text{otherwise} \\end{matrix}\\right. \\end{align} Yl,tΔ=(Yl,t−Yl,t−7/Yl,t−7Y_{l,t}^\\Delta = (Y_{l, t} - Y_{l, t-7} / Y_{l, t-7}. Yl,tΔY_{l,t}^\\Delta > 0.25, meaning number new cases week increased 25%, Zl,tZ_{l,t} . criteria location ll hotspot time tt. hand, Yl,tΔY_{l,t}^\\Delta $, Zl,tZ_{l,t} categorized , meaning >25% increase new cases past week. logistic regression model use predict binary response can considered simplification multinomial regression model presented vignette(\"preprocessing--models\"): πup(x)=Pr(Zl,t=|x)=egup(x)1+egup(x),πnot (x)=Pr(Zl,t=|x)=1−Pr(Zl,t=|x)=11+egup(x)\\begin{align} \\pi_{\\text{}}(x) &= Pr(Z_{l, t} = \\text{}|x) = \\frac{e^{g_{\\text{}}(x)}}{1 + e^{g_{\\text{}}(x)}}, \\\\ \\pi_{\\text{}}(x)&= Pr(Z_{l, t} = \\text{}|x) = 1 - Pr(Z_{l, t} = \\text{}|x)  = \\frac{1}{1 + e^{g_{\\text{}}(x)}} \\end{align} gup(x)=log(Pr(Zl,t=|x)Pr(Zl,t=|x))=β10+β11Yl,tΔ+β12Yl,t−7Δ+β13Yl,t−14Δ. g_{\\text{}}(x) = \\log\\left ( \\frac{\\Pr(Z_{l, t} = \\text{} \\vert x)}{\\Pr(Z_{l, t} = \\text{} \\vert x)} \\right ) = \\beta_{10} + \\beta_{11}Y_{l,t}^\\Delta + \\beta_{12}Y_{l,t-7}^\\Delta + \\beta_{13}Y_{l,t-14}^\\Delta. Now , operate subset case_death_rate_subset used example. time, use investigate whether number newly reported cases past 7 days increased least 25% compared preceding week sample states. Notice using arx_classifier() function ’ve completely eliminated need manually categorize response variable implement pre-processing steps, necessary vignette(\"preprocessing--models\"). Comparing pre-processing steps vignette, can see precisely , cover essentials transforming case_rate growth rate scale (step_growth_rate()), lagging predictors (step_epi_lag()), leading response (step_epi_ahead()), constructed growth rates, constructing binary classification response variable (step_mutate()). topic, important understand actually concerned case values . Rather concerned whether quantity cases future lot larger present. reason, outcome remain cases, rather transformed using either growth rates (predictors outcome example ) lagged differences. latter closer requirements 2022-23 CDC Flusight Hospitalization Experimental Target, conceptually easy understand simply change value horizon, default. default growth_rate. One reason choice growth rate rate scale, absolute scale, fosters comparability across locations without conscious effort (hand, using lag_difference one need take care operate rates per 100k raw counts). utilize epiprocess::growth_rate() create outcome using additional arguments. One important argument growth rate calculation method. rel_change relative change used method test data data accessible methods require access training data. optional arguments controlling growth rate calculation (can inputted additional_gr_args) can found documentation epiprocess::growth_rate() related vignette(\"growth_rate\", package = \"epiprocess\").","code":"log_res <- arx_classifier(   jhu,   outcome = \"case_rate\",   predictors = \"case_rate\",   args_list = arx_class_args_list(     breaks = 0.25 / 7 # division by 7 gives weekly not daily   ) )  log_res$epi_workflow #>  #> Call:  stats::glm(formula = ..y ~ ., family = stats::binomial, data = data) #>  #> Coefficients: #>                      (Intercept)   lag_0_gr_7_rel_change_case_rate   #>                           -1.603                            16.093   #>  lag_7_gr_7_rel_change_case_rate  lag_14_gr_7_rel_change_case_rate   #>                           25.265                            -1.868   #>  #> Degrees of Freedom: 914 Total (i.e. Null);  911 Residual #> Null Deviance:       1156  #> Residual Deviance: 813.8     AIC: 821.8"},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/arx-classifier.html","id":"visualizing-the-results","dir":"Articles","previous_headings":"Example of using the ARX classifier","what":"Visualizing the results","title":"Auto-regressive classifier","text":"visualize prediction classes across states target date, can plot results heatmap. However, plot results one target date, like 7-day ahead predictions, pretty sad heatmap (look like bar chart heatmap)… instead , let’s get predictions several aheads plot heatmap across target dates. get predictions across several ahead values, use map function way vignettes: can plot heatmap results aheads see ’s anything novel interesting take away:  bit variability near end, can clearly see upswings states starting beginning January 2022, can recall massive spike cases many states. results seem align well actually happened beginning January 2022.","code":"multi_log_res <- map(1:40, ~ arx_classifier(   jhu,   outcome = \"case_rate\",   predictors = \"case_rate\",   args_list = arx_class_args_list(     breaks = 0.25 / 7, # division by 7 gives weekly not daily     ahead = .x   ) )$predictions) %>% list_rbind() ggplot(multi_log_res, aes(target_date, geo_value, fill = .pred_class)) +   geom_tile() +   ylab(\"State\") +   xlab(\"Target date\") +   scale_fill_brewer(palette = \"Set1\")"},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/arx-classifier.html","id":"a-brief-reflection","dir":"Articles","previous_headings":"","what":"A brief reflection","title":"Auto-regressive classifier","text":"noticeable benefit using arx_classifier() function simplification reduction manual implementation classifier 30 3 lines. However, noted , trade-simplicity control precise pre-processing, post-processing, additional features embedded coding classifier. good thing epipredict provides - built-arx_classifer() means implement classifier scratch using epi_workflow framework. choose depend circumstances. advice start using built-classifier ostensibly simple projects begin implement modelling project takes complicated turn. get practice coding classifier hand, consider translating binary classification model example epi_workflow, akin vignette(\"preprocessing--models\").","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/epipredict.html","id":"goals-for-the-package","dir":"Articles","previous_headings":"","what":"Goals for the package","title":"Get started with epipredict","text":"high level, goal epipredict make running simple Machine Learning / Statistical forecasters epidemiology easy. However, package extremely extensible, part utility. hope easy users epi training statistics fit baseline models still allowing nuanced statistical understanding create complicated specializations using framework. Serving populations main motivation efforts, time, tried hard make useful.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/epipredict.html","id":"baseline-models","dir":"Articles","previous_headings":"Goals for the package","what":"Baseline models","title":"Get started with epipredict","text":"provide set basic, easy--use forecasters work box. able reasonably limited amount customization . serious customization happens framework discussed ). basic forecasters, provide: Baseline flat-line forecaster Autoregressive forecaster Autoregressive classifier forcasters provide built framework. use basic models illustrate flexibility.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/epipredict.html","id":"forecasting-framework","dir":"Articles","previous_headings":"Goals for the package","what":"Forecasting framework","title":"Get started with epipredict","text":"framework creating custom forecasters views prediction task set modular components. four types components: Preprocessor: make transformations data model training Trainer: train model data, resulting fitted model object Predictor: make predictions, using fitted model object processed test data Postprocessor: manipulate transform predictions returning Users familiar {tidymodels} especially {workflows} package notice lot overlap. design, fact feature. truth epipredict wrapper around much contained packages. Therefore, want something -verse, “just work” (hope). reason overlap workflows already implements first three steps. well. However, missing postprocessing stage currently plans implementation. feature important. baseline forecaster provide requires postprocessing. Anything complicated needs well. second omission tidymodels support panel data. Besides epidemiological data, economics, psychology, sociology, many areas frequently deal data type. framework behind epipredict implements . principle, nothing epidemiology, one simply use package solution missing functionality tidymodels. , “just work”. panel data functionality implemented epi_df data type companion {epiprocess} package. much see , moment, ’s enough look simple one: data built package contains measured variables case_rate death_rate COVID-19 daily level US state year 2021. “panel” part repeated measurements across number locations. epi_df encodes time stamp time_value key geo_value. 2 names required, values don’t need actually represent objects. Additional key’s also supported (like age group, ethnicity, taxonomy, etc.). epi_df also contains metadata describes keys well vintage data. ’s possible data collected different times set geo_value’s time_value’s actually different. details, see {epiprocess}.","code":"jhu <- case_death_rate_subset jhu #> An `epi_df` object, 20,496 x 4 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-31 19:08:25.791826 #>  #> # A tibble: 20,496 × 4 #>    geo_value time_value case_rate death_rate #>  * <chr>     <date>         <dbl>      <dbl> #>  1 ak        2020-12-31      35.9      0.158 #>  2 al        2020-12-31      65.1      0.438 #>  3 ar        2020-12-31      66.0      1.27  #>  4 as        2020-12-31       0        0     #>  5 az        2020-12-31      76.8      1.10  #>  6 ca        2020-12-31      96.0      0.751 #>  7 co        2020-12-31      35.8      0.649 #>  8 ct        2020-12-31      52.1      0.819 #>  9 dc        2020-12-31      31.0      0.601 #> 10 de        2020-12-31      65.2      0.807 #> # ℹ 20,486 more rows"},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/epipredict.html","id":"why-doesnt-this-package-already-exist","dir":"Articles","previous_headings":"Goals for the package","what":"Why doesn’t this package already exist?","title":"Get started with epipredict","text":"described : Parts actually exist. ’s universe called tidymodels. handles preprocessing, training, prediction, bound together, package called workflows. built epipredict top setup. way, CAN use almost everything provide. However, workflows doesn’t postprocessing. nothing -verse handles panel data. tidy-team doesn’t plans either things. (checked). two packages time series built tidymodels, ’s “basic” time series: 1-step AR models, exponential smoothing, STL decomposition, etc.1 group prioritized sorts models epidemic forecasting, one also integrate methods framework.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/epipredict.html","id":"show-me-the-basics","dir":"Articles","previous_headings":"","what":"Show me the basics","title":"Get started with epipredict","text":"start jhu data displayed . One “canned” forecasters provide autoregressive forecaster (without) covariates directly trains response. contrast typical “iterative” AR model trains predict one-step-ahead, plugs predictions “leverage ” longer horizons. ’ll estimate model jointly across locations using recent 30 days. object two components: predictions just another epi_df. contains predictions location along additional columns. default, 90% predictive interval, forecast_date (date forecast putatively made) target_date (date forecast made). list object class epi_workflow. object encapsulates instructions necessary create prediction. details . default, forecaster predicts outcome (death_rate) 1-week ahead, using 3 lags predictor (case_rate death_rate) 0 (today), 1 week back 2 weeks back. predictors outcome can changed directly. rest defaults encapsulated list arguments. list produced arx_args_list().","code":"jhu <- jhu %>% filter(time_value >= max(time_value) - 30) out <- arx_forecaster(   jhu,   outcome = \"death_rate\",   predictors = c(\"case_rate\", \"death_rate\") ) out$predictions #> # A tibble: 56 × 5 #>    geo_value  .pred        .pred_distn forecast_date target_date #>    <chr>      <dbl>             <dist> <date>        <date>      #>  1 ak        0.355  quantiles(0.36)[2] 2021-12-31    2022-01-07  #>  2 al        0.325  quantiles(0.32)[2] 2021-12-31    2022-01-07  #>  3 ar        0.496   quantiles(0.5)[2] 2021-12-31    2022-01-07  #>  4 as        0.0836  quantiles(0.2)[2] 2021-12-31    2022-01-07  #>  5 az        0.614  quantiles(0.61)[2] 2021-12-31    2022-01-07  #>  6 ca        0.327  quantiles(0.33)[2] 2021-12-31    2022-01-07  #>  7 co        0.567  quantiles(0.57)[2] 2021-12-31    2022-01-07  #>  8 ct        0.544  quantiles(0.54)[2] 2021-12-31    2022-01-07  #>  9 dc        0.831  quantiles(0.83)[2] 2021-12-31    2022-01-07  #> 10 de        0.607  quantiles(0.61)[2] 2021-12-31    2022-01-07  #> # ℹ 46 more rows out$epi_workflow #>  #> ══ Epi Workflow [trained] ══════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: linear_reg() #> Postprocessor: Frosting #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #>  #> 6 Recipe steps. #> 1. step_epi_lag() #> 2. step_epi_lag() #> 3. step_epi_ahead() #> 4. step_naomit() #> 5. step_naomit() #> 6. step_training_window() #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #>  #> Call: #> stats::lm(formula = ..y ~ ., data = data) #>  #> Coefficients: #>       (Intercept)    lag_0_case_rate    lag_7_case_rate   lag_14_case_rate   #>         0.0829475          0.0009830          0.0027035         -0.0005651   #>  lag_0_death_rate   lag_7_death_rate  lag_14_death_rate   #>         0.2466110          0.1964921          0.0752998 #>  #> ── Postprocessor ─────────────────────────────────────────────────────────────── #>  #> 5 Frosting layers. #> 1. layer_predict() #> 2. layer_residual_quantiles() #> 3. layer_add_forecast_date() #> 4. layer_add_target_date() #> 5. layer_threshold() #>"},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/epipredict.html","id":"simple-adjustments","dir":"Articles","previous_headings":"Show me the basics","what":"Simple adjustments","title":"Get started with epipredict","text":"Basic adjustments can made args_list. , ’ve used different lags case_rate now predicting 2 weeks ahead. example also illustrates major difficulty “iterative” versions AR models. model doesn’t produce forecasts case_rate, , data “plug ” necessary lags.2 Another property basic model predictive interval. describe detail different vignette, easy request multiple quantiles. column .pred_dstn predictions object actually “distribution” parameterized quantiles. default forecaster, created using quantiles residuals predictive model (possibly symmetrized). , used 23 quantiles, one can grab particular quantile, extract entire distribution “long” epi_df quantile_levels probability values value associated quantile. Additional simple adjustments basic forecaster can made using function:","code":"out2week <- arx_forecaster(   jhu,   outcome = \"death_rate\",   predictors = c(\"case_rate\", \"death_rate\"),   args_list = arx_args_list(     lags = list(c(0, 1, 2, 3, 7, 14), c(0, 7, 14)),     ahead = 14   ) ) out_q <- arx_forecaster(jhu, \"death_rate\", c(\"case_rate\", \"death_rate\"),   args_list = arx_args_list(     quantile_levels = c(.01, .025, seq(.05, .95, by = .05), .975, .99)   ) ) head(quantile(out_q$predictions$.pred_distn, p = .4)) #> [1] 0.30277798 0.27213225 0.44345734 0.03120647 0.56121844 0.27492711 out_q$predictions %>%   # first create a \"nested\" list-column   mutate(.pred_distn = nested_quantiles(.pred_distn)) %>%   unnest(.pred_distn) # then unnest it #> # A tibble: 1,288 × 6 #>    geo_value .pred values quantile_levels forecast_date target_date #>    <chr>     <dbl>  <dbl>           <dbl> <date>        <date>      #>  1 ak        0.355 0                0.01  2021-12-31    2022-01-07  #>  2 ak        0.355 0                0.025 2021-12-31    2022-01-07  #>  3 ak        0.355 0.0371           0.05  2021-12-31    2022-01-07  #>  4 ak        0.355 0.123            0.1   2021-12-31    2022-01-07  #>  5 ak        0.355 0.174            0.15  2021-12-31    2022-01-07  #>  6 ak        0.355 0.211            0.2   2021-12-31    2022-01-07  #>  7 ak        0.355 0.237            0.25  2021-12-31    2022-01-07  #>  8 ak        0.355 0.260            0.3   2021-12-31    2022-01-07  #>  9 ak        0.355 0.282            0.35  2021-12-31    2022-01-07  #> 10 ak        0.355 0.303            0.4   2021-12-31    2022-01-07  #> # ℹ 1,278 more rows arx_args_list(   lags = c(0L, 7L, 14L), ahead = 7L, n_training = Inf,   forecast_date = NULL, target_date = NULL, quantile_levels = c(0.05, 0.95),   symmetrize = TRUE, nonneg = TRUE, quantile_by_key = character(0L),   nafill_buffer = Inf )"},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/epipredict.html","id":"changing-the-engine","dir":"Articles","previous_headings":"Show me the basics","what":"Changing the engine","title":"Get started with epipredict","text":"far, forecasts produced using simple linear regression. way estimate model. trainer argument determines type model want. takes {parsnip} model. default linear regression, instead use random forest ranger package: boosted regression trees xgboost: quantile regression, using custom forecasting engine quantile_reg(): FWIW, last case (using quantile regression), far Delphi production forecast team used Covid forecasts past years.","code":"out_rf <- arx_forecaster(   jhu, \"death_rate\", c(\"case_rate\", \"death_rate\"),   rand_forest(mode = \"regression\") ) out_gb <- arx_forecaster(   jhu, \"death_rate\", c(\"case_rate\", \"death_rate\"),   boost_tree(mode = \"regression\", trees = 20) ) out_qr <- arx_forecaster(   jhu, \"death_rate\", c(\"case_rate\", \"death_rate\"),   quantile_reg() )"},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/epipredict.html","id":"inner-workings","dir":"Articles","previous_headings":"Show me the basics","what":"Inner workings","title":"Get started with epipredict","text":"Underneath hood, forecaster creates (returns) epi_workflow. Essentially, big S3 object wraps 4 modular steps (preprocessing - postprocessing) described .","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/epipredict.html","id":"preprocessing","dir":"Articles","previous_headings":"Show me the basics > Inner workings","what":"Preprocessing","title":"Get started with epipredict","text":"Preprocessing accomplished recipe (imagine baking cake) provided {recipes} package. ’ve made modifications (handle panel data) well added additional options. recipe gives specification handle training data. Think like fancified formula pass lm(): y ~ x1 + log(x2). general, 2 extensions formula recipes handles: transformations training test data can always applied. things like taking log variable, leading lagging, filtering rows, handling dummy variables, etc. Using statistics training data eventually process test data. major benefit recipes. prevents tidy team calls “data leakage”. simple example centering predictor mean. need store mean predictor training data use value test data rather accidentally calculating mean test predictor centering. recipe processed 2 steps, first “prepped”. calculates stores intermediate statistics necessary use test data. “baked” resulting training data ready passing statistical model (like lm). introduced epi_recipe. ’s just recipe knows handle time_value, geo_value, additional keys available necessary. epi_recipe out_gb can extracted result: “Inputs” original epi_df “roles” assigned. None predictors outcomes. created recipe prepped. “Operations” sequence instructions create cake (baked training data). create lagged predictors, lead outcome, remove NAs. models like lm internally handle NAs, everything , deal explicitly. code (inside forecaster) recipes provides function step_lag(), assumes data breaks sequence time_values. bit dangerous, avoid behaviour. lag/ahead functions also appropriately adjust amount data avoid accidentally dropping recent predictors test data.","code":"extract_recipe(out_gb$epi_workflow) er <- epi_recipe(jhu) %>%   step_epi_lag(case_rate, death_rate, lag = c(0, 7, 14)) %>%   step_epi_ahead(death_rate, ahead = 7) %>%   step_epi_naomit()"},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/epipredict.html","id":"the-model-specification","dir":"Articles","previous_headings":"Show me the basics > Inner workings","what":"The model specification","title":"Get started with epipredict","text":"Users familiarity parsnip package trouble . Basically, parsnip unifies function signature across statistical models. example, lm() “likes” work formulas, glmnet::glmnet() uses x y predictors response. parsnip agnostic. “linear regression”. switched lm() xgboost() without issue despite fact functions couldn’t different. epipredict provides engines/modules (flatline forecaster quantile regression), able use available models listed . estimate (fit) preprocessed model, one calls fit() epi_workflow.","code":"lm(formula, data, subset, weights, na.action,   method = \"qr\",   model = TRUE, x = FALSE, y = FALSE, qr = TRUE, singular.ok = TRUE,   contrasts = NULL, offset, ... )  xgboost(   data = NULL, label = NULL, missing = NA, weight = NULL,   params = list(), nrounds, verbose = 1, print_every_n = 1L,   early_stopping_rounds = NULL, maximize = NULL, save_period = NULL,   save_name = \"xgboost.model\", xgb_model = NULL, callbacks = list(),   ... ) ewf <- epi_workflow(er, linear_reg()) %>% fit(jhu)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/epipredict.html","id":"postprocessing","dir":"Articles","previous_headings":"Show me the basics > Inner workings","what":"Postprocessing","title":"Get started with epipredict","text":"stretch metaphor preparing cake natural limits, created postprocessing functionality called “frosting”. Much like recipe, postprocessing operation “layer” “slather” onto baked cake. fix ideas, postprocessing frosting arx_forecaster() 5 layers frosting. first generates forecasts test data. second uses quantiles residuals create distributional forecasts. next two add columns date forecast made date intended occur. predicting rates, non-negative, last layer thresholds predicted values intervals 0. code (inside forecaster) predict time, add object onto epi_workflow call forecast() get_test_data() function examines recipe ensures enough test data available create necessary lags produce prediction desired future time point (end training data). mimics happen jhu contained recent available historical data wanted actually predict future. instead used test data contained necessary predictors.","code":"extract_frosting(out_q$epi_workflow) f <- frosting() %>%   layer_predict() %>%   layer_residual_quantiles(     quantile_levels = c(.01, .025, seq(.05, .95, by = .05), .975, .99),     symmetrize = TRUE   ) %>%   layer_add_forecast_date() %>%   layer_add_target_date() %>%   layer_threshold(starts_with(\".pred\")) ewf %>%   add_frosting(f) %>%   forecast() #> An `epi_df` object, 56 x 6 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-31 19:08:25.791826 #>  #> # A tibble: 56 × 6 #>    geo_value time_value  .pred         .pred_distn forecast_date target_date #>  * <chr>     <date>      <dbl>              <dist> <date>        <date>      #>  1 ak        2021-12-31 0.355  quantiles(0.36)[23] 2021-12-31    2022-01-07  #>  2 al        2021-12-31 0.325  quantiles(0.32)[23] 2021-12-31    2022-01-07  #>  3 ar        2021-12-31 0.496   quantiles(0.5)[23] 2021-12-31    2022-01-07  #>  4 as        2021-12-31 0.0836 quantiles(0.08)[23] 2021-12-31    2022-01-07  #>  5 az        2021-12-31 0.614  quantiles(0.61)[23] 2021-12-31    2022-01-07  #>  6 ca        2021-12-31 0.327  quantiles(0.33)[23] 2021-12-31    2022-01-07  #>  7 co        2021-12-31 0.567  quantiles(0.57)[23] 2021-12-31    2022-01-07  #>  8 ct        2021-12-31 0.544  quantiles(0.54)[23] 2021-12-31    2022-01-07  #>  9 dc        2021-12-31 0.831  quantiles(0.83)[23] 2021-12-31    2022-01-07  #> 10 de        2021-12-31 0.607  quantiles(0.61)[23] 2021-12-31    2022-01-07  #> # ℹ 46 more rows"},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/epipredict.html","id":"conclusion","dir":"Articles","previous_headings":"Show me the basics","what":"Conclusion","title":"Get started with epipredict","text":"Internally, provide simple functions create reasonable forecasts. ideally, user create forecasters building components provide. vignettes, try walk customizations. illustrate everything , (roughly) code flatline_forecaster() applied case_rate. really differs arx_forecaster() recipe, test data, engine. frosting identical, fitting predicting procedure.","code":"r <- epi_recipe(jhu) %>%   step_epi_ahead(case_rate, ahead = 7, skip = TRUE) %>%   update_role(case_rate, new_role = \"predictor\") %>%   add_role(all_of(key_colnames(jhu)), new_role = \"predictor\")  f <- frosting() %>%   layer_predict() %>%   layer_residual_quantiles() %>%   layer_add_forecast_date() %>%   layer_add_target_date() %>%   layer_threshold(starts_with(\".pred\"))  eng <- linear_reg() %>% set_engine(\"flatline\") wf <- epi_workflow(r, eng, f) %>% fit(jhu) preds <- forecast(wf) preds #> An `epi_df` object, 56 x 6 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-31 19:08:25.791826 #>  #> # A tibble: 56 × 6 #>    geo_value time_value .pred          .pred_distn forecast_date target_date #>  * <chr>     <date>     <dbl>               <dist> <date>        <date>      #>  1 ak        2021-12-31  36.4  quantiles(39.58)[2] 2021-12-31    2022-01-07  #>  2 al        2021-12-31  89.9  quantiles(89.92)[2] 2021-12-31    2022-01-07  #>  3 ar        2021-12-31  82.6  quantiles(82.58)[2] 2021-12-31    2022-01-07  #>  4 as        2021-12-31   0    quantiles(21.39)[2] 2021-12-31    2022-01-07  #>  5 az        2021-12-31  58.3  quantiles(58.28)[2] 2021-12-31    2022-01-07  #>  6 ca        2021-12-31  84.4  quantiles(84.37)[2] 2021-12-31    2022-01-07  #>  7 co        2021-12-31 106.  quantiles(105.83)[2] 2021-12-31    2022-01-07  #>  8 ct        2021-12-31 143.   quantiles(143.1)[2] 2021-12-31    2022-01-07  #>  9 dc        2021-12-31 295.  quantiles(295.03)[2] 2021-12-31    2022-01-07  #> 10 de        2021-12-31 150.  quantiles(149.93)[2] 2021-12-31    2022-01-07  #> # ℹ 46 more rows"},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/panel-data.html","id":"example-panel-data-overview","dir":"Articles","previous_headings":"","what":"Example panel data overview","title":"Using epipredict on non-epidemic panel data","text":"vignette, demonstrate using epipredict employment panel data Statistics Canada. using Table 37-10-0115-01: Characteristics median employment income longitudinal cohorts postsecondary graduates two five years graduation, educational qualification field study (primary groupings). full dataset contains yearly median employment income two five years graduation, number graduates. data stratified variables geographic region (Canadian province), education, age group. year range dataset 2010 2017, inclusive. full dataset also contains metadata describes quality data collected. demonstration purposes, make following modifications get subset full dataset: keep provincial-level geographic region (full data also “Canada” region) keep “good” better quality data rows, indicated STATUS column Choose subset covariates aggregate across remaining ones. chosen covariates age group, educational qualification. use data epipredict, need convert epi_df format using epiprocess::as_epi_df() additional keys. case, additional keys age_group, edu_qual. Note modifications, encoded time_value type integer. lets us set time_type = \"year\", ensures lag ahead modifications later using correct time units. See epiprocess::epi_df list time_types available. Now, ready use grad_employ_subset epipredict. epi_df contains 1,445 rows 7 columns. quick summary columns epi_df: time_value (time value): year date format geo_value (geo value): province Canada num_graduates (raw, time series value): number graduates med_income_2y (raw, time series value): median employment income 2 years graduation med_income_5y (raw, time series value): median employment income 5 years graduation age_group (key): one two age groups, either 15 34 years, 35 64 years edu_qual (key): one 32 unique educational qualifications, e.g., “Master’s diploma” following sections, go pre-processing data epi_recipe framework, fitting model making predictions within epipredict framework using package’s canned forecasters.","code":"# Rename for simplicity employ <- grad_employ_subset sample_n(employ, 6) #> An `epi_df` object, 6 x 7 with metadata: #> * geo_type  = custom #> * time_type = integer #> * other_keys = age_group, edu_qual #> * as_of     = 2022-07-19 #>  #> # A tibble: 6 × 7 #>   geo_value        age_group     edu_qual time_value num_graduates med_income_2y #> * <chr>            <fct>         <fct>         <int>         <dbl>         <dbl> #> 1 Saskatchewan     35 to 64 yea… Undergr…       2016           120         69800 #> 2 British Columbia 35 to 64 yea… Post-ba…       2017           240         65000 #> 3 Saskatchewan     35 to 64 yea… Post-ba…       2012            10         96800 #> 4 Quebec           15 to 34 yea… Master'…       2010            80         65500 #> 5 British Columbia 35 to 64 yea… Career,…       2012          3060         43000 #> 6 New Brunswick    35 to 64 yea… Career,…       2013           230         26700 #> # ℹ 1 more variable: med_income_5y <dbl>"},{"path":[]},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/panel-data.html","id":"pre-processing","dir":"Articles","previous_headings":"Autoregressive (AR) model to predict number of graduates in a year","what":"Pre-processing","title":"Using epipredict on non-epidemic panel data","text":"simple example, let’s work num_graduates column now. first pre-process standardizing numeric column total within group keys. since raw numeric values vary greatly province province since large differences population. visualization sample small data British Columbia Ontario. Note groups time series information since filtered time series incomplete dates.  predict standardized number graduates (proportion) next year (time t+1t+1) using autoregressive model three lags (.e., AR(3) model). model represented algebraically like : yt+1,ijk=α0+α1ytijk+α2yt−1,ijk+α3yt−2,ijk+ϵtijk   y_{t+1,ijk} =    \\alpha_0 + \\alpha_1 y_{tijk} + \\alpha_2 y_{t-1,ijk} + \\alpha_3 y_{t-2,ijk} + \\epsilon_{tijk} ytijy_{tij} proportion graduates time tt location ii age group jj education quality kk. pre-processing step, need create additional columns employ yt+1,ijky_{t+1,ijk}, ytijky_{tijk}, yt−1,ijky_{t-1,ijk}, yt−2,ijky_{t-2,ijk}. via epi_recipe. Note creating epi_recipe alone doesn’t add outcome predictor columns; recipe just stores instructions adding . epi_recipe add one ahead column representing yt+1,ijky_{t+1,ijk} 3 lag columns representing ytijky_{tijk}, yt−1,ijky_{t-1,ijk}, yt−2,ijky_{t-2,ijk} (’s accurate think 0th “lag” “current” value 2 lags, ’s quite processing works). Also note since specified time_type year, lag lead values years. Let’s apply recipe using prep bake generate view lag ahead columns. can see prep bake steps created new columns according epi_recipe: ahead_1_num_graduates_prop corresponds yt+1,ijky_{t+1,ijk} lag_0_num_graduates_prop, lag_1_num_graduates_prop, lag_2_num_graduates_prop correspond ytijky_{tijk}, yt−1,ijky_{t-1,ijk}, yt−2,ijky_{t-2,ijk} respectively.","code":"employ_small <- employ %>%   group_by(geo_value, age_group, edu_qual) %>%   # Select groups where there are complete time series values   filter(n() >= 6) %>%   mutate(     num_graduates_prop = num_graduates / sum(num_graduates),     med_income_2y_prop = med_income_2y / sum(med_income_2y),     med_income_5y_prop = med_income_5y / sum(med_income_5y)   ) %>%   ungroup() head(employ_small) #> An `epi_df` object, 6 x 10 with metadata: #> * geo_type  = custom #> * time_type = integer #> * other_keys = age_group, edu_qual #> * as_of     = 2022-07-19 #>  #> # A tibble: 6 × 10 #>   geo_value            age_group edu_qual time_value num_graduates med_income_2y #> * <chr>                <fct>     <fct>         <int>         <dbl>         <dbl> #> 1 Newfoundland and La… 15 to 34… Career,…       2010           430         48800 #> 2 Newfoundland and La… 35 to 64… Career,…       2010           140         38100 #> 3 Newfoundland and La… 15 to 34… Career,…       2010           630         49500 #> 4 Newfoundland and La… 35 to 64… Career,…       2010           140         48400 #> 5 Newfoundland and La… 15 to 34… Undergr…       2010          1050         63600 #> 6 Newfoundland and La… 35 to 64… Undergr…       2010           130         85700 #> # ℹ 4 more variables: med_income_5y <dbl>, num_graduates_prop <dbl>, #> #   med_income_2y_prop <dbl>, med_income_5y_prop <dbl> employ_small %>%   filter(geo_value %in% c(\"British Columbia\", \"Ontario\")) %>%   filter(grepl(\"degree\", edu_qual, fixed = T)) %>%   group_by(geo_value, time_value, edu_qual, age_group) %>%   summarise(num_graduates_prop = sum(num_graduates_prop), .groups = \"drop\") %>%   ggplot(aes(x = time_value, y = num_graduates_prop, color = geo_value)) +   geom_line() +   scale_colour_manual(values = c(\"Cornflowerblue\", \"Orange\"), name = \"\") +   facet_grid(rows = vars(edu_qual), cols = vars(age_group)) +   xlab(\"Year\") +   ylab(\"Percentage of gratuates\") +   theme(legend.position = \"bottom\") r <- epi_recipe(employ_small) %>%   step_epi_ahead(num_graduates_prop, ahead = 1) %>%   step_epi_lag(num_graduates_prop, lag = 0:2) %>%   step_epi_naomit() r #>  #> ── Epi Recipe ────────────────────────────────────────────────────────────────── #>  #> ── Inputs #> Number of variables by role #> raw:        6 #> key:        2 #> geo_value:  1 #> time_value: 1 #>  #> ── Operations #> 1. Leading: num_graduates_prop by 1 #> 2. Lagging: num_graduates_prop by 0, 1, 2 #> 3. • Removing rows with NA values in: all_predictors() #> 4. • Removing rows with NA values in: all_outcomes() # Display a sample of the pre-processed data bake_and_show_sample <- function(recipe, data, n = 5) {   recipe %>%     prep(data) %>%     bake(new_data = data) %>%     sample_n(n) }  r %>% bake_and_show_sample(employ_small) #> An `epi_df` object, 5 x 14 with metadata: #> * geo_type  = custom #> * time_type = integer #> * other_keys = age_group, edu_qual #> * as_of     = 2022-07-19 #>  #> # A tibble: 5 × 14 #>   geo_value        age_group     edu_qual time_value num_graduates med_income_2y #> * <chr>            <fct>         <fct>         <dbl>         <dbl>         <dbl> #> 1 Ontario          35 to 64 yea… Master'…       2012            40        109300 #> 2 British Columbia 15 to 34 yea… Undergr…       2014         11520         51100 #> 3 Alberta          35 to 64 yea… Career,…       2013          1270         47400 #> 4 Alberta          35 to 64 yea… Undergr…       2016          1050         78400 #> 5 Quebec           15 to 34 yea… Career,…       2016          3920         39900 #> # ℹ 8 more variables: med_income_5y <dbl>, num_graduates_prop <dbl>, #> #   med_income_2y_prop <dbl>, med_income_5y_prop <dbl>, #> #   ahead_1_num_graduates_prop <dbl>, lag_0_num_graduates_prop <dbl>, #> #   lag_1_num_graduates_prop <dbl>, lag_2_num_graduates_prop <dbl>"},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/panel-data.html","id":"model-fitting-and-prediction","dir":"Articles","previous_headings":"Autoregressive (AR) model to predict number of graduates in a year","what":"Model fitting and prediction","title":"Using epipredict on non-epidemic panel data","text":"Since goal now fit simple autoregressive model, can use parsnip::linear_reg() default engine lm, fits linear regression using ordinary least squares. use epi_workflow epi_recipe defined pre-processing section along parsnip::linear_reg() model. Note epi_workflow container doesn’t actually fitting. pass workflow fit() get estimated model coefficients α̂,=0,...,3\\widehat{\\alpha}_i,\\ =0,...,3. output tells us coefficients fitted model; instance, estimated intercept α̂0=\\widehat{\\alpha}_0 = 0.109 coefficient ytijky_{tijk} α̂1=\\widehat\\alpha_1 = 0.324. summary also tells us estimated coefficients significantly different zero. Extracting 95% confidence intervals coefficients also leads us conclusion: coefficient estimates significantly different 0. Now workflow, can generate predictions subset data. demo, predict number graduates using last 2 years dataset. can using augment function . Note predict augment still return epiprocess::epi_df keys present original dataset.","code":"wf_linreg <- epi_workflow(r, linear_reg()) %>%   fit(employ_small) summary(extract_fit_engine(wf_linreg)) #>  #> Call: #> stats::lm(formula = ..y ~ ., data = data) #>  #> Residuals: #>       Min        1Q    Median        3Q       Max  #> -0.104501 -0.013043 -0.002708  0.009289  0.210582  #>  #> Coefficients: #>                           Estimate Std. Error t value Pr(>|t|)     #> (Intercept)               0.108532   0.006695  16.211  < 2e-16 *** #> lag_0_num_graduates_prop  0.324251   0.037163   8.725  < 2e-16 *** #> lag_1_num_graduates_prop  0.014190   0.038543   0.368 0.712848     #> lag_2_num_graduates_prop -0.137378   0.036337  -3.781 0.000168 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 0.02993 on 777 degrees of freedom #> Multiple R-squared:  0.1084, Adjusted R-squared:  0.1049  #> F-statistic: 31.47 on 3 and 777 DF,  p-value: < 2.2e-16 confint(extract_fit_engine(wf_linreg)) #>                                2.5 %      97.5 % #> (Intercept)               0.09538942  0.12167466 #> lag_0_num_graduates_prop  0.25130008  0.39720211 #> lag_1_num_graduates_prop -0.06147071  0.08985152 #> lag_2_num_graduates_prop -0.20870743 -0.06604791 latest <- get_test_data(recipe = r, x = employ_small) preds <- stats::predict(wf_linreg, latest) %>% filter(!is.na(.pred)) # Display a sample of the prediction values, excluding NAs preds %>% sample_n(5) #> An `epi_df` object, 5 x 5 with metadata: #> * geo_type  = custom #> * time_type = integer #> * other_keys = age_group, edu_qual #> * as_of     = 2022-07-19 #>  #> # A tibble: 5 × 5 #>   geo_value                 age_group      edu_qual             time_value .pred #> * <chr>                     <fct>          <fct>                     <dbl> <dbl> #> 1 New Brunswick             15 to 34 years Professional degree        2017 0.141 #> 2 British Columbia          15 to 34 years Career, technical o…       2017 0.134 #> 3 Nova Scotia               15 to 34 years Master's degree            2017 0.133 #> 4 Ontario                   15 to 34 years Undergraduate certi…       2017 0.161 #> 5 Newfoundland and Labrador 15 to 34 years Master's degree            2017 0.139 augment(wf_linreg, latest) %>% sample_n(5) #> An `epi_df` object, 5 x 11 with metadata: #> * geo_type  = custom #> * time_type = integer #> * other_keys = age_group, edu_qual #> * as_of     = 2022-07-19 #>  #> # A tibble: 5 × 11 #>   geo_value     age_group edu_qual time_value  .pred num_graduates med_income_2y #> * <chr>         <fct>     <fct>         <dbl>  <dbl>         <dbl>         <dbl> #> 1 British Colu… 35 to 64… Post-ba…       2017  0.143           240         65000 #> 2 Saskatchewan  15 to 34… Career,…       2015 NA              1120         39500 #> 3 Manitoba      15 to 34… Career,…       2016 NA              1010         45100 #> 4 Saskatchewan  35 to 64… Doctora…       2017  0.135            60         74800 #> 5 Manitoba      35 to 64… Other c…       2016 NA               110         48900 #> # ℹ 4 more variables: med_income_5y <dbl>, num_graduates_prop <dbl>, #> #   med_income_2y_prop <dbl>, med_income_5y_prop <dbl>"},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/panel-data.html","id":"model-diagnostics","dir":"Articles","previous_headings":"Autoregressive (AR) model to predict number of graduates in a year","what":"Model diagnostics","title":"Using epipredict on non-epidemic panel data","text":"First, ’ll plot residuals (, ytijk−ŷtijky_{tijk} - \\widehat{y}_{tijk}) fitted values (ŷtijk\\widehat{y}_{tijk}).  fitted values vs. residuals plot shows us residuals mostly clustered around zero, form even band around zero line, indicating variance residuals constant. Additionally, fitted values vs. square root standardized residuals makes obvious - spread square root standardized residuals varies fitted values. Q-Q plot shows us residuals heavier tails Normal distribution. normality residuals assumption doesn’t hold either. Finally, residuals vs. leverage plot shows us influential points based Cook’s distance (outside red dotted line). Since appear violating linear model assumptions, might consider transforming data differently, considering non-linear model, something else.","code":"par(mfrow = c(2, 2), mar = c(5, 3, 1.2, 0)) plot(extract_fit_engine(wf_linreg))"},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/panel-data.html","id":"ar-model-with-exogenous-inputs","dir":"Articles","previous_headings":"","what":"AR model with exogenous inputs","title":"Using epipredict on non-epidemic panel data","text":"Now suppose want model 1-step-ahead 5-year employment income using current two previous values, also incorporating information two time-series dataset: 2-year employment income number graduates previous 2 years. using autoregressive model exogenous inputs, defined follows: yt+1,ijk=α0+α1ytijk+α2yt−1,ijk+α3yt−2,ijk+β1xtijk+β2xt−1,ijk+γ2ztijk+γ2zt−1,ijk+ϵtijk \\begin{aligned}   y_{t+1,ijk} &=    \\alpha_0 + \\alpha_1 y_{tijk} + \\alpha_2 y_{t-1,ijk} + \\alpha_3 y_{t-2,ijk}\\\\   &\\quad + \\beta_1 x_{tijk} + \\beta_2 x_{t-1,ijk}\\\\   &\\quad + \\gamma_2 z_{tijk} + \\gamma_2 z_{t-1,ijk} + \\epsilon_{tijk} \\end{aligned} ytijky_{tijk} 5-year median income (proportion) time tt (location ii, age group jj education quality kk), xtijkx_{tijk} 2-year median income (proportion) time tt, ztijkz_{tijk} number graduates (proportion) time tt.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/panel-data.html","id":"pre-processing-1","dir":"Articles","previous_headings":"AR model with exogenous inputs","what":"Pre-processing","title":"Using epipredict on non-epidemic panel data","text":", construct epi_recipe detailing pre-processing steps.","code":"rx <- epi_recipe(employ_small) %>%   step_epi_ahead(med_income_5y_prop, ahead = 1) %>%   # 5-year median income has current, and two lags c(0, 1, 2)   step_epi_lag(med_income_5y_prop, lag = 0:2) %>%   # But the two exogenous variables have current values, and 1 lag c(0, 1)   step_epi_lag(med_income_2y_prop, lag = c(0, 1)) %>%   step_epi_lag(num_graduates_prop, lag = c(0, 1)) %>%   step_epi_naomit()  bake_and_show_sample(rx, employ_small) #> An `epi_df` object, 5 x 18 with metadata: #> * geo_type  = custom #> * time_type = integer #> * other_keys = age_group, edu_qual #> * as_of     = 2022-07-19 #>  #> # A tibble: 5 × 18 #>   geo_value            age_group edu_qual time_value num_graduates med_income_2y #> * <chr>                <fct>     <fct>         <dbl>         <dbl>         <dbl> #> 1 Prince Edward Island 35 to 64… Undergr…       2017            10         69700 #> 2 British Columbia     35 to 64… Post-ba…       2014           180         74700 #> 3 Alberta              35 to 64… Career,…       2016          1250         46000 #> 4 Saskatchewan         15 to 34… Undergr…       2015          2600         65400 #> 5 Saskatchewan         15 to 34… Doctora…       2016            70         56800 #> # ℹ 12 more variables: med_income_5y <dbl>, num_graduates_prop <dbl>, #> #   med_income_2y_prop <dbl>, med_income_5y_prop <dbl>, #> #   ahead_1_med_income_5y_prop <dbl>, lag_0_med_income_5y_prop <dbl>, #> #   lag_1_med_income_5y_prop <dbl>, lag_2_med_income_5y_prop <dbl>, #> #   lag_0_med_income_2y_prop <dbl>, lag_1_med_income_2y_prop <dbl>, #> #   lag_0_num_graduates_prop <dbl>, lag_1_num_graduates_prop <dbl>"},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/panel-data.html","id":"model-fitting-post-processing","dir":"Articles","previous_headings":"AR model with exogenous inputs","what":"Model fitting & post-processing","title":"Using epipredict on non-epidemic panel data","text":"fitting model making predictions, let’s add post-processing steps using frosting layers things: Threshold predictions 0. predicting proportions, can’t negative. transformed values back dollars people can’t negative either. Generate prediction intervals based residual quantiles, allowing us quantify uncertainty associated future predicted values. Convert predictions back income values number graduates, rather standardized proportions. via frosting layer layer_population_scaling(). Based summary output model, can examine confidence intervals perform hypothesis tests usual. Let’s take look predictions along 90% prediction intervals.","code":"# Create dataframe of the sums we used for standardizing # Only have to include med_income_5y since that is our outcome totals <- employ_small %>%   group_by(geo_value, age_group, edu_qual) %>%   summarise(med_income_5y_tot = sum(med_income_5y), .groups = \"drop\")  # Define post-processing steps f <- frosting() %>%   layer_predict() %>%   layer_naomit(.pred) %>%   layer_threshold(.pred, lower = 0) %>%   # 90% prediction interval   layer_residual_quantiles(     quantile_levels = c(0.1, 0.9),     symmetrize = FALSE   ) %>%   layer_population_scaling(     .pred, .pred_distn,     df = totals, df_pop_col = \"med_income_5y_tot\"   )  wfx_linreg <- epi_workflow(rx, parsnip::linear_reg()) %>%   fit(employ_small) %>%   add_frosting(f)  summary(extract_fit_engine(wfx_linreg)) #>  #> Call: #> stats::lm(formula = ..y ~ ., data = data) #>  #> Residuals: #>       Min        1Q    Median        3Q       Max  #> -0.049668 -0.004509 -0.000516  0.004707  0.049882  #>  #> Coefficients: #>                           Estimate Std. Error t value Pr(>|t|)     #> (Intercept)               0.041278   0.004975   8.298 4.72e-16 *** #> lag_0_med_income_5y_prop  0.320780   0.049348   6.500 1.44e-10 *** #> lag_1_med_income_5y_prop  0.079610   0.049116   1.621  0.10546     #> lag_2_med_income_5y_prop  0.073048   0.033686   2.168  0.03043 *   #> lag_0_med_income_2y_prop  0.118122   0.045579   2.592  0.00973 **  #> lag_1_med_income_2y_prop  0.034455   0.042749   0.806  0.42050     #> lag_0_num_graduates_prop -0.025129   0.013603  -1.847  0.06509 .   #> lag_1_num_graduates_prop  0.078268   0.013396   5.842 7.58e-09 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 0.01056 on 773 degrees of freedom #> Multiple R-squared:  0.3224, Adjusted R-squared:  0.3163  #> F-statistic: 52.54 on 7 and 773 DF,  p-value: < 2.2e-16 latest <- get_test_data(recipe = rx, x = employ_small) predsx <- predict(wfx_linreg, latest)  # Display predictions along with prediction intervals predsx %>%   select(     geo_value, time_value, edu_qual, age_group,     .pred_scaled, .pred_distn_scaled   ) %>%   head() %>%   pivot_quantiles_wider(.pred_distn_scaled) #> # A tibble: 6 × 7 #>   geo_value             time_value edu_qual age_group .pred_scaled  `0.1`  `0.9` #>   <chr>                      <dbl> <fct>    <fct>            <dbl>  <dbl>  <dbl> #> 1 Newfoundland and Lab…       2017 Career,… 15 to 34…       45724. 41734. 50431. #> 2 Newfoundland and Lab…       2017 Career,… 35 to 64…       37614. 34441. 41359. #> 3 Newfoundland and Lab…       2017 Career,… 15 to 34…       56992. 52334. 62489. #> 4 Newfoundland and Lab…       2017 Career,… 35 to 64…       47802. 43858. 52455. #> 5 Newfoundland and Lab…       2017 Post ca… 15 to 34…       61127. 56661. 66396. #> 6 Newfoundland and Lab…       2017 Undergr… 15 to 34…       72713. 66726. 79777."},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/panel-data.html","id":"using-canned-forecasters","dir":"Articles","previous_headings":"","what":"Using canned forecasters","title":"Using epipredict on non-epidemic panel data","text":"’ve seen can non-epidemiological panel data using recipes frame, epi_recipe pre-processing, epi_workflow model fitting, frosting post-processing. epipredict also comes canned forecasters steps behind scenes simple models. Even though aren’t working epidemiological data, canned forecasters still work expected, box. demonstrate simple flatline_forecaster direct autoregressive (AR) forecaster arx_forecaster. illustrations, continue use employ_small dataset transformed numeric columns proportions within group keys epi_df.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/panel-data.html","id":"flatline-forecaster","dir":"Articles","previous_headings":"Using canned forecasters","what":"Flatline forecaster","title":"Using epipredict on non-epidemic panel data","text":"first example, ’ll use flatline_forecaster make simple prediction 2-year median income next year, based one previous time point. model representated algebraically : yt+1,ijk=ytijk+ϵtijky_{t+1,ijk} = y_{tijk} + \\epsilon_{tijk} ytijky_{tijk} 2-year median income (proportion) time tt.","code":"out_fl <- flatline_forecaster(employ_small, \"med_income_2y_prop\",   args_list = flatline_args_list(ahead = 1) )  out_fl #> ══ A basic forecaster of type flatline ═════════════════════════════════════════ #>  #> This forecaster was fit on 2024-10-09 20:16:04. #>  #> Training data was an <epi_df> with: #> • Geography: custom, #> • Other keys: age_group and edu_qual, #> • Time type: integer, #> • Using data up-to-date as of: 2022-07-19. #> • With the last data available on 2017 #>  #> ── Predictions ───────────────────────────────────────────────────────────────── #>  #> A total of 167 predictions are available for #> • 11 unique geographic regions, #> • At forecast dates: 2017, #> • For target dates: 2018, #>"},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/panel-data.html","id":"autoregressive-forecaster-with-exogenous-inputs","dir":"Articles","previous_headings":"Using canned forecasters","what":"Autoregressive forecaster with exogenous inputs","title":"Using epipredict on non-epidemic panel data","text":"second example, ’ll use arx_forecaster make prediction 5-year median income based using two lags, using two lags two exogenous variables: 2-year median income number graduates. canned forecaster gives us simple way making forecast since defines recipe, workflow, post-processing steps behind scenes. similar model introduced “Autoregressive Linear Model Exogenous Inputs” section article, inputs number lags. changes direct AR forecaster, like changing engine, also work expected. use boosted tree model instead linear regression.","code":"arx_args <- arx_args_list(lags = c(0L, 1L), ahead = 1L)  out_arx_lr <- arx_forecaster(employ_small, \"med_income_5y_prop\",   c(\"med_income_5y_prop\", \"med_income_2y_prop\", \"num_graduates_prop\"),   args_list = arx_args )  out_arx_lr #> ══ A basic forecaster of type ARX Forecaster ═══════════════════════════════════ #>  #> This forecaster was fit on 2024-10-09 20:16:04. #>  #> Training data was an <epi_df> with: #> • Geography: custom, #> • Other keys: age_group and edu_qual, #> • Time type: integer, #> • Using data up-to-date as of: 2022-07-19. #> • With the last data available on 2017 #>  #> ── Predictions ───────────────────────────────────────────────────────────────── #>  #> A total of 166 predictions are available for #> • 11 unique geographic regions, #> • At forecast dates: 2017, #> • For target dates: 2018, #> out_arx_rf <- arx_forecaster(   employ_small, \"med_income_5y_prop\",   c(\"med_income_5y_prop\", \"med_income_2y_prop\", \"num_graduates_prop\"),   trainer = parsnip::boost_tree(mode = \"regression\", trees = 20),   args_list = arx_args )  out_arx_rf #> ══ A basic forecaster of type ARX Forecaster ═══════════════════════════════════ #>  #> This forecaster was fit on 2024-10-09 20:16:05. #>  #> Training data was an <epi_df> with: #> • Geography: custom, #> • Other keys: age_group and edu_qual, #> • Time type: integer, #> • Using data up-to-date as of: 2022-07-19. #> • With the last data available on 2017 #>  #> ── Predictions ───────────────────────────────────────────────────────────────── #>  #> A total of 166 predictions are available for #> • 11 unique geographic regions, #> • At forecast dates: 2017, #> • For target dates: 2018, #>"},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/panel-data.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Using epipredict on non-epidemic panel data","text":"purpose epipredict allow tidymodels operate epidemiology data, can easily adapted (workflows canned forecasters) work generic panel data modelling.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/preprocessing-and-models.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Examples of Preprocessing and Models","text":"epipredict package utilizes tidymodels framework, namely {recipes} dplyr-like pipeable sequences feature engineering {parsnip} unified interface range models. epipredict additional customized feature engineering preprocessing steps, step_epi_lag(), step_population_scaling(), step_epi_naomit(). can used along steps recipes package feature engineering. vignette, illustrate examples use epipredict recipes parsnip different purposes epidemiological forecasting. focus basic autoregressive models, COVID cases deaths near future predicted using linear combination cases deaths near past. remaining vignette split three sections. first section, use Poisson regression predict death counts. second section, use linear regression predict death rates. Last least, create classification model hotspot predictions.","code":"library(tidyr) library(dplyr) library(epidatr) library(epipredict) library(recipes) library(workflows) library(poissonreg)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/preprocessing-and-models.html","id":"poisson-regression","dir":"Articles","previous_headings":"","what":"Poisson Regression","title":"Examples of Preprocessing and Models","text":"COVID-19, US Center Disease Control Prevention (CDC) collected models forecasts characterize state outbreak course. use inform public health decision makers potential consequences deploying control measures. One outcomes CDC forecasts death counts COVID-19. Although many state---art models, choose use Poisson regression, textbook example modeling count data, illustration using epipredict package existing tidymodels packages. counts_subset dataset comes epidatr package, contains number confirmed cases deaths June 4, 2021 Dec 31, 2021 U.S. states. wish predict 7-day ahead death counts lagged cases deaths. Furthermore, let state dummy variable. Using differential intercept coefficients, can allow intercept shift states. μt+7=𝔼(yt+7)\\mu_{t+7} = \\mathbb{E}(y_{t+7}), yt+7y_{t+7} assumed follow Poisson distribution mean μt+7\\mu_{t+7}; sstates_{\\text{state}} dummy variables state take values either 0 1. Preprocessing steps performed prepare data model fitting. diving , helpful understand roles recipes framework.","code":"x <- pub_covidcast(   source = \"jhu-csse\",   signals = \"confirmed_incidence_num\",   time_type = \"day\",   geo_type = \"state\",   time_values = epirange(20210604, 20211231),   geo_values = \"ca,fl,tx,ny,nj\" ) %>%   select(geo_value, time_value, cases = value)  y <- pub_covidcast(   source = \"jhu-csse\",   signals = \"deaths_incidence_num\",   time_type = \"day\",   geo_type = \"state\",   time_values = epirange(20210604, 20211231),   geo_values = \"ca,fl,tx,ny,nj\" ) %>%   select(geo_value, time_value, deaths = value)  counts_subset <- full_join(x, y, by = c(\"geo_value\", \"time_value\")) %>%   as_epi_df()"},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/preprocessing-and-models.html","id":"aside-on-recipes","dir":"Articles","previous_headings":"Poisson Regression","what":"Aside on recipes","title":"Examples of Preprocessing and Models","text":"recipes can assign one roles column data. roles restricted predefined set; can anything. conventional situations, typically “predictor” /“outcome”. Additional roles enable targeted step_*() operations specific variables groups variables. case, role predictor given explanatory variables right-hand side model (equation ). role outcome response variable wish predict. geo_value time_value predefined roles unique epipredict package. Since work epi_df objects, datasets geo_value time_value passed automatically two roles assigned appropriate columns data. recipes package also allows manual alterations roles bulk. handy functions can used together help us manipulate variable roles easily. update_role() alters existing role recipe assigns initial role variables yet declared role. add_role() adds additional role variables already role recipe, without overwriting old roles. remove_role() eliminates single existing role recipe.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/preprocessing-and-models.html","id":"end-aside","dir":"Articles","previous_headings":"Poisson Regression","what":"End aside","title":"Examples of Preprocessing and Models","text":"Notice following preprocessing steps, used add_role() geo_value_factor since, currently, default role raw, like reuse variable predictors. specifying preprocessing steps, use parsnip package modeling producing prediction death count, 7 days latest available date dataset. Note time_value corresponds last available date training set, target date forecast (2022-01-07). Let’s take look fit: now, ’ve used Poisson regression model count data. Poisson regression can also used model rate data, case rates death rates, incorporating offset terms model. log(population)\\log(\\text{population}) log state population used scale count data left-hand side equation. offset simply predictor coefficient fixed 1 rather estimated. several ways model rate data given count population data. First, parsnip framework, specify formula fit(). However, lose ability use recipes framework create new variables since variables exist original dataset (, , lags leads) called directly fit(). Alternatively, step_population_scaling() layer_population_scaling() epipredict package can perform population scaling provide population data, illustrate next section.","code":"counts_subset <- counts_subset %>%   mutate(geo_value_factor = as.factor(geo_value)) %>%   as_epi_df()  epi_recipe(counts_subset) #>  #> ── Epi Recipe ────────────────────────────────────────────────────────────────── #>  #> ── Inputs #> Number of variables by role #> raw:        3 #> geo_value:  1 #> time_value: 1  r <- epi_recipe(counts_subset) %>%   add_role(geo_value_factor, new_role = \"predictor\") %>%   step_dummy(geo_value_factor) %>%   ## Occasionally, data reporting errors / corrections result in negative   ## cases / deaths   step_mutate(cases = pmax(cases, 0), deaths = pmax(deaths, 0)) %>%   step_epi_lag(cases, deaths, lag = c(0, 7)) %>%   step_epi_ahead(deaths, ahead = 7, role = \"outcome\") %>%   step_epi_naomit() latest <- get_test_data(r, counts_subset)  wf <- epi_workflow(r, parsnip::poisson_reg()) %>%   fit(counts_subset)  predict(wf, latest) %>% filter(!is.na(.pred)) #> An `epi_df` object, 5 x 3 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2024-10-09 20:16:11.377878 #>  #> # A tibble: 5 × 3 #>   geo_value time_value .pred #> * <chr>     <date>     <dbl> #> 1 ca        2021-12-31 108.  #> 2 fl        2021-12-31 270.  #> 3 nj        2021-12-31  22.5 #> 4 ny        2021-12-31  94.8 #> 5 tx        2021-12-31  91.0 extract_fit_engine(wf) #>  #> Call:  stats::glm(formula = ..y ~ ., family = stats::poisson, data = data) #>  #> Coefficients: #>         (Intercept)  geo_value_factor_fl  geo_value_factor_nj   #>           3.970e+00           -1.487e-01           -1.425e+00   #> geo_value_factor_ny  geo_value_factor_tx          lag_0_cases   #>          -6.865e-01            3.025e-01            1.339e-05   #>         lag_7_cases         lag_0_deaths         lag_7_deaths   #>           1.717e-06            1.731e-03            8.566e-04   #>  #> Degrees of Freedom: 984 Total (i.e. Null);  976 Residual #> Null Deviance:       139600  #> Residual Deviance: 58110     AIC: 62710"},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/preprocessing-and-models.html","id":"linear-regression","dir":"Articles","previous_headings":"","what":"Linear Regression","title":"Examples of Preprocessing and Models","text":"COVID-19, CDC required submission case death count predictions. However, Delphi Group preferred train rate data instead, puts different locations similar scale (eliminating need location-specific intercepts). can use liner regression predict death rates use state population data scale rates counts.1 using layer_population_scaling() epipredict package. Additionally, forecasts submitted, prediction intervals provided along point estimates. can obtained via postprocessing using layer_residual_quantiles(). worth pointing , however, layer_residual_quantiles() used population scaling else transformation make results uninterpretable. wish, now, predict 7-day ahead death counts lagged case rates death rates, along extra behaviourial predictors. Namely, use survey data COVID-19 Trends Impact Survey. survey data provides estimated percentage people wore mask time public past 7 days estimated percentage respondents reported people encountered public past 7 days maintained distance least 6 feet. State-wise population data 2019 U.S. Census included package used layer_population_scaling(). Rather using raw mask-wearing / social-distancing metrics, sake illustration, ’ll convert categorical predictors.  take subset death rate case rate data built-dataset case_death_rate_subset. Preprocessing steps rely functions epipredict package well recipes package. also many functions recipes package allow scalar transformations, log transformations data centering. case, center numerical predictors allow meaningful interpretation intercept. sanity check can examine structure training data: directly predicting results, need add postprocessing layers obtain death counts instead death rates. Note rates used far “per 100K people” rather “per person”. ’ll also use quantile regression quantile_reg engine rather ordinary least squares create median predictions 90% prediction interval. columns marked *_scaled rescaled correct units, case deaths rather deaths per 100K people (remain .pred). look prediction intervals: Last least, let’s take look regression fit check coefficients:","code":"behav_ind_mask <- pub_covidcast(   source = \"fb-survey\",   signals = \"smoothed_wwearing_mask_7d\",   time_type = \"day\",   geo_type = \"state\",   time_values = epirange(20210604, 20211231),   geo_values = \"ca,fl,tx,ny,nj\" ) %>%   select(geo_value, time_value, masking = value)  behav_ind_distancing <- pub_covidcast(   source = \"fb-survey\",   signals = \"smoothed_wothers_distanced_public\",   time_type = \"day\",   geo_type = \"state\",   time_values = epirange(20210604, 20211231),   geo_values = \"ca,fl,tx,ny,nj\" ) %>%   select(geo_value, time_value, distancing = value)  pop_dat <- state_census %>% select(abbr, pop)  behav_ind <- behav_ind_mask %>%   full_join(behav_ind_distancing, by = c(\"geo_value\", \"time_value\")) jhu <- filter(   case_death_rate_subset,   time_value >= \"2021-06-04\",   time_value <= \"2021-12-31\",   geo_value %in% c(\"ca\", \"fl\", \"tx\", \"ny\", \"nj\") ) jhu <- jhu %>%   mutate(geo_value_factor = as.factor(geo_value)) %>%   left_join(behav_ind, by = c(\"geo_value\", \"time_value\")) %>%   as_epi_df()  r <- epi_recipe(jhu) %>%   add_role(geo_value_factor, new_role = \"predictor\") %>%   step_dummy(geo_value_factor) %>%   step_epi_lag(case_rate, death_rate, lag = c(0, 7, 14)) %>%   step_mutate(     masking = cut_number(masking, 5),     distancing = cut_number(distancing, 5)   ) %>%   step_epi_ahead(death_rate, ahead = 7, role = \"outcome\") %>%   step_center(contains(\"lag\"), role = \"predictor\") %>%   step_epi_naomit() glimpse(slice_sample(bake(prep(r, jhu), jhu), n = 6)) #> Rows: 6 #> Columns: 17 #> $ geo_value           <chr> \"ny\", \"ca\", \"ca\", \"nj\", \"ca\", \"tx\" #> $ time_value          <date> 2021-10-16, 2021-11-24, 2021-11-28, 2021-12-03, 20… #> $ case_rate           <dbl> 23.910028, 11.695843, 10.649673, 34.521027, 32.50… #> $ death_rate          <dbl> 0.1935616, 0.2514728, 0.1589395, 0.1736988, -0.041… #> $ masking             <fct> NA, NA, NA, NA, NA, NA #> $ distancing          <fct> NA, NA, NA, NA, NA, NA #> $ geo_value_factor_fl <dbl> 0, 0, 0, 0, 0, 0 #> $ geo_value_factor_nj <dbl> 0, 0, 0, 1, 0, 0 #> $ geo_value_factor_ny <dbl> 1, 0, 0, 0, 0, 0 #> $ geo_value_factor_tx <dbl> 0, 0, 0, 0, 0, 1 #> $ lag_0_case_rate     <dbl> -3.031634, -15.245820, -16.291990, 7.579365, 5.560… #> $ lag_7_case_rate     <dbl> -1.452113, -13.677834, -13.883585, -2.516074, 2.70… #> $ lag_14_case_rate    <dbl> -1.970740, -11.431271, -12.990548, -5.872642, -2.0… #> $ lag_0_death_rate    <dbl> -0.0883120, -0.0304008, -0.1229341, -0.1081748, -0… #> $ lag_7_death_rate    <dbl> -0.1053041, -0.0833807, -0.0587051, -0.1483829, -0… #> $ lag_14_death_rate   <dbl> -0.0580218, -0.0721315, -0.0663255, -0.1355163, -0… #> $ ahead_7_death_rate  <dbl> 0.1950392, 0.1730917, 0.2315146, 0.1753071, 0.1767… f <- frosting() %>%   layer_predict() %>%   layer_add_target_date(\"2022-01-07\") %>%   layer_threshold(.pred, lower = 0) %>%   layer_quantile_distn() %>%   layer_naomit(.pred) %>%   layer_population_scaling(     .pred, .pred_distn,     df = pop_dat,     rate_rescaling = 1e5,     by = c(\"geo_value\" = \"abbr\"),     df_pop_col = \"pop\"   )  wf <- epi_workflow(r, quantile_reg(quantile_levels = c(.05, .5, .95))) %>%   fit(jhu) %>%   add_frosting(f)  p <- forecast(wf) p #> An `epi_df` object, 5 x 7 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-31 19:08:25.791826 #>  #> # A tibble: 5 × 7 #>   geo_value time_value              .pred target_date        .pred_distn #> * <chr>     <date>                 <dist> <date>                  <dist> #> 1 ca        2021-12-31 quantiles(0.18)[3] 2022-01-07  quantiles(0.18)[2] #> 2 fl        2021-12-31 quantiles(0.35)[3] 2022-01-07  quantiles(0.36)[2] #> 3 nj        2021-12-31 quantiles(0.65)[3] 2022-01-07  quantiles(0.64)[2] #> 4 ny        2021-12-31  quantiles(0.7)[3] 2022-01-07  quantiles(0.69)[2] #> 5 tx        2021-12-31  quantiles(0.3)[3] 2022-01-07   quantiles(0.3)[2] #> # ℹ 2 more variables: .pred_scaled <dist>, .pred_distn_scaled <dist> p %>%   select(geo_value, target_date, .pred_scaled, .pred_distn_scaled) %>%   pivot_quantiles_wider(.pred_distn_scaled) #> # A tibble: 5 × 5 #>   geo_value target_date         .pred_scaled `0.25` `0.75` #>   <chr>     <date>                    <dist>  <dbl>  <dbl> #> 1 ca        2022-01-07   quantiles(71.61)[3]   48.8   94.0 #> 2 fl        2022-01-07    quantiles(74.7)[3]   48.4  104.  #> 3 nj        2022-01-07    quantiles(57.4)[3]   45.5   68.7 #> 4 ny        2022-01-07  quantiles(135.85)[3]  108.   163.  #> 5 tx        2022-01-07   quantiles(86.77)[3]   68.6  107. #> Call: #> quantreg::rq(formula = ..y ~ ., tau = ~c(0.05, 0.5, 0.95), data = data,  #>     na.action = stats::na.omit, method = ~\"br\", model = FALSE) #>  #> Coefficients: #>                        tau= 0.05     tau= 0.50    tau= 0.95 #> (Intercept)          0.210811625  0.2962574475  0.417583265 #> geo_value_factor_fl  0.032085820  0.0482361119  0.171126713 #> geo_value_factor_nj  0.007313762 -0.0033797953 -0.025251865 #> geo_value_factor_ny -0.001489163 -0.0199485947 -0.032635584 #> geo_value_factor_tx  0.029077485  0.0391980273  0.071961515 #> lag_0_case_rate     -0.001636588 -0.0011625693 -0.001430622 #> lag_7_case_rate      0.004700752  0.0057822095  0.006912655 #> lag_14_case_rate     0.001715816  0.0004224753  0.003448733 #> lag_0_death_rate     0.462341754  0.5274192012  0.164856372 #> lag_7_death_rate    -0.007368501  0.1132903956  0.172687438 #> lag_14_death_rate   -0.072500707 -0.0270474349  0.181279299 #>  #> Degrees of freedom: 950 total; 939 residual"},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/preprocessing-and-models.html","id":"classification","dir":"Articles","previous_headings":"","what":"Classification","title":"Examples of Preprocessing and Models","text":"Sometimes preferable create predictive model surges upswings rather raw values. case, target predict future increased case rates (denoted ), decreased case rates (), flat case rates (flat) relative current level. models may referred “hotspot prediction models”. follow analysis McDonald, Bien, Green, Hu, et al. extend application predict three categories instead two. Hotspot prediction uses categorical outcome variable defined terms relative change Yℓ,t+aY_{\\ell, t+} compared Yℓ,tY_{\\ell, t}. Yℓ,tY_{\\ell, t} denotes case rates location ℓ\\ell time tt. define response variables follows: Zℓ,t={,ifYℓ,tΔ>0.25down,ifYℓ,tΔ<−0.20flat,otherwise  Z_{\\ell, t}=     \\begin{cases}       \\text{}, & \\text{}\\ Y^{\\Delta}_{\\ell, t} > 0.25 \\\\       \\text{}, & \\text{}\\  Y^{\\Delta}_{\\ell, t} < -0.20\\\\       \\text{flat}, & \\text{otherwise}     \\end{cases} Yℓ,tΔ=(Yℓ,t−Yℓ,t−7)/(Yℓ,t−7)Y^{\\Delta}_{\\ell, t} = (Y_{\\ell, t}- Y_{\\ell, t-7})\\ /\\ (Y_{\\ell, t-7}). say location ℓ\\ell hotspot time tt Zℓ,tZ_{\\ell,t} , meaning number newly reported cases past 7 days increased least 25% compared preceding week. Zℓ,tZ_{\\ell,t} categorized , suggests least 20% decrease newly reported cases past 7 days (20% decrease inverse 25% increase). Otherwise, consider trend flat. expression multinomial regression use follows: πj(x)=Pr(Zℓ,t=j|x)=egj(x)1+∑k=12egk(x) \\pi_{j}(x) = \\text{Pr}(Z_{\\ell,t} = j|x) = \\frac{e^{g_j(x)}}{1 + \\sum_{k=1}^{2}e^{g_k(x)} } jj either , flat, Preprocessing steps similar previous models additional step categorizing response variables. , use subset death rate case rate data built-dataset case_death_rate_subset. fit multinomial regression examine predictions: can also look estimated coefficients model summary information: One also use formula epi_recipe() achieve results . However, one add_formula(), add_recipe(), workflow_variables() can specified. purpose demonstrating add_formula rather add_recipe, prep bake recipe return data.frame used model fitting.","code":"jhu <- case_death_rate_subset %>%   dplyr::filter(     time_value >= \"2021-06-04\",     time_value <= \"2021-12-31\",     geo_value %in% c(\"ca\", \"fl\", \"tx\", \"ny\", \"nj\")   ) %>%   mutate(geo_value_factor = as.factor(geo_value))  r <- epi_recipe(jhu) %>%   add_role(time_value, new_role = \"predictor\") %>%   step_dummy(geo_value_factor) %>%   step_growth_rate(case_rate, role = \"none\", prefix = \"gr_\") %>%   step_epi_lag(starts_with(\"gr_\"), lag = c(0, 7, 14)) %>%   step_epi_ahead(starts_with(\"gr_\"), ahead = 7, role = \"none\") %>%   # note recipes::step_cut() has a bug in it, or we could use that here   step_mutate(     response = cut(       ahead_7_gr_7_rel_change_case_rate,       breaks = c(-Inf, -0.2, 0.25, Inf) / 7, # division gives weekly not daily       labels = c(\"down\", \"flat\", \"up\")     ),     role = \"outcome\"   ) %>%   step_rm(has_role(\"none\"), has_role(\"raw\")) %>%   step_epi_naomit() wf <- epi_workflow(r, multinom_reg()) %>%   fit(jhu)  forecast(wf) %>% filter(!is.na(.pred_class)) #> An `epi_df` object, 5 x 3 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-31 19:08:25.791826 #>  #> # A tibble: 5 × 3 #>   geo_value time_value .pred_class #> * <chr>     <date>     <fct>       #> 1 ca        2021-12-31 up          #> 2 fl        2021-12-31 up          #> 3 nj        2021-12-31 up          #> 4 ny        2021-12-31 up          #> 5 tx        2021-12-31 up extract_fit_engine(wf) #> Call: #> nnet::multinom(formula = ..y ~ ., data = data, trace = FALSE) #>  #> Coefficients: #>      (Intercept)  time_value geo_value_factor_fl geo_value_factor_nj #> flat   -144.2225 0.007754541          -1.3251323            1.137559 #> up     -133.1994 0.007082196          -0.5081303            1.562700 #>      geo_value_factor_ny geo_value_factor_tx lag_0_gr_7_rel_change_case_rate #> flat            24.74419          -0.3345776                        18.96354 #> up              24.84975          -0.3176996                        33.79518 #>      lag_7_gr_7_rel_change_case_rate lag_14_gr_7_rel_change_case_rate #> flat                        33.19049                         7.157042 #> up                          56.52374                         4.684437 #>  #> Residual Deviance: 1157.928  #> AIC: 1193.928 b <- bake(prep(r, jhu), jhu)  epi_workflow() %>%   add_formula(     response ~ geo_value + time_value + lag_0_gr_7_rel_change_case_rate +       lag_7_gr_7_rel_change_case_rate + lag_14_gr_7_rel_change_case_rate   ) %>%   add_model(parsnip::multinom_reg()) %>%   fit(data = b) #>  #> ══ Epi Workflow [trained] ══════════════════════════════════════════════════════ #> Preprocessor: Formula #> Model: multinom_reg() #> Postprocessor: None #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #>  #> response ~ geo_value + time_value + lag_0_gr_7_rel_change_case_rate + #> lag_7_gr_7_rel_change_case_rate + lag_14_gr_7_rel_change_case_rate #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #> Call: #> nnet::multinom(formula = ..y ~ ., data = data, trace = FALSE) #>  #> Coefficients: #>      (Intercept) geo_valuefl geo_valuenj geo_valueny geo_valuetx  time_value #> flat   -144.2169  -1.3265549    1.133934    24.75059  -0.3335115 0.007754345 #> up     -133.3502  -0.5120186    1.559702    24.85665  -0.3158343 0.007090249 #>      lag_0_gr_7_rel_change_case_rate lag_7_gr_7_rel_change_case_rate #> flat                        19.02252                        33.20794 #> up                          33.84660                        56.57061 #>      lag_14_gr_7_rel_change_case_rate #> flat                         7.140372 #> up                           4.668915 #>  #> Residual Deviance: 1157.919  #> AIC: 1193.919 #>"},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/preprocessing-and-models.html","id":"benefits-of-lagging-and-leading-in-epipredict","dir":"Articles","previous_headings":"","what":"Benefits of Lagging and Leading in epipredict","title":"Examples of Preprocessing and Models","text":"step_epi_ahead step_epi_lag functions epipredict package handy creating correct lags leads future predictions. Let’s start simple dataset preprocessing: want predict death rates 2022-01-07, 7 days ahead latest available date dataset. compare two methods trying create lags leads: Notice difference number rows b1 b2 returns. second version, one doesn’t use step_epi_ahead step_epi_lag, omitted dates compared one used epipredict functions. model trained based recipes functions predict 7 days ahead 2021-12-24 instead 7 days ahead 2021-12-31.","code":"ex <- filter(   case_death_rate_subset,   time_value >= \"2021-12-01\",   time_value <= \"2021-12-31\",   geo_value == \"ca\" )  dim(ex) #> [1] 31  4 p1 <- epi_recipe(ex) %>%   step_epi_lag(case_rate, lag = c(0, 7, 14)) %>%   step_epi_lag(death_rate, lag = c(0, 7, 14)) %>%   step_epi_ahead(death_rate, ahead = 7, role = \"outcome\") %>%   step_epi_naomit() %>%   prep(ex)  b1 <- bake(p1, ex) b1 #> An `epi_df` object, 17 x 11 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-31 19:08:25.791826 #>  #> # A tibble: 17 × 11 #>    geo_value time_value case_rate death_rate lag_0_case_rate lag_7_case_rate #>  * <chr>     <date>         <dbl>      <dbl>           <dbl>           <dbl> #>  1 ca        2021-12-15      15.8      0.157            15.8            18.0 #>  2 ca        2021-12-16      16.3      0.155            16.3            17.4 #>  3 ca        2021-12-17      16.9      0.158            16.9            17.4 #>  4 ca        2021-12-18      17.6      0.164            17.6            17.2 #>  5 ca        2021-12-19      19.1      0.165            19.1            16.3 #>  6 ca        2021-12-20      20.6      0.164            20.6            16.0 #>  7 ca        2021-12-21      22.6      0.165            22.6            16.6 #>  8 ca        2021-12-22      26.2      0.163            26.2            15.8 #>  9 ca        2021-12-23      30.8      0.167            30.8            16.3 #> 10 ca        2021-12-24      33.8      0.167            33.8            16.9 #> 11 ca        2021-12-25      32.6      0.153            32.6            17.6 #> 12 ca        2021-12-26      34.5      0.153            34.5            19.1 #> 13 ca        2021-12-27      48.4      0.132            48.4            20.6 #> 14 ca        2021-12-28      54.9      0.142            54.9            22.6 #> 15 ca        2021-12-29      63.7      0.140            63.7            26.2 #> 16 ca        2021-12-30      76.0      0.140            76.0            30.8 #> 17 ca        2021-12-31      84.4      0.142            84.4            33.8 #> # ℹ 5 more variables: lag_14_case_rate <dbl>, lag_0_death_rate <dbl>, #> #   lag_7_death_rate <dbl>, lag_14_death_rate <dbl>, ahead_7_death_rate <dbl>   p2 <- epi_recipe(ex) %>%   step_mutate(     lag0case_rate = lag(case_rate, 0),     lag7case_rate = lag(case_rate, 7),     lag14case_rate = lag(case_rate, 14),     lag0death_rate = lag(death_rate, 0),     lag7death_rate = lag(death_rate, 7),     lag14death_rate = lag(death_rate, 14),     ahead7death_rate = lead(death_rate, 7)   ) %>%   step_epi_naomit() %>%   prep(ex)  b2 <- bake(p2, ex) b2 #> An `epi_df` object, 10 x 11 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-31 19:08:25.791826 #>  #> # A tibble: 10 × 11 #>    geo_value time_value case_rate death_rate lag0case_rate lag7case_rate #>  * <chr>     <date>         <dbl>      <dbl>         <dbl>         <dbl> #>  1 ca        2021-12-15      15.8      0.157          15.8          18.0 #>  2 ca        2021-12-16      16.3      0.155          16.3          17.4 #>  3 ca        2021-12-17      16.9      0.158          16.9          17.4 #>  4 ca        2021-12-18      17.6      0.164          17.6          17.2 #>  5 ca        2021-12-19      19.1      0.165          19.1          16.3 #>  6 ca        2021-12-20      20.6      0.164          20.6          16.0 #>  7 ca        2021-12-21      22.6      0.165          22.6          16.6 #>  8 ca        2021-12-22      26.2      0.163          26.2          15.8 #>  9 ca        2021-12-23      30.8      0.167          30.8          16.3 #> 10 ca        2021-12-24      33.8      0.167          33.8          16.9 #> # ℹ 5 more variables: lag14case_rate <dbl>, lag0death_rate <dbl>, #> #   lag7death_rate <dbl>, lag14death_rate <dbl>, ahead7death_rate <dbl> dates_used_in_training1 <- b1 %>%   select(-ahead_7_death_rate) %>%   na.omit() %>%   pull(time_value) dates_used_in_training1 #>  [1] \"2021-12-15\" \"2021-12-16\" \"2021-12-17\" \"2021-12-18\" \"2021-12-19\" #>  [6] \"2021-12-20\" \"2021-12-21\" \"2021-12-22\" \"2021-12-23\" \"2021-12-24\" #> [11] \"2021-12-25\" \"2021-12-26\" \"2021-12-27\" \"2021-12-28\" \"2021-12-29\" #> [16] \"2021-12-30\" \"2021-12-31\"  dates_used_in_training2 <- b2 %>%   select(-ahead7death_rate) %>%   na.omit() %>%   pull(time_value) dates_used_in_training2 #>  [1] \"2021-12-15\" \"2021-12-16\" \"2021-12-17\" \"2021-12-18\" \"2021-12-19\" #>  [6] \"2021-12-20\" \"2021-12-21\" \"2021-12-22\" \"2021-12-23\" \"2021-12-24\""},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/preprocessing-and-models.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Examples of Preprocessing and Models","text":"McDonald, Bien, Green, Hu, et al. “Can auxiliary indicators improve COVID-19 forecasting hotspot prediction?.” Proceedings National Academy Sciences 118.51 (2021): e2111453118. doi:10.1073/pnas.2111453118","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/preprocessing-and-models.html","id":"attribution","dir":"Articles","previous_headings":"","what":"Attribution","title":"Examples of Preprocessing and Models","text":"object contains modified part COVID-19 Data Repository Center Systems Science Engineering (CSSE) Johns Hopkins University republished COVIDcast Epidata API. data set licensed terms Creative Commons Attribution 4.0 International license Johns Hopkins University behalf Center Systems Science Engineering. Copyright Johns Hopkins University 2020.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/sliding.html","id":"demonstrations-of-sliding-ar-and-arx-forecasters","dir":"Articles","previous_headings":"","what":"Demonstrations of sliding AR and ARX forecasters","title":"Demonstrations of sliding AR and ARX forecasters","text":"key function epiprocess package epix_slide() (refer following vignette basics function: “Work archive objects data revisions”) allows performing version-aware computations. , function uses data available time t reference time. vignette, use epix_slide() backtesting arx_forecaster historical COVID-19 case data US Canada. first examine results version-unaware forecaster, comparing two different fitting engines contrast version-aware forecasting. former proceed constructing epi_archive erases version information use epix_slide() forecast future. latter keep versioned data proceed similarly using epix_slide() forecast future.","code":""},{"path":[]},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/sliding.html","id":"example-using-cli-and-case-data-from-us-states","dir":"Articles","previous_headings":"Demonstrations of sliding AR and ARX forecasters > Comparing different forecasting engines","what":"Example using CLI and case data from US states","title":"Demonstrations of sliding AR and ARX forecasters","text":"First, download version history (ie. archive) percentage doctor’s visits CLI (COVID-like illness) computed medical insurance claims number new confirmed COVID-19 cases per 100,000 population (daily) 50 states COVIDcast API. process , modification use sync = locf epix_merge() last version observation can carried forward extrapolate unavailable versions less --date input archive. obtaining latest snapshot data proceed fake version information setting version = time_value. effect obtaining data arrives exactly day time_value. , arx_forecaster() heavy lifting. creates leads target (respecting time stamps locations) along lags features (, response doctors visits), estimates forecasting model using specified engine, creates predictions, non-parametric confidence bands. see predictions compare, plot top latest case rates. Note even though ’ve fitted model states, ’ll just display results two states, California (CA) Florida (FL), get sense model performance keeping graphic simple.  two states interest, simple linear regression clearly performs better random forest terms accuracy predictions result overconfident predictions (overly narrow confidence bands). Though, general, neither approach produces amazingly accurate forecasts. behaviour rather different across states effects notable factors age public health measures may important account forecasting. Including factors well making enhancements correcting outliers improvements one make simple model.1","code":"theme_set(theme_bw())  y <- readRDS(\"all_states_covidcast_signals.rds\") %>%   purrr::map(~ select(.x, geo_value, time_value, version = issue, value))  x <- epix_merge(   y[[1]] %>% rename(percent_cli = value) %>% as_epi_archive(compactify = FALSE),   y[[2]] %>% rename(case_rate = value) %>% as_epi_archive(compactify = FALSE),   sync = \"locf\",   compactify = TRUE ) rm(y) # Latest snapshot of data, and forecast dates x_latest <- epix_as_of(x, version = max(x$versions_end)) %>%   mutate(version = time_value) %>%   as_epi_archive() fc_time_values <- seq(   from = as.Date(\"2020-08-01\"),   to = as.Date(\"2021-11-01\"),   by = \"1 month\" ) aheads <- c(7, 14, 21, 28)  forecast_k_week_ahead <- function(epi_archive, outcome, predictors, ahead = 7, engine) {   epi_archive %>%     epix_slide(       .f = function(x, gk, rtv) {         arx_forecaster(           x, outcome, predictors, engine,           args_list = arx_args_list(ahead = ahead)         )$predictions %>%           mutate(engine_type = engine$engine) %>%           pivot_quantiles_wider(.pred_distn)       },       .before = 120,       .versions = fc_time_values     ) } # Generate the forecasts and bind them together fc <- bind_rows(   map(aheads, ~ forecast_k_week_ahead(     x_latest,     outcome = \"case_rate\",     predictors = c(\"case_rate\", \"percent_cli\"),     ahead = .x,     engine = linear_reg()   )),   map(aheads, ~ forecast_k_week_ahead(     x_latest,     outcome = \"case_rate\",     predictors = c(\"case_rate\", \"percent_cli\"),     ahead = .x,     engine = rand_forest(mode = \"regression\")   )) ) fc_cafl <- fc %>%   tibble() %>%   filter(geo_value %in% c(\"ca\", \"fl\")) x_latest_cafl <- x_latest$DT %>%   tibble() %>%   filter(geo_value %in% c(\"ca\", \"fl\"))  p1 <- ggplot(fc_cafl, aes(target_date, group = forecast_date, fill = engine_type)) +   geom_line(     data = x_latest_cafl, aes(x = time_value, y = case_rate),     inherit.aes = FALSE, color = \"gray50\"   ) +   geom_ribbon(aes(ymin = `0.05`, ymax = `0.95`), alpha = 0.4) +   geom_line(aes(y = .pred)) +   geom_point(aes(y = .pred), size = 0.5) +   geom_vline(aes(xintercept = forecast_date), linetype = 2, alpha = 0.5) +   facet_grid(vars(geo_value), vars(engine_type), scales = \"free\") +   scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +   scale_fill_brewer(palette = \"Set1\") +   labs(x = \"Date\", y = \"Reported COVID-19 case rates\") +   theme(legend.position = \"none\")"},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/sliding.html","id":"example-using-case-data-from-canada","dir":"Articles","previous_headings":"Demonstrations of sliding AR and ARX forecasters > Comparing different forecasting engines","what":"Example using case data from Canada","title":"Demonstrations of sliding AR and ARX forecasters","text":"leveraging flexibility epiprocess, can apply techniques data sources. Since collaborators British Columbia, Canada, ’ll essentially thing Canada . COVID-19 Canada Open Data Working Group collects daily time series data COVID-19 cases, deaths, recoveries, testing vaccinations health region province levels. Data collected publicly available sources government datasets news releases. Unfortunately, simple versioned source, created Github commit history. First, load versioned case rates provincial level. converting 7-day averages (due highly variable provincial reporting mismatches), convert data epi_archive object, extract latest version . Finally, run forcasting exercise American data, compare forecasts produced using simple linear regression using boosted regression trees. figures shows results provinces.   approaches tend produce quite volatile forecasts (point predictions) /overly confident (narrow bands), particularly boosted regression trees used. meant simple demonstration sliding different engines arx_forecaster, may devote another vignette work improving predictive modelling using suite tools available epipredict.","code":"# source(\"drafts/canada-case-rates.R) can <- readRDS(system.file(   \"extdata\", \"can_prov_cases.rds\",   package = \"epipredict\", mustWork = TRUE )) %>%   group_by(version, geo_value) %>%   arrange(time_value) %>%   mutate(cr_7dav = RcppRoll::roll_meanr(case_rate, n = 7L)) %>%   as_epi_archive(compactify = TRUE)  can_latest <- epix_as_of(can, version = max(can$DT$version)) %>%   mutate(version = time_value) %>%   as_epi_archive()  # Generate the forecasts, and bind them together can_fc <- bind_rows(   map(     aheads,     ~ forecast_k_week_ahead(can_latest, \"cr_7dav\", \"cr_7dav\", .x, linear_reg())   ),   map(     aheads,     ~ forecast_k_week_ahead(       can_latest, \"cr_7dav\", \"cr_7dav\", .x,       boost_tree(mode = \"regression\", trees = 20)     )   ) ) ggplot(   can_fc %>% filter(engine_type == \"lm\"),   aes(x = target_date, group = forecast_date) ) +   coord_cartesian(xlim = lubridate::ymd(c(\"2020-12-01\", NA))) +   geom_line(     data = can_latest$DT %>% tibble(), aes(x = time_value, y = cr_7dav),     inherit.aes = FALSE, color = \"gray50\"   ) +   geom_ribbon(aes(ymin = `0.05`, ymax = `0.95`, fill = geo_value),     alpha = 0.4   ) +   geom_line(aes(y = .pred)) +   geom_point(aes(y = .pred), size = 0.5) +   geom_vline(aes(xintercept = forecast_date), linetype = 2, alpha = 0.5) +   facet_wrap(~geo_value, scales = \"free_y\", ncol = 3) +   scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +   labs(     title = \"Using simple linear regression\", x = \"Date\",     y = \"Reported COVID-19 case rates\"   ) +   theme(legend.position = \"none\") ggplot(   can_fc %>% filter(engine_type == \"xgboost\"),   aes(x = target_date, group = forecast_date) ) +   coord_cartesian(xlim = lubridate::ymd(c(\"2020-12-01\", NA))) +   geom_line(     data = can_latest$DT %>% tibble(), aes(x = time_value, y = cr_7dav),     inherit.aes = FALSE, color = \"gray50\"   ) +   geom_ribbon(aes(ymin = `0.05`, ymax = `0.95`, fill = geo_value),     alpha = 0.4   ) +   geom_line(aes(y = .pred)) +   geom_point(aes(y = .pred), size = 0.5) +   geom_vline(aes(xintercept = forecast_date), linetype = 2, alpha = 0.5) +   facet_wrap(~geo_value, scales = \"free_y\", ncol = 3) +   scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +   labs(     title = \"Using boosted regression trees\", x = \"Date\",     y = \"Reported COVID-19 case rates\"   ) +   theme(legend.position = \"none\")"},{"path":[]},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/sliding.html","id":"example-using-case-data-from-us-states","dir":"Articles","previous_headings":"Demonstrations of sliding AR and ARX forecasters > Version-aware forecasting","what":"Example using case data from US states","title":"Demonstrations of sliding AR and ARX forecasters","text":"now employ forecaster uses properly-versioned data (available real-time) forecast 7 day average future COVID-19 case rates current past COVID-19 case rates death rates states. , can make forecasts archive, x, compare forecasts latest data, x_latest using general set-. Note example, use geo-pooled approach (using combined data US states territories) train model. specify ARX model. can now use forecaster function ’ve created use pipeline forecasting predictions. store predictions arx_preds variable calculate date version data epi archive store x_latest. Now plot actual predicted 7 day average death rate chosen states","code":"# loading in the data states <- \"*\"  confirmed_incidence_prop <- pub_covidcast(   source = \"jhu-csse\",   signals = \"confirmed_incidence_prop\",   time_type = \"day\",   geo_type = \"state\",   time_values = epirange(20200301, 20211231),   geo_values = states,   issues = epirange(20000101, 20221231) ) %>%   select(geo_value, time_value, version = issue, case_rate = value) %>%   arrange(geo_value, time_value) %>%   as_epi_archive(compactify = FALSE)  deaths_incidence_prop <- pub_covidcast(   source = \"jhu-csse\",   signals = \"deaths_incidence_prop\",   time_type = \"day\",   geo_type = \"state\",   time_values = epirange(20200301, 20211231),   geo_values = states,   issues = epirange(20000101, 20221231) ) %>%   select(geo_value, time_value, version = issue, death_rate = value) %>%   arrange(geo_value, time_value) %>%   as_epi_archive(compactify = FALSE)   x <- epix_merge(confirmed_incidence_prop, deaths_incidence_prop, sync = \"locf\")  x <- x %>%   epix_slide(     .versions = fc_time_values,     function(x, gk, rtv) {       x %>%         group_by(geo_value) %>%         epi_slide_mean(case_rate, .window_size = 7L) %>%         rename(case_rate_7d_av = slide_value_case_rate) %>%         epi_slide_mean(death_rate, ..window_size = 7L) %>%         rename(death_rate_7d_av = slide_value_death_rate) %>%         ungroup()     }   ) %>%   rename(version = time_value) %>%   rename(     time_value = slide_value_time_value,     geo_value = slide_value_geo_value,     case_rate = slide_value_case_rate,     death_rate = slide_value_death_rate,     case_rate_7d_av = slide_value_case_rate_7d_av,     death_rate_7d_av = slide_value_death_rate_7d_av   ) %>%   as_epi_archive(compactify = TRUE)  saveRDS(x$DT, file = \"case_death_rate_archive.rds\") x <- readRDS(\"case_death_rate_archive.rds\") x <- as_epi_archive(x) aheads <- c(7, 14, 21) fc_time_values <- seq(   from = as.Date(\"2020-09-01\"),   to = as.Date(\"2021-12-31\"),   by = \"1 month\" ) forecaster <- function(x) {   map(aheads, function(ahead) {     arx_forecaster(       epi_data = x,       outcome = \"death_rate_7d_av\",       predictors = c(\"death_rate_7d_av\", \"case_rate_7d_av\"),       trainer = quantile_reg(),       args_list = arx_args_list(lags = c(0, 7, 14, 21), ahead = ahead)     )$predictions   }) %>%     bind_rows() } arx_preds <- x %>%   epix_slide(     ~ forecaster(.x),     .before = 120, .versions = fc_time_values   ) %>%   mutate(engine_type = quantile_reg()$engine) %>%   mutate(ahead_val = target_date - forecast_date)  x_latest <- epix_as_of(x, version = max(x$versions_end)) states_to_show <- c(\"ca\", \"ny\", \"mi\", \"az\") fc_states <- arx_preds %>%   filter(geo_value %in% states_to_show) %>%   pivot_quantiles_wider(.pred_distn)  x_latest_states <- x_latest %>% filter(geo_value %in% states_to_show)  p2 <- ggplot(fc_states, aes(target_date, group = forecast_date)) +   geom_ribbon(aes(ymin = `0.05`, ymax = `0.95`, fill = geo_value), alpha = 0.4) +   geom_line(     data = x_latest_states, aes(x = time_value, y = death_rate_7d_av),     inherit.aes = FALSE, color = \"gray50\"   ) +   geom_line(aes(y = .pred, color = geo_value)) +   geom_point(aes(y = .pred, color = geo_value), size = 0.5) +   geom_vline(aes(xintercept = forecast_date), linetype = 2, alpha = 0.5) +   facet_wrap(~geo_value, scales = \"free_y\", ncol = 1L) +   scale_x_date(minor_breaks = \"month\", date_labels = \"%b %y\") +   scale_fill_brewer(palette = \"Set1\") +   scale_color_brewer(palette = \"Set1\") +   labs(x = \"Date\", y = \"7 day average COVID-19 death rates\") +   theme(legend.position = \"none\")"},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/smooth-qr.html","id":"introducing-smooth-quantile-regression","dir":"Articles","previous_headings":"","what":"Introducing smooth quantile regression","title":"Smooth quantile regression","text":"Whereas time-series forecasting examples package used (direct) models single horizons, multi-period forecasting, goal (directly) forecast several horizons simultaneously. useful epidemiological applications decisions based trend signal. idea underlying smooth quantile regression set forecast targets can approximated smooth curve. novel approach Tuzhilina et al., 2022 enforces smoothness across horizons can applied point estimation regression interval prediction quantile regression. focus vignette latter.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/smooth-qr.html","id":"built-in-function-for-smooth-quantile-regression-and-its-parameters","dir":"Articles","previous_headings":"","what":"Built-in function for smooth quantile regression and its parameters","title":"Smooth quantile regression","text":"built-smooth quantile regression function, smooth_quantile_reg() provides model specification smooth quantile regression works tidymodels framework. following parameters default values: smooth quantile regression, type model mode regression. engine currently supported smooth_qr() smoothqr package. outcome_locations indicate multiple horizon (ie. ahead) values. specified user. quantile_levels parameter vector values indicates quantiles estimated. default median (0.5 quantile). degree parameter indicates degree polynomials used smoothing response. number aheads. degree precisely equal number aheads, smoothing. better understand parameter works, look origins used model.","code":"smooth_quantile_reg(   mode = \"regression\",   engine = \"smoothqr\",   outcome_locations = NULL,   quantile_levels = 0.5,   degree = 3L )"},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/smooth-qr.html","id":"model-form","dir":"Articles","previous_headings":"","what":"Model form","title":"Smooth quantile regression","text":"Smooth quantile regression linear auto-regressive, key feature transformation forces coefficients satisfy smoothing constraint. purpose model coefficient smooth function ahead values, coefficient set linear combination smooth basis functions (spline polynomial). degree parameter controls number polynomials used. greater number responses. tuning parameter, can chosen performing grid search cross-validation. Intuitively, d=1d = 1 corresponds constant model, d=2d = 2 gives straight line forecasts, d=3d = 3 gives quadratic forecasts. Since degree 3 found work well tested applications (see Section 9 Tuzhilina et al., 2022), default value.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/smooth-qr.html","id":"demonstration-of-smooth-quantile-regression","dir":"Articles","previous_headings":"","what":"Demonstration of smooth quantile regression","title":"Smooth quantile regression","text":"now apply smooth quantile regression real data used COVID-19 forecasting. built-dataset use subset JHU daily data state cases deaths. sample data ranges Dec. 31, 2020 Dec. 31, 2021. set forecast date November 30, 2021 can produce forecasts target dates 1 28 days ahead. construct test data, tedf days beyond . use recent 3 months worth data forecast date training. plotting focus subset two states - California Utah. Suppose goal data predict COVID-19 death rates several horizons state. day tt, want predict new deaths yy =1,…,28a = 1,\\dots, 28 days ahead locations jj using death rates today, 1 week ago, 2 weeks ago. location, ’ll predict median (0.5 quantile) target dates using ŷj(t+)=α()+∑l=02βl()yj(t−7l) \\hat{y}_{j}(t+) = \\alpha() + \\sum_{l = 0}^2 \\beta_{l}()  y_{j}(t - 7l)  βl()=∑=1dθilhi()\\beta_{l}() = \\sum_{=1}^d \\theta_{il} h_i() smoothing constraint h1(),…,hd(){h_1(), \\dots, h_d()} set smooth basis functions dd hyperparameter manages flexibility βl()\\beta_{l}(). Remember goal βl()\\beta_{l}() smooth function aheads achieved imposing smoothing constraint. Note model intended simple straightforward. modification model add case rates another predictive feature (leave reader incorporate additional features beyond historical response values). can update basic model incorporate k=2k = 2 predictive features case death rates location j, xj(t)=(xj1(t),xj2(t))x_j(t) = (x_{j1}(t), x_{j2}(t)) follows: ŷj(t+)=α()+∑k=12∑l=02βkl()xjk(t−7l) \\hat{y}_{j}(t+) = \\alpha() + \\sum_{k = 1}^2 \\sum_{l = 0}^2 \\beta_{kl}()  x_{jk}(t - 7l)  βkl()=∑=1dθiklhi()\\beta_{kl}() = \\sum_{=1}^d \\theta_{ikl} h_i(). Now, create forecaster scratch building epi_workflow (canned forecaster currently available). Building forecaster allows customization control pre-processing post-processing actions wish take. pre-processing steps take epi_recipe simply lag predictor (0, 7, 14 days) lead response multiple aheads specified function user. post-processing layers add frosting nearly simple. first predict, unnest prediction list-cols, omit NAs , enforce greater 0. third component epi_workflow, model, smooth quantile regression, three main arguments - quantiles, aheads, degree. creating epi_workflow components, get test data based longest lag period make predictions. input forecaster function ease use. Notice allow function user specify aheads, degree, quantile may want change parameter values. also allow input forecast date fixed onset demonstration. now can produce smooth quantile regression predictions problem: often, ’re going want limit just predicting median value uncertainty predictions, let’s try predict several different quantiles addition median: can see different columns different quantile predictions. Let’s visualize results sample two states. create simple plotting function, median predictions orange line surrounding quantiles blue bands around . comparison, include actual values time black line. Since like plot actual death rates states time, bind training testing data together input plotting function follows:  can see predictions smooth curves state, expected using smooth quantile regression. addition curvature forecasts matches truth, forecasts look remarkably accurate.","code":"library(epipredict) library(dplyr) library(purrr) library(ggplot2) theme_set(theme_bw()) edf <- case_death_rate_subset fd <- as.Date(\"2021-11-30\")  tedf <- edf %>% filter(time_value >= fd) edf <- edf %>% filter(time_value < fd, time_value >= fd - 90L) geos <- c(\"ut\", \"ca\") smooth_fc <- function(x, aheads = 1:28, degree = 3L, quantiles = 0.5, fd) {   rec <- epi_recipe(x) %>%     step_epi_lag(case_rate, lag = c(0, 7, 14)) %>%     step_epi_lag(death_rate, lag = c(0, 7, 14)) %>%     step_epi_ahead(death_rate, ahead = aheads)    f <- frosting() %>%     layer_predict() %>%     layer_unnest(.pred) %>%     layer_naomit(distn) %>%     layer_add_forecast_date() %>%     layer_threshold(distn)    ee <- smooth_quantile_reg(     quantile_levels = quantiles,     outcome_locations = aheads,     degree = degree   )    ewf <- epi_workflow(rec, ee, f)    the_fit <- ewf %>% fit(x)    latest <- get_test_data(rec, x)    preds <- predict(the_fit, new_data = latest) %>%     mutate(forecast_date = fd, target_date = fd + ahead) %>%     select(geo_value, target_date, distn, ahead) %>%     pivot_quantiles_wider(distn)    preds } smooth_preds <- smooth_fc(edf, fd = fd)  smooth_preds #> # A tibble: 1,568 × 4 #>    geo_value target_date ahead `0.5` #>    <chr>     <date>      <int> <dbl> #>  1 ak        2021-12-01      1 0.323 #>  2 ak        2021-12-02      2 0.347 #>  3 ak        2021-12-03      3 0.369 #>  4 ak        2021-12-04      4 0.389 #>  5 ak        2021-12-05      5 0.407 #>  6 ak        2021-12-06      6 0.422 #>  7 ak        2021-12-07      7 0.436 #>  8 ak        2021-12-08      8 0.448 #>  9 ak        2021-12-09      9 0.458 #> 10 ak        2021-12-10     10 0.465 #> # ℹ 1,558 more rows several_quantiles <- c(.1, .25, .5, .75, .9) smooth_preds <- smooth_fc(edf, quantiles = several_quantiles, fd = fd)  smooth_preds #> # A tibble: 1,568 × 8 #>    geo_value target_date ahead `0.1` `0.25` `0.5` `0.75` `0.9` #>    <chr>     <date>      <int> <dbl>  <dbl> <dbl>  <dbl> <dbl> #>  1 ak        2021-12-01      1 0.286  0.315 0.323  0.350 0.434 #>  2 ak        2021-12-02      2 0.292  0.331 0.347  0.383 0.474 #>  3 ak        2021-12-03      3 0.298  0.345 0.369  0.414 0.511 #>  4 ak        2021-12-04      4 0.303  0.358 0.389  0.442 0.544 #>  5 ak        2021-12-05      5 0.307  0.369 0.407  0.467 0.575 #>  6 ak        2021-12-06      6 0.310  0.378 0.422  0.490 0.603 #>  7 ak        2021-12-07      7 0.313  0.387 0.436  0.511 0.629 #>  8 ak        2021-12-08      8 0.314  0.393 0.448  0.529 0.651 #>  9 ak        2021-12-09      9 0.315  0.398 0.458  0.544 0.670 #> 10 ak        2021-12-10     10 0.315  0.402 0.465  0.557 0.687 #> # ℹ 1,558 more rows plot_preds <- function(preds, geos_to_plot = NULL, train_test_dat, fd) {   if (!is.null(geos_to_plot)) {     preds <- preds %>% filter(geo_value %in% geos_to_plot)     train_test_dat <- train_test_dat %>% filter(geo_value %in% geos_to_plot)   }    ggplot(preds) +     geom_ribbon(aes(target_date, ymin = `0.1`, ymax = `0.9`),       fill = \"cornflowerblue\", alpha = .8     ) +     geom_ribbon(aes(target_date, ymin = `0.25`, ymax = `0.75`),       fill = \"#00488E\", alpha = .8     ) +     geom_line(data = train_test_dat, aes(time_value, death_rate)) +     geom_line(aes(target_date, `0.5`), color = \"orange\") +     geom_vline(xintercept = fd) +     facet_wrap(~geo_value) +     scale_x_date(name = \"\", date_labels = \"%b %Y\", date_breaks = \"2 months\") +     ylab(\"Deaths per 100K inhabitants\") } plot_preds(smooth_preds, geos, bind_rows(tedf, edf), fd)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/smooth-qr.html","id":"varying-the-degrees-parameter","dir":"Articles","previous_headings":"Demonstration of smooth quantile regression","what":"Varying the degrees parameter","title":"Smooth quantile regression","text":"can test impact different degrees using map() function. Noting may take time run, let’s try degrees 1 7: One way quantify impact forecasting look mean absolute error (MAE) mean squared error (MSE) degrees. can select degree results lowest MAE. Since MAE compares predicted values actual values, first join test data predicted data comparisons: compute MAE degrees: Instead just looking raw numbers, let’s create simple line plot visualize MAE changes degrees data:  can see degree results lowest MAE 3. Hence, pick degree future forecasting work data.","code":"smooth_preds_list <- map(1:7, ~ smooth_fc(edf,   degree = .x,   quantiles = c(.1, .25, .5, .75, .9),   fd = fd ) %>%   mutate(degree = .x)) %>% list_rbind() tedf_sub <- tedf %>%   rename(target_date = time_value, actual = death_rate) %>%   select(geo_value, target_date, actual) smooth_preds_df_deg <- smooth_preds_list %>%   left_join(tedf_sub, by = c(\"geo_value\", \"target_date\")) %>%   group_by(degree) %>%   mutate(error = abs(`0.5` - actual)) %>%   summarise(mean = mean(error))  # Arrange the MAE from smallest to largest smooth_preds_df_deg %>% arrange(mean) #> # A tibble: 7 × 2 #>   degree  mean #>    <int> <dbl> #> 1      3 0.201 #> 2      2 0.202 #> 3      5 0.203 #> 4      4 0.203 #> 5      6 0.203 #> 6      7 0.204 #> 7      1 0.205 ggplot(smooth_preds_df_deg, aes(degree, mean)) +   geom_line() +   xlab(\"Degrees of freedom\") +   ylab(\"Mean MAE\")"},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/smooth-qr.html","id":"a-brief-comparison-between-smoothing-and-no-smoothing","dir":"Articles","previous_headings":"Demonstration of smooth quantile regression","what":"A brief comparison between smoothing and no smoothing","title":"Smooth quantile regression","text":"Now, briefly compare results using smooth quantile regression obtained without smoothing. latter approach amounts ordinary quantile regression get predictions intended target date. main drawback ignores fact responses represent signal, just different ahead values. contrast, smooth quantile regression approach utilizes information data structure - fact aheads independent , naturally related time smooth curve. get basic quantile regression results can utilize forecaster ’ve already built. can simply set degree number ahead values re-run code without smoothing. can produce corresponding plot inspect predictions obtained baseline model:  Unlike smooth quantile regression, resulting forecasts smooth curves, rather jagged irregular shape. formal comparison two approaches, compare test performance terms accuracy calculating either , MAE MSE, performance measure choice can calculated times locations ahead value  aheads, times, locations single numerical summary. former shows forecasts immediate future distant future inaccurate models consideration. latter shows smooth quantile regression model baseline models perform similarly overall, smooth quantile regression model slightly beating baseline model terms overall average MAE. One commonly used metric Weighted Interval Score (WIS, Bracher et al., 2021), scoring rule based population quantiles. point score interval, whereas MAE evaluates accuracy point forecast. Let FF forecast composed predicted quantiles qτq_{\\tau} set quantile levels τ\\tau. , terms predicted quantiles, WIS target variable YY represented follows (McDonald etal., 2021): WIS(F,Y)=2∑τϕτ(Y−qτ) WIS(F, Y) = 2 \\sum_{\\tau} \\phi_{\\tau} (Y - q_{\\tau})  ϕτ(x)=τ|x|\\phi_{\\tau}(x) = \\tau |x| x≥0x \\geq 0 andϕτ(x)=(1−τ)|x|\\phi_{\\tau}(x) = (1 - \\tau) |x| x<0x < 0. form general can accommodate symmetric asymmetric quantile levels. quantile levels symmetric, can alternatively express WIS collection central prediction intervals (ℓα,uα\\ell_{\\alpha}, u_{\\alpha}) parametrized exclusion probability α\\alpha: WIS(F,Y)=∑α{(uα−ℓα)+2⋅dist(Y,[ℓα,uα])} WIS(F, Y) =  \\sum_{\\alpha} \\{ (u_{\\alpha} - \\ell_{\\alpha}) + 2 \\cdot \\text{dist}(Y, [\\ell_{\\alpha}, u_{\\alpha}]) \\}  dist(,S)\\text{dist}(,S) smallest distance point aa element set SS. implement former representation, mention form shows score can decomposed addition sharpness component (first term summand) /overprediction component (second term summand). alternative representation useful , easily see major limitation WIS, score tends prioritize sharpness (wide interval ) relative coverage (interval contains truth). Now, write simple function first representation score compatible latest version epipredict (adapted corresponding function smoothmpf-epipredict). inputs actual predicted values quantile levels. Next, apply wis_dist_quantile function get WIS score state target date. compute mean WIS ahead value states. results smooth baseline forecasters shown similar style line plot chose MAE:  results consistent saw MAE: forecasts near distant future tend inaccurate models. smooth quantile regression model slightly outperforms baseline model. Though averaging WIS score location time tends primary aggregation scheme used evaluation model comparisons (see, example, McDonald et al., 2021), can also obtain single numerical summary averaging aheads, times, locations: Overall, perspectives agree smooth quantile regression model tends perform slightly better baseline model terms average WIS, illustrating difficulty forecasting problem.","code":"baseline_preds <- smooth_fc(   edf,   degree = 28L, quantiles = several_quantiles, fd = fd ) plot_preds(baseline_preds, geos, bind_rows(tedf, edf), fd) baseline_preds_mae_df <- baseline_preds %>%   left_join(tedf_sub, by = c(\"geo_value\", \"target_date\")) %>%   group_by(ahead) %>%   mutate(error = abs(`0.5` - actual)) %>%   summarise(mean = mean(error)) %>%   mutate(type = \"baseline\")  smooth_preds_mae_df <- smooth_preds %>%   left_join(tedf_sub, by = c(\"geo_value\", \"target_date\")) %>%   group_by(ahead) %>%   mutate(error = abs(`0.5` - actual)) %>%   summarise(mean = mean(error)) %>%   mutate(type = \"smooth\")  preds_mae_df <- bind_rows(baseline_preds_mae_df, smooth_preds_mae_df)  ggplot(preds_mae_df, aes(ahead, mean, color = type)) +   geom_line() +   xlab(\"Ahead\") +   ylab(\"Mean MAE\") +   scale_color_manual(values = c(\"#A69943\", \"#063970\")) mean(baseline_preds_mae_df$mean) #> [1] 0.2038163 mean(smooth_preds_mae_df$mean) #> [1] 0.201258 wis_dist_quantile <- function(actual, values, quantile_levels) {   2 * mean(pmax(     quantile_levels * (actual - values),     (1 - quantile_levels) * (values - actual),     na.rm = TRUE   )) } smooth_preds_wis_df <- smooth_preds %>%   left_join(tedf_sub, by = c(\"geo_value\", \"target_date\")) %>%   rowwise() %>%   mutate(wis = wis_dist_quantile(     actual, c(`0.1`, `0.25`, `0.5`, `0.75`, `0.9`),     several_quantiles   )) %>%   group_by(ahead) %>%   summarise(mean = mean(wis)) %>%   mutate(type = \"smooth\")  baseline_preds_wis_df <- baseline_preds %>%   left_join(tedf_sub, by = c(\"geo_value\", \"target_date\")) %>%   rowwise() %>%   mutate(wis = wis_dist_quantile(     actual, c(`0.1`, `0.25`, `0.5`, `0.75`, `0.9`),     several_quantiles   )) %>%   group_by(ahead) %>%   summarise(mean = mean(wis)) %>%   mutate(type = \"baseline\")  preds_wis_df <- bind_rows(smooth_preds_wis_df, baseline_preds_wis_df)  ggplot(preds_wis_df, aes(ahead, mean, color = type)) +   geom_line() +   xlab(\"Ahead\") +   ylab(\"Mean WIS\") +   scale_color_manual(values = c(\"#A69943\", \"#063970\")) mean(baseline_preds_wis_df$mean) #> [1] 0.1674422 mean(smooth_preds_wis_df$mean) #> [1] 0.1644727"},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/smooth-qr.html","id":"what-weve-learned-in-a-nutshell","dir":"Articles","previous_headings":"","what":"What we’ve learned in a nutshell","title":"Smooth quantile regression","text":"Smooth quantile regression used multi-period forecasting predicting several horizons simultaneously single smooth curve. operates key assumption future response can approximated well smooth curve.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/smooth-qr.html","id":"attribution","dir":"Articles","previous_headings":"","what":"Attribution","title":"Smooth quantile regression","text":"information presented smooth quantile regression Tuzhilina et al., 2022.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/symptom-surveys.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Can symptoms surveys improve COVID-19 forecasts?","text":"COVID-19 pandemic, Delphi ran COVID-19 symptom surveys Facebook Google. surveys, millions people US asked whether people know experiencing COVID-like symptoms. enabled calculation “% CLI--community” signal counties across US. simply estimate percentage people know someone presently sick COVID-like illness. surveys valuable tools monitoring pandemic reported daily subject reporting delays plague sources data. vignette, look whether % CLI--community indicators Facebook Google surveys improve accuracy short-term forecasts county-level COVID-19 case rates. purpose study demonstrate value Facebook Google % CLI--community signals add predictive power beyond can achieve simple time series models trained case rates alone. Note vignette adapted following Delphi blog post, necessary modifications enable use epipredict. results may different blog post (one reason exploring use different forecaster another ’re using recent versions datasets). Now, delve forecasting problem set-code followed discussion results.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/symptom-surveys.html","id":"problem-setup","dir":"Articles","previous_headings":"Introduction","what":"Problem Setup","title":"Can symptoms surveys improve COVID-19 forecasts?","text":"goal predict county-level COVID-19 case incidence rates 1 2 weeks ahead. , restrict attention 442 counties least 200 confirmed cases May 14, 2020 (end Google survey data) Facebook Google % CLI--community signals available. set notation, let Yl,tY_{l,t} denote smoothed COVID-19 case incidence rate location (county) ll day tt. Let Fl,tF_{l,t} Gl,tG_{l,t} denote Facebook Google % CLI--community signals, respectively, location ll time tt. Note rescale signals given values API true proportions. evaluate following four models: h(Yl,t+d)≈α+∑j=02βjh(Yl,t−7j)h(Yl,t+d)≈α+∑j=02βjh(Yl,t−7j)+∑j=02γjh(Fl,t−7j)h(Yl,t+d)≈α+∑j=02βjh(Yl,t−7j)+∑j=02τjh(Gl,t−7j)h(Yl,t+d)≈α+∑j=02βjh(Yl,t−7j)+∑j=02γjh(Fl,t−7j)+∑j=02τjh(Gl,t−7j) \\begin{align} h(Y_{l,t+d}) &\\approx \\alpha + \\sum_{j = 0}^2 \\beta_j h(Y_{l,t-7j}) \\\\ h(Y_{l,t+d}) &\\approx \\alpha + \\sum_{j = 0}^2 \\beta_j h(Y_{l,t-7j}) + \\sum_{j = 0}^2 \\gamma_j h(F_{l, t-7j}) \\\\ h(Y_{l,t+d}) &\\approx \\alpha + \\sum_{j = 0}^2 \\beta_j h(Y_{l,t-7j}) + \\sum_{j = 0}^2 \\tau_j h(G_{l, t-7j}) \\\\ h(Y_{l,t+d}) &\\approx \\alpha + \\sum_{j = 0}^2 \\beta_j h(Y_{l,t-7j}) + \\sum_{j = 0}^2 \\gamma_j h(F_{l, t-7j}) + \\sum_{j = 0}^2 \\tau_j h(G_{l, t-7j}) \\end{align}  d=7d = 7 d=14d = 14 depending target value, hh transformation specified later. ’ll call first model “Cases” model bases predictions future case rates COVID-19 case rates (0, 1 2 weeks back). second model called “Cases + Facebook” additionally incorporates current Facebook signal, Facebook signal 1 2 weeks back. third model, “Cases + Google”, exactly second substitutes Google signal instead Facebook one. fourth final model model, “Cases + Facebook + Google”, uses Facebook Google signals. model, use canned autoregressive forecaster quantile regression forecast time t0t_0 (predict case rates t0+dt_0 + d). train training locations, ll (442 counties), time tt within recent 14 days data available including time t0t_0. words, use 14 trailing days training set. forecasts denoted Ŷl,t0+d\\hat{Y}_{l, t_0 + d}. see accurate forecasts , use scaled absolute error: |Ŷl,t0+d−Yl,t0+d||Yl,t0−Yl,t0+d| \\frac{| \\hat{Y}_{l, t_0 + d} - Y_{l, t_0 + d} |} {| Y_{l, t_0} - Y_{l, t_0 + d} |} error denominator strawman model error. model simply uses recent case rate future predictions. may recognize application flatline forecaster epipredict. normalize manner two reasons. First, since scaled error fraction improvement strawman’s error, get interpretable scale, numebrs like 0.8 0.9 favorable, numbers like 2 5 increasingly disastrous. Second, problems expect considerable county--county variability forecasting difficulty. Normalizing strawman’s error helps adjust results aggregate dominated county--county differences.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/symptom-surveys.html","id":"transformations","dir":"Articles","previous_headings":"Introduction","what":"Transformations","title":"Can symptoms surveys improve COVID-19 forecasts?","text":"help stabilize variance case, Facebook Google data, chose use logit transformation proportions. actuality, use “padded” version h(x)=log(x+a1−x+)h(x) = \\log (\\frac{x+}{1-x+}) numerator denominator pushed away zero small constant, =0.01a = 0.01. alternative logit transform using log transform (h(x)=log(x+)h(x) = \\log (x+) aa padding). Note variance-stabilizing transformations used model fitting. calculate errors, back-transform values comparison using inverse transform h−1h^{-1} may calculate original scale.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/symptom-surveys.html","id":"forecasting-code","dir":"Articles","previous_headings":"Introduction","what":"Forecasting Code","title":"Can symptoms surveys improve COVID-19 forecasts?","text":"code marches forecast date t0t_0 forward, one day time nine forecasting dates four models can fit (May 6, 2020 May 14, 2020). , fits models, makes predictions 7 14 days ahead (permissible data), records errors. number benefits using epipredict writing code scratch fit predict models. First, reformat data input model concern unique interface. instead work unifying interface streamline modelling process. Second, avoid write function append shift values (leads lags). done us --hood arx_forecaster() function. can see forecaster output inspecting step_epi_lag() step_epi_ahead() pre-processing steps epi_workflow. Third, need one loop forecast dates (second loop different aheads) can easily use map() arx_forecaster() different ahead values, ’ve done . However, trade-offs bear mind. instance, since using canned arx forecaster, able easily modify add steps signal transformations pre-processing (pre-specified part using canned forecaster). code-forecaster epipredict framework, easily add steps re-scale transform signals epi_recipe. make code succinct self-contained.","code":"library(epidatr) library(dplyr) library(purrr) library(epipredict) library(recipes)  case_num <- 200 as_of_date <- \"2020-05-14\" geo_values <- pub_covidcast(   source = \"jhu-csse\",   signals = \"confirmed_cumulative_num\",   geo_type = \"county\",   time_type = \"day\",   geo_values = \"*\",   time_values = epirange(20200514, 20200514) ) %>%   filter(value >= case_num) %>%   pull(geo_value) %>%   unique()  # Fetch county-level Google and Facebook % CLI-in-community signals, and JHU # confirmed case incidence proportion start_day <- \"2020-04-11\" end_day <- \"2020-09-01\"  goog_sm_cli <- pub_covidcast(   source = \"google-survey\",   signals = \"smoothed_cli\",   geo_type = \"county\",   time_type = \"day\",   geo_values = \"*\",   time_values = epirange(start_day, end_day) ) %>%   filter(geo_value %in% geo_values) %>%   select(geo_value, time_value, value) %>%   rename(goog = value)  fb_survey <- pub_covidcast(   source = \"fb-survey\",   signals = \"smoothed_hh_cmnty_cli\",   geo_type = \"county\",   time_type = \"day\",   geo_values = \"*\",   time_values = epirange(start_day, end_day) ) %>%   filter(geo_value %in% geo_values) %>%   select(geo_value, time_value, value) %>%   rename(fb = value)  jhu_7dav_incid <- pub_covidcast(   source = \"jhu-csse\",   signals = \"confirmed_7dav_incidence_prop\",   geo_type = \"county\",   time_type = \"day\",   geo_values = \"*\",   time_values = epirange(start_day, end_day) ) %>%   filter(geo_value %in% geo_values) %>%   select(geo_value, time_value, value) %>%   rename(case = value)  # Find \"complete\" counties, present in all three data signals at all times geo_values_complete <- intersect(   intersect(goog_sm_cli$geo_value, fb_survey$geo_value),   jhu_7dav_incid$geo_value )  # Make one big matrix by joining these three data frames z <- full_join(full_join(goog_sm_cli, fb_survey, by = c(\"geo_value\", \"time_value\")),   jhu_7dav_incid,   by = c(\"geo_value\", \"time_value\") ) %>%   filter(geo_value %in% geo_values_complete) %>%   as_epi_df()  Logit <- function(x, a = 0.01) log((x + a) / (1 - x + a)) Sigmd <- function(y, a = 0.01) (exp(y) * (1 + a) - a) / (1 + exp(y))  #### Parameters #####  # Transforms to consider, in what follows trans <- Logit inv_trans <- Sigmd  # Rescale factors for our signals: bring them all down to proportions (between # 0 and 1) rescale_f <- 1e-2 # Originally a percentage rescale_g <- 1e-2 # Originally a percentage rescale_c <- 1e-5 # Originally a count per 100,000 people  z <- z %>% mutate(   case = trans(case * rescale_c),   fb = trans(fb * rescale_f),   goog = trans(goog * rescale_g) )  # lead = 7 leads <- c(7, 14) lags <- c(0, 7, 14) n <- 14 # Number of trailing days to use for the training set  # Nine forecast dates dates <- seq(as.Date(\"2020-05-06\"), as.Date(\"2020-05-14\"), by = \"day\")  # List for storage of results out_list <- vector(mode = \"list\", length = length(dates)) for (k in 1:length(dates)) {   date <- dates[k]    if (date %in% c(\"2020-05-13\", \"2020-05-14\")) leads <- c(7, 14) else leads <- 7    # Pre-structuring test data   z_te <- z %>%     rename(       target_date = time_value,       target_case = case     ) %>%     select(geo_value, target_date, target_case)    # Strawman model   out_df0 <- map(leads, ~ flatline_forecaster(     z %>%       filter(between(time_value, date - .x - max(lags) - n, date)) %>%       select(time_value, geo_value, case),     outcome = \"case\",     args_list = arx_args_list(       lags = lags,       ahead = .x,       nonneg = FALSE     )   )$predictions %>%     mutate(lead = .x) %>%     left_join(z_te %>% filter(target_date == (date + .x)), by = c(\"geo_value\", \"target_date\"))) %>%     list_rbind() %>%     mutate(err0 = abs(inv_trans(.pred) - inv_trans(target_case))) %>%     select(geo_value, forecast_date, err0, lead)     # Cases model   out_df1 <- map(leads, ~ arx_forecaster(     z %>%       filter(between(time_value, date - .x - max(lags) - n, date)) %>%       select(time_value, geo_value, case) %>%       filter(complete.cases(.)),     outcome = \"case\",     predictors = \"case\",     trainer = quantile_reg(),     args_list = arx_args_list(       lags = lags,       ahead = .x,       nonneg = FALSE     )   )$predictions %>%     mutate(lead = .x) %>%     left_join(z_te %>% filter(target_date == (date + .x)), by = c(\"geo_value\", \"target_date\"))) %>%     list_rbind() %>%     mutate(err1 = abs(inv_trans(.pred) - inv_trans(target_case))) %>%     select(geo_value, forecast_date, err1, lead)    # Cases and Facebook model   out_df2 <- map(leads, ~ arx_forecaster(     z %>%       filter(between(time_value, date - .x - max(lags) - n, date)) %>%       select(time_value, geo_value, case, fb) %>%       filter(complete.cases(.)),     outcome = \"case\",     predictors = c(\"case\", \"fb\"),     trainer = quantile_reg(),     args_list = arx_args_list(       lags = lags,       ahead = .x,       nonneg = FALSE     )   )$predictions %>%     mutate(lead = .x) %>%     left_join(z_te %>% filter(target_date == (date + .x)), by = c(\"geo_value\", \"target_date\"))) %>%     list_rbind() %>%     mutate(err2 = abs(inv_trans(.pred) - inv_trans(target_case))) %>%     select(geo_value, forecast_date, err2, lead)     # Cases and Google model   out_df3 <- map(leads, ~ arx_forecaster(     z %>%       filter(between(time_value, date - .x - max(lags) - n, date)) %>%       select(time_value, geo_value, case, goog) %>%       filter(complete.cases(.)),     outcome = \"case\",     predictors = c(\"case\", \"goog\"),     trainer = quantile_reg(),     args_list = arx_args_list(       lags = lags,       ahead = .x,       nonneg = FALSE     )   )$predictions %>%     mutate(lead = .x) %>%     left_join(z_te %>% filter(target_date == (date + .x)), by = c(\"geo_value\", \"target_date\"))) %>%     list_rbind() %>%     mutate(err3 = abs(inv_trans(.pred) - inv_trans(target_case))) %>%     select(geo_value, forecast_date, err3, lead)    # Cases, Facebook and Google model   out_df4 <- map(leads, ~ arx_forecaster(     z %>%       filter(between(time_value, date - .x - max(lags) - n, date)) %>%       select(time_value, geo_value, case, fb, goog) %>%       filter(complete.cases(.)),     outcome = \"case\",     predictors = c(\"case\", \"goog\"),     trainer = quantile_reg(),     args_list = arx_args_list(       lags = lags,       ahead = .x,       nonneg = FALSE     )   )$predictions %>%     mutate(lead = .x) %>%     left_join(z_te %>% filter(target_date == (date + .x)), by = c(\"geo_value\", \"target_date\"))) %>%     list_rbind() %>%     mutate(err4 = abs(inv_trans(.pred) - inv_trans(target_case))) %>%     select(geo_value, forecast_date, err4, lead)    # Left join of the results for all models   out_list[[k]] <- left_join(left_join(left_join(left_join(out_df0, out_df1), out_df2), out_df3), out_df4) } # Outside of loop bind rows of list out_df <- do.call(rbind, out_list)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/symptom-surveys.html","id":"results-all-four-models","dir":"Articles","previous_headings":"Introduction","what":"Results: All Four Models","title":"Can symptoms surveys improve COVID-19 forecasts?","text":"Since two common forecast dates available four models 14-day-ahead forecasts (May 13 May 14, 2020), skip studying 14-day-ahead forecast results four-way model discussion. compute median scaled errors four models 9-day test period. can see adding either survey signals improves median scaled error model uses cases , biggest gain achieved “Cases + Google” model. can also see median scaled errors close 1 (“Cases + Google” “Cases + Facebook + Google” models exceeding 1), speaks difficulty forecasting problem. Test period: 2020-05-06 2020-05-14 $$\\\\[0.01in]$$ differences median scaled errors significant? basic hypothesis testing suggests probably : conduct sign test whether difference “Cases” model’s scaled error model’s scaled error centered zero. sign test run 9 test days x 442 counties = 3978 pairs scaled errors. p-value “Cases” versus “Cases + Google” test tiny well cutoff 0.01. contrast, p-values “Cases” versus “Cases + Facebook” “Cases” versus “Cases + Facebook + Google” tests much bigger exceed cutoff, suggesting Facebook survey adding much situation (meaning time ahead considered, etc.) $$\\\\[0.01in]$$ take test results grain salt sign test assumes independence observations, clearly true given spatiotemporal structure forecasting problem. mitigate dependence across time (intuitively seems matter across space), recomputed tests stratified way, day run sign test scaled errors two models 442 counties. results plotted histograms ; “Cases + Google” (lesser extent) “Cases + Facebook + Google” models appear deliver decently small p-values, evident “Cases + Facebook” model. Taking larger sample size (nine test days) natural next step take see results persist.","code":"library(dplyr) library(tidyr) library(ggplot2)  model_names <- c(   \"Cases\", \"Cases + Facebook\", \"Cases + Google\",   \"Cases + Facebook + Google\" )  # Calculate the scaled errors for each model, that is, the error relative to the strawman's error res_all4 <- out_df %>%   drop_na() %>% # Restrict to common time   mutate(across(err1:err4, ~ .x / err0)) %>% # compute relative error to strawman   mutate(across(err2:err4, list(diff = ~ err1 - .x))) %>% # relative to cases model   ungroup() %>%   select(-err0)  # Calculate and print median errors, for all 4 models, and just 7 days ahead res_err4 <- res_all4 %>%   select(-ends_with(\"diff\")) %>%   pivot_longer(     names_to = \"model\", values_to = \"err\",     cols = -c(geo_value, forecast_date, lead)   ) %>%   mutate(     lead = factor(lead, labels = paste(leads, \"days ahead\")),     model = factor(model, labels = model_names)   )  knitr::kable(   res_err4 %>%     group_by(model, lead) %>%     summarise(err = median(err), n = length(unique(forecast_date))) %>%     arrange(lead) %>% ungroup() %>%     rename(       \"Model\" = model, \"Median scaled error\" = err,       \"Target\" = lead, \"Test days\" = n     ) %>%     filter(Target == \"7 days ahead\"),   caption = paste(     \"Test period:\", min(res_err4$forecast_date), \"to\",     max(res_err4$forecast_date)   ),   format = \"html\", table.attr = \"style='width:70%;'\" ) # Compute p-values using the sign test against a one-sided alternative, for # all models, and just 7 days ahead res_dif4 <- res_all4 %>%   select(-ends_with(as.character(1:4))) %>%   pivot_longer(     names_to = \"model\", values_to = \"diff\",     cols = -c(geo_value, forecast_date, lead)   ) %>%   mutate(     lead = factor(lead, labels = paste(leads, \"days ahead\")),     model = factor(model,       labels = c(         \"Cases vs Cases + Facebook\",         \"Cases vs Cases + Google\",         \"Cases vs Cases + Facebook + Google\"       )     )   )  knitr::kable(   res_dif4 %>%     group_by(model, lead) %>%     summarise(p = binom.test(       x = sum(diff > 0, na.rm = TRUE),       n = n(), alt = \"greater\"     )$p.val) %>%     ungroup() %>% filter(lead == \"7 days ahead\") %>%     rename(\"Comparison\" = model, \"Target\" = lead, \"P-value\" = p),   format = \"html\", table.attr = \"style='width:50%;'\",   digiits = 3 ) # Red, blue (similar to ggplot defaults), then yellow ggplot_colors <- c(\"#FC4E07\", \"#00AFBB\", \"#E7B800\")  ggplot(res_dif4 %>%   group_by(model, lead, forecast_date) %>%   summarise(p = binom.test(     x = sum(diff > 0, na.rm = TRUE),     n = n(), alt = \"greater\"   )$p.val) %>%   ungroup() %>% filter(lead == \"7 days ahead\"), aes(p)) +   geom_histogram(aes(color = model, fill = model), alpha = 0.4) +   scale_color_manual(values = ggplot_colors) +   scale_fill_manual(values = ggplot_colors) +   facet_wrap(vars(lead, model)) +   labs(x = \"P-value\", y = \"Count\") +   theme_bw() +   theme(legend.position = \"none\")"},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/symptom-surveys.html","id":"results-first-two-models","dir":"Articles","previous_headings":"Introduction","what":"Results: First Two Models","title":"Can symptoms surveys improve COVID-19 forecasts?","text":"One way get larger sample size current data compare subset models. Therefore, next focus comparing results “Cases” “Cases + Facebook” models . Restricting common forecast dates two models yields much longer test period 7 14-day-ahead forecasts: May 20 August 27, 2020. make code compare two models simple function option use different dates aheads (particular, function useful next section explore several ahead values): median scaled errors test period computed reported . Now see decent improvement median scaled error “Cases + Facebook” model, true 7-day-ahead 14-day-ahead forecasts. Test period: 2020-05-20 2020-08-25 $$\\\\[0.01in]$$ Thanks extended length test period, can also plot trajectories median scaled errors time, , left plot concerning 7-day-ahead forecasts, right 14-day-ahead forecasts. plots reveal something interesting bothersome: median scaled errors quite volatile time, periods July, forecasting became much harder, scaled errors reaching 1.5 7-day-ahead forecasts, 1.8 14-day-ahead forecasts. Furthermore, can see clear visual difference median scaled errors “Cases + Facebook” model red “Cases” model black. former appears latter periods low median scaled errors periods forecasting becomes hard scaled errors shoot 1. suggests Facebook signal may useful incorporate periods time forecasting easier.  fact lines non-coincident suggests results ’re seeing likely significantly different, though ’s hard say definitively given complicated dependence structure present data. perform sign test whether difference scaled errors “Cases” “Cases + Facebook” models centered zero. p-values essentially zero, given large sample sizes: 98 test days total 7-day-ahead forecasts 91 days 14-day-ahead forecasts (times 442 counties day). $$\\\\[0.01in]$$ stratify recompute p-values forecast date, bulk p-values quite small.  exploration illustrates important point: test period chosen large enough size see differences () models comparison. observe significant differences “Cases” “Cases + Facebook” models test period small 9 days, observe significant difference extended test period nearly 100 days.","code":"case_fb_mods <- function(forecast_dates, leads) {   # List for storage of results   out_list <- vector(mode = \"list\", length = length(forecast_dates))   for (k in 1:length(forecast_dates)) {     date <- forecast_dates[k]      # Pre-structuring test data     z_te <- z %>%       rename(         target_date = time_value,         target_case = case       ) %>%       select(geo_value, target_date, target_case)      # Strawman model     out_df0 <- map(leads, ~ flatline_forecaster(       z %>%         filter(between(time_value, date - .x - max(lags) - n, date)) %>%         select(time_value, geo_value, case),       outcome = \"case\",       args_list = arx_args_list(         lags = lags,         ahead = .x,         nonneg = FALSE       )     )$predictions %>%       mutate(lead = .x) %>%       left_join(z_te %>% filter(target_date == (date + .x)), by = c(\"geo_value\", \"target_date\"))) %>%       list_rbind() %>%       mutate(err0 = abs(inv_trans(.pred) - inv_trans(target_case))) %>%       select(geo_value, forecast_date, err0, lead)      # Cases model     out_df1 <- map(leads, ~ arx_forecaster(       z %>%         filter(between(time_value, date - .x - max(lags) - n, date)) %>%         select(time_value, geo_value, case) %>%         filter(complete.cases(.)),       outcome = \"case\",       predictors = \"case\",       trainer = quantile_reg(),       args_list = arx_args_list(         lags = lags,         ahead = .x,         nonneg = FALSE       )     )$predictions %>%       mutate(lead = .x) %>%       left_join(z_te %>% filter(target_date == (date + .x)), by = c(\"geo_value\", \"target_date\"))) %>%       list_rbind() %>%       mutate(err1 = abs(inv_trans(.pred) - inv_trans(target_case))) %>%       select(geo_value, forecast_date, err1, lead)      # Cases and Facebook model     out_df2 <- map(leads, ~ arx_forecaster(       z %>%         filter(between(time_value, date - .x - max(lags) - n, date)) %>%         select(time_value, geo_value, case, fb) %>%         filter(complete.cases(.)),       outcome = \"case\",       predictors = c(\"case\", \"fb\"),       trainer = quantile_reg(),       args_list = arx_args_list(         lags = lags,         ahead = .x,         nonneg = FALSE       )     )$predictions %>%       mutate(lead = .x) %>%       left_join(z_te %>% filter(target_date == (date + .x)), by = c(\"geo_value\", \"target_date\"))) %>%       list_rbind() %>%       mutate(err2 = abs(inv_trans(.pred) - inv_trans(target_case))) %>%       select(geo_value, forecast_date, err2, lead)      # Left join of the results for all models     out_list[[k]] <- left_join(left_join(out_df0, out_df1), out_df2)   }   # Outside of loop bind rows and split into two lists by lead   out_df <- do.call(rbind, out_list) }  # Choose forecast dates common to the Cases and Cases + Facebook models dates <- seq(as.Date(\"2020-05-20\"), as.Date(\"2020-08-27\"), by = \"day\")  # Two leads to consider leads <- c(7, 14)  res <- case_fb_mods(dates, leads) # For just models 1 and 2, then calculate the scaled # errors, that is, the error relative to the strawman's error res_all2 <- res %>%   drop_na() %>% # Restrict to common time   mutate(across(err1:err2, ~ .x / err0)) %>% # compute relative error to strawman   mutate(err12_diff = err1 - err2) %>% # Compute differences   # relative to cases model   ungroup() %>%   select(-err0)  # Calculate and print median errors, for just models 1 and 2, and both 7 and 14 # days ahead res_err2 <- res_all2 %>%   select(-ends_with(\"diff\")) %>%   pivot_longer(     names_to = \"model\", values_to = \"err\",     cols = -c(geo_value, forecast_date, lead)   ) %>%   mutate(     lead = factor(lead, labels = paste(leads, \"days ahead\")),     model = factor(model, labels = model_names[1:2])   )  knitr::kable(   res_err2 %>%     select(-ends_with(\"diff\")) %>%     group_by(model, lead) %>%     summarise(err = median(err), n = length(unique(forecast_date))) %>%     arrange(lead) %>% ungroup() %>%     rename(       \"Model\" = model, \"Median scaled error\" = err,       \"Target\" = lead, \"Test days\" = n     ),   caption = paste(     \"Test period:\", min(res_err2$forecast_date), \"to\",     max(res_err2$forecast_date)   ),   format = \"html\", table.attr = \"style='width:70%;'\", digits = 3 ) # Plot median errors as a function of time, for models 1 and 2, and both 7 and # 14 days ahead ggplot(   res_err2 %>%     group_by(model, lead, forecast_date) %>%     summarise(err = median(err)) %>% ungroup(),   aes(x = forecast_date, y = err) ) +   geom_line(aes(color = model)) +   scale_color_manual(values = c(\"black\", ggplot_colors)) +   geom_hline(yintercept = 1, linetype = 2, color = \"gray\") +   facet_wrap(vars(lead)) +   labs(x = \"Date\", y = \"Median scaled error\") +   theme_bw() +   theme(legend.position = \"bottom\", legend.title = element_blank()) # Compute p-values using the sign test against a one-sided alternative, just # for models 1 and 2, and both 7 and 14 days ahead res_dif2 <- res_all2 %>%   select(-ends_with(as.character(1:4))) %>%   pivot_longer(     names_to = \"model\", values_to = \"diff\",     cols = -c(geo_value, forecast_date, lead)   ) %>%   mutate(     lead = factor(lead, labels = paste(leads, \"days ahead\")),     model = factor(model, labels = \"Cases > Cases + Facebook\")   )  knitr::kable(   res_dif2 %>%     group_by(model, lead) %>%     summarise(p = binom.test(       x = sum(diff > 0, na.rm = TRUE),       n = n(), alt = \"greater\"     )$p.val) %>%     ungroup() %>%     rename(\"Comparison\" = model, \"Target\" = lead, \"P-value\" = p),   format = \"html\", table.attr = \"style='width:50%;'\" ) ggplot(res_dif2 %>%   group_by(model, lead, forecast_date) %>%   summarise(p = binom.test(     x = sum(diff > 0, na.rm = TRUE),     n = n(), alt = \"greater\"   )$p.val) %>%   ungroup(), aes(p)) +   geom_histogram(aes(color = model, fill = model), alpha = 0.4) +   scale_color_manual(values = ggplot_colors) +   scale_fill_manual(values = ggplot_colors) +   facet_wrap(vars(lead, model)) +   labs(x = \"P-value\", y = \"Count\") +   theme_bw() +   theme(legend.position = \"none\")"},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/symptom-surveys.html","id":"varying-the-number-of-days-ahead","dir":"Articles","previous_headings":"Introduction","what":"Varying the Number of Days Ahead","title":"Can symptoms surveys improve COVID-19 forecasts?","text":"Statistical significance refers whether effect exists (opposed occurring chance), practical significance refers magnitude effect whether meaningful real world. Hypothesis tests, sign tests conducted , tell us whether differences errors statistically significant, practical significance. example, 7-day-ahead forecasts, improvement 0.019 units scaled error scale really mean, comparing “Cases + Facebook” model “Cases” model? meaningful gain practice? answer questions , can look way median scaled errors behave function number days ahead. Previously, considered forecasting case rates just 7 14 days ahead. Now systematically examine 5 20 days ahead (key difference code use leads = 5:20). Note running code many leads may take . obtain plot median scaled errors “Cases” “Cases + Facebook” models different number days ahead forecast target. done May 20 August 27 forecast dates common two models.  first glance shows “Cases + Facebook” model, red, gives better median scaled errors ahead values. Furthermore, vertical gap two curves consistently range seeing (7 14 days ahead), around 0.02 units scaled error scale. look different angle, considering horizontal gap curves, can infer something quite bit interesting: 7-day-ahead forecasts, median scaled error “Cases” model (indicated horizontal gray line) comparable 12-day-ahead forecasts “Cases + Facebook” model. using % CLI--community signal Facebook survey buys us around 4 extra days lead time forecasting problem, striking. might imagine, different forecast targets yield different lead times (14-day-ahead forecasts, appears around 2 3 days lead time), added value survey signal clear throughout.","code":"# Consider a number of leads leads <- 5:20  res <- case_fb_mods(dates, leads) err_by_lead <- res %>%   drop_na() %>% # Restrict to common time   mutate(across(err1:err2, ~ .x / err0)) %>%   ungroup() %>%   select(-err0) %>%   pivot_longer(     names_to = \"model\", values_to = \"err\",     cols = -c(geo_value, forecast_date, lead)   ) %>%   mutate(model = factor(model, labels = model_names[1:2])) %>%   group_by(model, lead) %>%   summarise(err = median(err)) %>%   ungroup()  ggplot(err_by_lead, aes(x = lead, y = err)) +   geom_line(aes(color = model)) +   geom_point(aes(color = model)) +   scale_color_manual(values = c(\"black\", ggplot_colors)) +   geom_hline(     yintercept = err_by_lead %>%       filter(lead %in% 7, model == \"Cases\") %>% pull(err),     linetype = 2, color = \"gray\"   ) +   labs(     title = \"Forecasting errors by number of days ahead\",     subtitle = sprintf(       \"Over all counties with at least %i cumulative cases\",       case_num     ),     x = \"Number of days ahead\", y = \"Median scaled error\"   ) +   theme_bw() # + theme(legend.position = \"bottom\", legend.title = element_blank())"},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/symptom-surveys.html","id":"wrap-up","dir":"Articles","previous_headings":"Introduction","what":"Wrap-Up","title":"Can symptoms surveys improve COVID-19 forecasts?","text":"vignette, ’ve shown either Facebook Google % CLI--community signals can improve accuracy short-term forecasts county-level COVID-19 case rates. significance improvements apparent Facebook signal, thanks much larger test period. either signal, magnitude improvement offered seems modest nontrivial, especially forecasting problem difficult first place. reiterate just demo. analysis fairly simple lacks qualities ’d expect truly comprehensive, realistic forecasting analysis. reflection, let’s discuss three possible areas improve: models considered simple autoregressive structures standard time series improved various ways (including, considering relevant dimensions like mobility measures, county health metrics, etc.). forecasts produced point rather distributional forecasts. , predict single number, rather entire distribution happens 7 14 days ahead. Distributional forecasts portray uncertainty transparent way, important practice. way trained forecast models account data latency revisions, critical issues. (retrospective) forecast date, t0t_0, constructed forecasts training data fetched API today, “” day writing , “” forecast date. matters nearly signals subject latency go multiple revisions. flip side, example far away realistic. models examined actually different Delphi’s forecasters production. Also, way fit quantile regression models code extends immediately multiple quantile regression (just requires changing parameter quantile_levels call quantile_reg()). lastly, ’s fairly easy change data acquisition step code data gets pulled “” forecast date (requires specifying parameter as_of call pub_covidcast() change per forecast date). Hopefully preliminary findings gotten excited possible uses symptom survey data. practice, try hand implementing suggested improvements develop novel analytic approach extract insights data.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/update.html","id":"main-goal-of-the-addupdateremove-and-adjust-functions","dir":"Articles","previous_headings":"","what":"Main goal of the add/update/remove and adjust functions","title":"Using the add/update/remove and adjust functions","text":"primary goal update adjust functions allow user modify step, layer, epi_recipe, frosting, part epi_workflow create new object time wish make change pre-processing, fitting, post-processing. context pre-processing, goal update functions add/remove/update epi_recipe step . , add_epi_recipe(), update_epi_recipe(), remove_epi_recipe() add/update/remove entire epi_recipe epi_workflow well adjust_epi_recipe() adjust particular step epi_recipe epi_workflow step number name. model, one may Add_model(), Update_model(), Remove_model() epi_workflow.1 post-processing, goal update frosting object layer , add_frosting(), remove_frosting(), update_frosting() add/update/remove entire frosting object epi_workflow well adjust_frosting() adjust particular layer frosting epi_workflow number name. summary function uses processing step shown following table: Since adding/removing/updating frosting well adjusting layer frosting object proceeds way performing tasks epi_recipe, focus implementing epi_recipe vignette briefly go examples frosting object.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/update.html","id":"addupdateremove-an-epi_recipe-in-an-epi_workflow","dir":"Articles","previous_headings":"","what":"Add/update/remove an epi_recipe in an epi_workflow","title":"Using the add/update/remove and adjust functions","text":"start built-case_death_rate_subset dataset contains JHU daily COVID-19 cases deaths state take subset Nov. 1, 2021 Dec. 31, 2021 four states Alaska, California, New York, South Carolina. , construct simple epi_recipe object named r, lag death rates 0, 7, 14 days, lead death rate 14 days, omit NA values predictors outcomes (set skip = TRUE skip processing outcome variable recipe baked). add recipe epi_workflow object inputting r add_epi_recipe() function: may go add fitted linear model epi_workflow: stage, suppose decide overhaul recipe different set pre-processing steps want make multiple changes existing steps, desire keep remainder epi_workflow . can use update_epi_recipe() function trade current recipe r another recipe r2 wf follows: can see output wf depicts sequence steps r2 instead r, indicates update successful. longer approach achieve end use remove_epi_recipe() remove old recipe add_epi_recipe() add new one. hood, update_epi_recipe() function operates way. add_epi_recipe() remove_epi_recipe() functions offload workflows versions functions much possible. main reason using epipredict version ensure retain epi_workflow class. see , let’s look happens remove current epi_recipe using workflows::remove_recipe() inspect class wf: can observe wf longer epi_workflow workflow. demoted workflow. epi_workflows workflows, workflows epi_workflows, meaning may compatibility issues limitations tools may used epipredict package plain workflow object. Now, checked happens epi_recipe remove , note actually store change wf. Hence, epi_workflow remains unchanged. One thing notice workflow output model fit remains r recipe. illustrates important point - operations performed using old recipe updated automatically. careful fit model using new recipe, r2. Similarly, predictions made using old recipe, re-generated using version epi_workflow contains updated recipe. can use Update_model() replace model used wf, fit : Alternatively, may use Remove_model() followed Add_model() combination effect.","code":"jhu <- case_death_rate_subset %>%   dplyr::filter(time_value >= as.Date(\"2021-11-01\"), geo_value %in% c(\"ak\", \"ca\", \"ny\", \"sc\"))  jhu #> An `epi_df` object, 244 x 4 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-31 19:08:25.791826 #>  #> # A tibble: 244 × 4 #>    geo_value time_value case_rate death_rate #>  * <chr>     <date>         <dbl>      <dbl> #>  1 ak        2021-11-01      87.9      0.494 #>  2 ca        2021-11-01      15.6      0.239 #>  3 ny        2021-11-01      19.9      0.177 #>  4 sc        2021-11-01      16.0      0.531 #>  5 ak        2021-11-02      83.2      0.395 #>  6 ca        2021-11-02      15.5      0.201 #>  7 ny        2021-11-02      20.3      0.171 #>  8 sc        2021-11-02      15.6      0.550 #>  9 ak        2021-11-03      85.2      0.415 #> 10 ca        2021-11-03      15.4      0.186 #> # ℹ 234 more rows r <- epi_recipe(jhu) %>%   step_epi_lag(death_rate, lag = c(0, 7, 14)) %>%   step_epi_ahead(death_rate, ahead = 14) %>%   step_naomit(all_predictors()) %>%   step_naomit(all_outcomes(), skip = TRUE) wf <- epi_workflow() %>%   add_epi_recipe(r)  wf #>  #> ══ Epi Workflow ════════════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: None #> Postprocessor: None #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #>  #> 4 Recipe steps. #> 1. step_epi_lag() #> 2. step_epi_ahead() #> 3. step_naomit() #> 4. step_naomit() #> # Fit a linear model wf <- epi_workflow(r, parsnip::linear_reg()) %>% fit(jhu)  wf #>  #> ══ Epi Workflow [trained] ══════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: linear_reg() #> Postprocessor: None #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #>  #> 4 Recipe steps. #> 1. step_epi_lag() #> 2. step_epi_ahead() #> 3. step_naomit() #> 4. step_naomit() #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #>  #> Call: #> stats::lm(formula = ..y ~ ., data = data) #>  #> Coefficients: #>       (Intercept)   lag_0_death_rate   lag_7_death_rate  lag_14_death_rate   #>           0.43505           -0.75576            0.02826            0.08960 #> r2 <- epi_recipe(jhu) %>%   step_epi_lag(death_rate, lag = c(0, 1, 7, 14)) %>%   step_epi_lag(case_rate, lag = c(0:7, 14)) %>%   step_epi_ahead(death_rate, ahead = 7) %>%   step_epi_naomit()  wf <- update_epi_recipe(wf, r2) wf #>  #> ══ Epi Workflow ════════════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: linear_reg() #> Postprocessor: None #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #>  #> 5 Recipe steps. #> 1. step_epi_lag() #> 2. step_epi_lag() #> 3. step_epi_ahead() #> 4. step_naomit() #> 5. step_naomit() #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #>  #> Call: #> stats::lm(formula = ..y ~ ., data = data) #>  #> Coefficients: #>       (Intercept)   lag_0_death_rate   lag_7_death_rate  lag_14_death_rate   #>           0.43505           -0.75576            0.02826            0.08960 #> wf %>% class() # class before #> [1] \"epi_workflow\" \"workflow\" workflows::remove_recipe(wf) %>% class() # class after removing recipe using workflows function #> [1] \"workflow\" wf #>  #> ══ Epi Workflow ════════════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: linear_reg() #> Postprocessor: None #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #>  #> 5 Recipe steps. #> 1. step_epi_lag() #> 2. step_epi_lag() #> 3. step_epi_ahead() #> 4. step_naomit() #> 5. step_naomit() #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #>  #> Call: #> stats::lm(formula = ..y ~ ., data = data) #>  #> Coefficients: #>       (Intercept)   lag_0_death_rate   lag_7_death_rate  lag_14_death_rate   #>           0.43505           -0.75576            0.02826            0.08960 #> # fit linear model wf <- Update_model(wf, parsnip::linear_reg()) %>% fit(jhu) wf #>  #> ══ Epi Workflow [trained] ══════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: linear_reg() #> Postprocessor: None #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #>  #> 5 Recipe steps. #> 1. step_epi_lag() #> 2. step_epi_lag() #> 3. step_epi_ahead() #> 4. step_naomit() #> 5. step_naomit() #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #>  #> Call: #> stats::lm(formula = ..y ~ ., data = data) #>  #> Coefficients: #>       (Intercept)   lag_0_death_rate   lag_1_death_rate   lag_7_death_rate   #>          0.293291          -0.158682           0.055165          -0.349197   #> lag_14_death_rate    lag_0_case_rate    lag_1_case_rate    lag_2_case_rate   #>         -0.305136           0.009031          -0.009463          -0.005372   #>   lag_3_case_rate    lag_4_case_rate    lag_5_case_rate    lag_6_case_rate   #>         -0.006244           0.004840           0.005537          -0.013347   #>   lag_7_case_rate   lag_14_case_rate   #>          0.011286           0.011721 #>"},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/update.html","id":"addupdateremove-a-frosting-object-in-an-epi_workflow","dir":"Articles","previous_headings":"","what":"Add/update/remove a frosting object in an epi_workflow","title":"Using the add/update/remove and adjust functions","text":"now generate create frosting object post-processing predictions. initial frosting object, f, simply implement predictions fitted epi_workflow: Suppose decide augment post-processing include threshold enforce predictions least 0. well, let’s include forecast target dates separate columns. update frosting leaving remainder epi_workflow , can use update_frosting() function follows: Internally, works removing old frosting followed adding new frosting, just like update recipe model. decide want frosting post-processing , can remove frosting object workflow make predictions follows: can see results p3 p1, simply prediction layer frosting post-processing container.","code":"f <- frosting() %>%   layer_predict()  wf1 <- wf %>% add_frosting(f) p1 <- forecast(wf1) p1 #> An `epi_df` object, 4 x 3 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-31 19:08:25.791826 #>  #> # A tibble: 4 × 3 #>   geo_value time_value   .pred #> * <chr>     <date>       <dbl> #> 1 ak        2021-12-31 -0.206  #> 2 ca        2021-12-31  0.0989 #> 3 ny        2021-12-31  0.289  #> 4 sc        2021-12-31  0.352 # Update frosting in a workflow and predict f2 <- frosting() %>%   layer_predict() %>%   layer_threshold(.pred) %>%   layer_add_forecast_date() %>%   layer_add_target_date()  wf2 <- wf1 %>% update_frosting(f2) p2 <- forecast(wf2) p2 #> An `epi_df` object, 4 x 5 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-31 19:08:25.791826 #>  #> # A tibble: 4 × 5 #>   geo_value time_value  .pred forecast_date target_date #> * <chr>     <date>      <dbl> <date>        <date>      #> 1 ak        2021-12-31 0      2021-12-31    2022-01-07  #> 2 ca        2021-12-31 0.0989 2021-12-31    2022-01-07  #> 3 ny        2021-12-31 0.289  2021-12-31    2022-01-07  #> 4 sc        2021-12-31 0.352  2021-12-31    2022-01-07 update_frosting #> function (x, frosting, ...)  #> { #>     rlang::check_dots_empty() #>     x <- remove_frosting(x) #>     add_frosting(x, frosting) #> } #> <bytecode: 0x55c34d1a5140> #> <environment: namespace:epipredict> wf3 <- wf2 %>% remove_frosting() p3 <- forecast(wf3) p3 #> An `epi_df` object, 4 x 3 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-31 19:08:25.791826 #>  #> # A tibble: 4 × 3 #>   geo_value time_value   .pred #> * <chr>     <date>       <dbl> #> 1 ak        2021-12-31 -0.206  #> 2 ca        2021-12-31  0.0989 #> 3 ny        2021-12-31  0.289  #> 4 sc        2021-12-31  0.352"},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/update.html","id":"adjust-a-single-step-of-an-epi_recipe","dir":"Articles","previous_headings":"","what":"Adjust a single step of an epi_recipe","title":"Using the add/update/remove and adjust functions","text":"Suppose just want change single step epi_recipe (either standalone part epi_workflow). Instead replacing entire epi_recipe, can use adjust_epi_recipe() function. function, step adjusted indicated either step number name which_step parameter. , parameter name update value must inputted .... instance, suppose decide lead death_rate 14 days instead 7. may adjust step wf recipe setting which_step step number order operations, can obtained inspecting r2 tidy summary : Alternatively, may adjust step name specifying full name step, step_epi_ahead, which_step: least two steps recipe share name, specifying name which_step throw error adjust_epi_recipe() intended used modify multiple steps . way, , modify step name another indicate number ordering steps. example, r2 two steps named step_epi_lag - first step lag death rate, second lag case rate. want modify lags case_rate variable, specify step number 2 which_step. adjust recipe directly way adjust recipe workflow. main difference input wf first argument adjust_epi_recipe() rather r2. Note adjust r2 object directly, adjusting recipe epi_workflow. , modify step r2, change automatically transfer wf. need modify recipe wf directly (adjust_epi_recipe() wf) update recipe wf new epi_recipe undergone adjustment (using update_epi_recipe()):","code":"workflows::extract_preprocessor(wf) # step_epi_ahead is the third step in r2 #>  #> ── Epi Recipe ────────────────────────────────────────────────────────────────── #>  #> ── Inputs #> Number of variables by role #> raw:        2 #> geo_value:  1 #> time_value: 1 #>  #> ── Operations #> 1. Lagging: death_rate by 0, 1, 7, 14 #> 2. Lagging: case_rate by 0, 1, 2, 3, 4, 5, 6, 7, 14 #> 3. Leading: death_rate by 7 #> 4. • Removing rows with NA values in: all_predictors() #> 5. • Removing rows with NA values in: all_outcomes() tidy(workflows::extract_preprocessor(wf)) # tidy tibble summary of r2 #> # A tibble: 5 × 6 #>   number operation type      trained skip  id              #>    <int> <chr>     <chr>     <lgl>   <lgl> <chr>           #> 1      1 step      epi_lag   FALSE   FALSE epi_lag_9QeuR   #> 2      2 step      epi_lag   FALSE   FALSE epi_lag_8HfdV   #> 3      3 step      epi_ahead FALSE   FALSE epi_ahead_HIyvQ #> 4      4 step      naomit    FALSE   FALSE naomit_vjF0H    #> 5      5 step      naomit    FALSE   TRUE  naomit_gF0fi  wf <- wf %>% adjust_epi_recipe(which_step = 3, ahead = 14) wf %>% adjust_epi_recipe(which_step = \"step_epi_ahead\", ahead = 14) # not overwrite r2 because same result #>  #> ══ Epi Workflow ════════════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: linear_reg() #> Postprocessor: None #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #>  #> 5 Recipe steps. #> 1. step_epi_lag() #> 2. step_epi_lag() #> 3. step_epi_ahead() #> 4. step_naomit() #> 5. step_naomit() #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #>  #> Call: #> stats::lm(formula = ..y ~ ., data = data) #>  #> Coefficients: #>       (Intercept)   lag_0_death_rate   lag_1_death_rate   lag_7_death_rate   #>          0.293291          -0.158682           0.055165          -0.349197   #> lag_14_death_rate    lag_0_case_rate    lag_1_case_rate    lag_2_case_rate   #>         -0.305136           0.009031          -0.009463          -0.005372   #>   lag_3_case_rate    lag_4_case_rate    lag_5_case_rate    lag_6_case_rate   #>         -0.006244           0.004840           0.005537          -0.013347   #>   lag_7_case_rate   lag_14_case_rate   #>          0.011286           0.011721 #> wf <- wf %>% adjust_epi_recipe(which_step = 2, lag = c(0, 1, 7, 14, 21))  workflows::extract_preprocessor(wf) #>  #> ── Epi Recipe ────────────────────────────────────────────────────────────────── #>  #> ── Inputs #> Number of variables by role #> raw:        2 #> geo_value:  1 #> time_value: 1 #>  #> ── Operations #> 1. Lagging: death_rate by 0, 1, 7, 14 #> 2. Lagging: case_rate by 0, 1, 7, 14, 21 #> 3. Leading: death_rate by 14 #> 4. • Removing rows with NA values in: all_predictors() #> 5. • Removing rows with NA values in: all_outcomes() adjust_epi_recipe(r2, which_step = 2, lag = c(0, 1, 7, 14, 21)) # should be same result as above #>  #> ── Epi Recipe ────────────────────────────────────────────────────────────────── #>  #> ── Inputs #> Number of variables by role #> raw:        2 #> geo_value:  1 #> time_value: 1 #>  #> ── Operations #> 1. Lagging: death_rate by 0, 1, 7, 14 #> 2. Lagging: case_rate by 0, 1, 7, 14, 21 #> 3. Leading: death_rate by 7 #> 4. • Removing rows with NA values in: all_predictors() #> 5. • Removing rows with NA values in: all_outcomes() r2 <- adjust_epi_recipe(r2, which_step = 2, lag = 0:21)  workflows::extract_preprocessor(wf) #>  #> ── Epi Recipe ────────────────────────────────────────────────────────────────── #>  #> ── Inputs #> Number of variables by role #> raw:        2 #> geo_value:  1 #> time_value: 1 #>  #> ── Operations #> 1. Lagging: death_rate by 0, 1, 7, 14 #> 2. Lagging: case_rate by 0, 1, 7, 14, 21 #> 3. Leading: death_rate by 14 #> 4. • Removing rows with NA values in: all_predictors() #> 5. • Removing rows with NA values in: all_outcomes()"},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/update.html","id":"adjust-a-single-layer-of-a-frosting","dir":"Articles","previous_headings":"","what":"Adjust a single layer of a frosting","title":"Using the add/update/remove and adjust functions","text":"Adjusting layer frosting object proceeds way adjusting step epi_recipe . want change single layer frosting (either standalone object part epi_workflow), can use adjust_frosting() function wherein layer adjusted indicated either number name which_layer parameter. addition, argument name update value must inputted .... Let’s work frosting object directly instead working epi_workflow simple, illustrative example. Recall frosting f2 following layers: Suppose decide change upper bound prediction threshold 10 instead Inf. can adjust layer frosting object setting which_layer layer number, 3 (can found inspecting f2 tidy(f2)): Alternatively, may adjust layer specifying full name, layer_threshold, which_layer, achieve result:","code":"f2 #>  #> ── Frosting ──────────────────────────────────────────────────────────────────── #>  #> ── Layers #> 1. Creating predictions: \"<calculated>\" #> 2. Thresholding predictions: .pred to [0, Inf) #> 3. Adding forecast date: \"<calculated>\" #> 4. Adding target date: \"<calculated>\" f2 <- f2 %>% adjust_frosting(which_layer = 2, upper = 10)  f2 #>  #> ── Frosting ──────────────────────────────────────────────────────────────────── #>  #> ── Layers #> 1. Creating predictions: \"<calculated>\" #> 2. Thresholding predictions: .pred to [0, 10] #> 3. Adding forecast date: \"<calculated>\" #> 4. Adding target date: \"<calculated>\" f2 %>% adjust_frosting(which_layer = \"layer_threshold\", upper = 10) # not overwrite f2 because same result #>  #> ── Frosting ──────────────────────────────────────────────────────────────────── #>  #> ── Layers #> 1. Creating predictions: \"<calculated>\" #> 2. Thresholding predictions: .pred to [0, 10] #> 3. Adding forecast date: \"<calculated>\" #> 4. Adding target date: \"<calculated>\""},{"path":"https://cmu-delphi.github.io/epipredict/dev/articles/update.html","id":"on-the-tidy-method-to-inspect-an-epi_recipe-or-a-frosting-object","dir":"Articles","previous_headings":"","what":"On the tidy method to inspect an epi_recipe or a frosting object","title":"Using the add/update/remove and adjust functions","text":"tidy method, used epi_recipe, return data frame contains specific overview information recipe including operation number, operation class (either “step” “check”), type method, boolean value indicate whether prep() used estimate operation, boolean value indicate whether step applied bake() called, id operation. contrast, printing epi_recipe object shows inputs (number roles variables) well ordering brief written summary operations: general structure persists compare output frosting object tidy tibble. However, longer output specific recipe roles recipe output trained skip columns tidy tibble . Thus, output frosting object tidy tibble simplified comparison epi_recipe.","code":"tidy(r2) #> # A tibble: 5 × 6 #>   number operation type      trained skip  id              #>    <int> <chr>     <chr>     <lgl>   <lgl> <chr>           #> 1      1 step      epi_lag   FALSE   FALSE epi_lag_9QeuR   #> 2      2 step      epi_lag   FALSE   FALSE epi_lag_8HfdV   #> 3      3 step      epi_ahead FALSE   FALSE epi_ahead_HIyvQ #> 4      4 step      naomit    FALSE   FALSE naomit_vjF0H    #> 5      5 step      naomit    FALSE   TRUE  naomit_gF0fi r2 #>  #> ── Epi Recipe ────────────────────────────────────────────────────────────────── #>  #> ── Inputs #> Number of variables by role #> raw:        2 #> geo_value:  1 #> time_value: 1 #>  #> ── Operations #> 1. Lagging: death_rate by 0, 1, 7, 14 #> 2. Lagging: case_rate by 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, #> 16, #> 3. 17, 18, 19... #> 4. Leading: death_rate by 7 #> 5. • Removing rows with NA values in: all_predictors() #> 6. • Removing rows with NA values in: all_outcomes() f #>  #> ── Frosting ──────────────────────────────────────────────────────────────────── #>  #> ── Layers #> 1. Creating predictions: \"<calculated>\"  tidy(f) #> # A tibble: 1 × 4 #>   number operation type    id                    #>    <int> <chr>     <chr>   <chr>                 #> 1      1 layer     predict predict_default_qZ3vE"},{"path":"https://cmu-delphi.github.io/epipredict/dev/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Daniel J. McDonald. Author, maintainer. Ryan Tibshirani. Author. Dmitry Shemetov. Author. David Weber. Author. CMU's Delphi Research Group. Copyright holder, funder. Logan Brooks. Author. Rachel Lobay. Author. Maggie Liu. Contributor. Ken Mawer. Contributor. Chloe . Contributor. Jacob Bien. Contributor.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"McDonald D, Tibshirani R, Shemetov D, Weber D, Brooks L, Lobay R (2024). epipredict: Basic epidemiology forecasting methods. R package version 0.1.2, https://cmu-delphi.github.io/epipredict, https://github.com/cmu-delphi/epipredict/.","code":"@Manual{,   title = {epipredict: Basic epidemiology forecasting methods},   author = {Daniel J. McDonald and Ryan Tibshirani and Dmitry Shemetov and David Weber and Logan Brooks and Rachel Lobay},   year = {2024},   note = {R package version 0.1.2,     https://cmu-delphi.github.io/epipredict},   url = {https://github.com/cmu-delphi/epipredict/}, }"},{"path":"https://cmu-delphi.github.io/epipredict/dev/index.html","id":"epipredict","dir":"","previous_headings":"","what":"Basic epidemiology forecasting methods","title":"Basic epidemiology forecasting methods","text":"Note: package currently development may work expected. Please file bug reports issues repo, best address quickly.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Basic epidemiology forecasting methods","text":"install (unless ’re making changes package, use stable version):","code":"# Stable version pak::pkg_install(\"cmu-delphi/epipredict@main\")  # Dev version pak::pkg_install(\"cmu-delphi/epipredict@dev\")"},{"path":"https://cmu-delphi.github.io/epipredict/dev/index.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"Basic epidemiology forecasting methods","text":"can view documentation main branch https://cmu-delphi.github.io/epipredict.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/index.html","id":"goals-for-epipredict","dir":"","previous_headings":"","what":"Goals for epipredict","title":"Basic epidemiology forecasting methods","text":"hope provide: Baseline flatline forecaster Autoregressive forecaster Autoregressive classifier CDC FluSight flatline forecaster Preprocessor: things data model training Trainer: train model data, resulting fitted model object Predictor: make predictions, using fitted model object Postprocessor: things predictions returning Target audiences: Basic. data, calls forecaster default arguments. Intermediate. Wants examine changes arguments, take advantage built flexibility. Advanced. Wants write forecasters. Maybe willing build components. Advanced user find task relatively easy. Examples tasks illustrated vignettes articles. See also (progress) Forecasting Book.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/index.html","id":"intermediate-example","dir":"","previous_headings":"","what":"Intermediate example","title":"Basic epidemiology forecasting methods","text":"package comes built-historical data illustration, --date versions downloaded {epidatr} package processed using {epiprocess}.[1] create train simple auto-regressive forecaster predict death rate two weeks future using past (lagged) deaths cases, use following function. case, used number different lags case rate, using 3 weekly lags death rate (predictors). result fitted model object used time future create different forecasts, well set predicted values (prediction intervals) location 14 days last available time value data. fitted model involved preprocessing data appropriately generate lagged predictors, estimating linear model stats::lm() postprocessing results meaningful epidemiological tasks. can also examine predictions. results show distributional forecast produced using data end 2021 14th January 2022. prediction death rate per 100K inhabitants available every state (geo_value) along 90% predictive interval. epidemiological signals non-Covid related illnesses also available {epidatr} interfaces directly Delphi’s Epidata API","code":"library(epipredict) case_death_rate_subset #> An `epi_df` object, 20,496 x 4 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-31 12:08:25.791826 #>  #> # A tibble: 20,496 × 4 #>    geo_value time_value case_rate death_rate #>  * <chr>     <date>         <dbl>      <dbl> #>  1 ak        2020-12-31      35.9      0.158 #>  2 al        2020-12-31      65.1      0.438 #>  3 ar        2020-12-31      66.0      1.27  #>  4 as        2020-12-31       0        0     #>  5 az        2020-12-31      76.8      1.10  #>  6 ca        2020-12-31      96.0      0.751 #>  7 co        2020-12-31      35.8      0.649 #>  8 ct        2020-12-31      52.1      0.819 #>  9 dc        2020-12-31      31.0      0.601 #> 10 de        2020-12-31      65.2      0.807 #> # ℹ 20,486 more rows two_week_ahead <- arx_forecaster(   case_death_rate_subset,   outcome = \"death_rate\",   predictors = c(\"case_rate\", \"death_rate\"),   args_list = arx_args_list(     lags = list(c(0, 1, 2, 3, 7, 14), c(0, 7, 14)),     ahead = 14   ) ) two_week_ahead #> ══ A basic forecaster of type ARX Forecaster ═══════════════════════════════ #>  #> This forecaster was fit on 2024-01-29 15:10:01. #>  #> Training data was an <epi_df> with: #> • Geography: state, #> • Time type: day, #> • Using data up-to-date as of: 2022-05-31 12:08:25. #>  #> ── Predictions ───────────────────────────────────────────────────────────── #>  #> A total of 56 predictions are available for #> • 56 unique geographic regions, #> • At forecast date: 2021-12-31, #> • For target date: 2022-01-14. #> two_week_ahead$epi_workflow #>  #> ══ Epi Workflow [trained] ══════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: linear_reg() #> Postprocessor: Frosting #>  #> ── Preprocessor ──────────────────────────────────────────────────────────── #>  #> 6 Recipe steps. #> 1. step_epi_lag() #> 2. step_epi_lag() #> 3. step_epi_ahead() #> 4. step_naomit() #> 5. step_naomit() #> 6. step_training_window() #>  #> ── Model ─────────────────────────────────────────────────────────────────── #>  #> Call: #> stats::lm(formula = ..y ~ ., data = data) #>  #> Coefficients: #>       (Intercept)    lag_0_case_rate    lag_1_case_rate    lag_2_case_rate   #>        -0.0073358          0.0030365          0.0012467          0.0009536   #>   lag_3_case_rate    lag_7_case_rate   lag_14_case_rate   lag_0_death_rate   #>         0.0011425          0.0012481          0.0003041          0.1351769   #>  lag_7_death_rate  lag_14_death_rate   #>         0.1471127          0.1062473 #>  #> ── Postprocessor ─────────────────────────────────────────────────────────── #>  #> 5 Frosting layers. #> 1. layer_predict() #> 2. layer_residual_quantiles() #> 3. layer_add_forecast_date() #> 4. layer_add_target_date() #> 5. layer_threshold() #> two_week_ahead$predictions #> # A tibble: 56 × 5 #>    geo_value .pred        .pred_distn forecast_date target_date #>    <chr>     <dbl>             <dist> <date>        <date>      #>  1 ak        0.449 quantiles(0.45)[2] 2021-12-31    2022-01-14  #>  2 al        0.574 quantiles(0.57)[2] 2021-12-31    2022-01-14  #>  3 ar        0.673 quantiles(0.67)[2] 2021-12-31    2022-01-14  #>  4 as        0     quantiles(0.12)[2] 2021-12-31    2022-01-14  #>  5 az        0.679 quantiles(0.68)[2] 2021-12-31    2022-01-14  #>  6 ca        0.575 quantiles(0.57)[2] 2021-12-31    2022-01-14  #>  7 co        0.862 quantiles(0.86)[2] 2021-12-31    2022-01-14  #>  8 ct        1.07  quantiles(1.07)[2] 2021-12-31    2022-01-14  #>  9 dc        2.12  quantiles(2.12)[2] 2021-12-31    2022-01-14  #> 10 de        1.09  quantiles(1.09)[2] 2021-12-31    2022-01-14  #> # ℹ 46 more rows"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/Add_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Add a model to an epi_workflow — Add_model","title":"Add a model to an epi_workflow — Add_model","text":"Add model epi_workflow","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/Add_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add a model to an epi_workflow — Add_model","text":"","code":"Add_model(x, spec, ..., formula = NULL)  Remove_model(x)  Update_model(x, spec, ..., formula = NULL)  # S3 method for class 'epi_workflow' Add_model(x, spec, ..., formula = NULL)  # S3 method for class 'epi_workflow' Remove_model(x)  # S3 method for class 'epi_workflow' Update_model(x, spec, ..., formula = NULL)  # S3 method for class 'workflow' Add_model(x, spec, ..., formula = NULL)  # S3 method for class 'workflow' Remove_model(x)  # S3 method for class 'workflow' Update_model(x, spec, ..., formula = NULL)  add_model(x, spec, ..., formula = NULL)  remove_model(x)  update_model(x, spec, ..., formula = NULL)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/Add_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add a model to an epi_workflow — Add_model","text":"x epi_workflow. spec parsnip model specification. ... used. formula optional formula override specify terms model. Typically, terms extracted formula recipe preprocessing methods. However, models (like survival bayesian models) use formula preprocess, specify structure model. cases, formula specifying model structure must passed unchanged model call . argument used purposes.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/Add_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add a model to an epi_workflow — Add_model","text":"x, updated new, updated, removed model.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/Add_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add a model to an epi_workflow — Add_model","text":"behaviour workflows::add_model() also ensures returned object epi_workflow. family called Add_* / Update_* / Remove_* avoid masking related functions {workflows}. also provide aliases lower-case names. However, event {workflows} loaded {epipredict}, may fail function properly.","code":""},{"path":[]},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/Add_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add a model to an epi_workflow — Add_model","text":"","code":"library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union jhu <- case_death_rate_subset %>%   filter(time_value > \"2021-11-01\", geo_value %in% c(\"ak\", \"ca\", \"ny\"))  r <- epi_recipe(jhu) %>%   step_epi_lag(death_rate, lag = c(0, 7, 14)) %>%   step_epi_ahead(death_rate, ahead = 7)  rf_model <- rand_forest(mode = \"regression\")  wf <- epi_workflow(r)  wf <- wf %>% Add_model(rf_model) wf #>  #> ══ Epi Workflow ════════════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: rand_forest() #> Postprocessor: None #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #>  #> 2 Recipe steps. #> 1. step_epi_lag() #> 2. step_epi_ahead() #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #> Random Forest Model Specification (regression) #>  #> Computational engine: ranger  #>  #>   lm_model <- linear_reg()  wf <- Update_model(wf, lm_model) wf #>  #> ══ Epi Workflow ════════════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: linear_reg() #> Postprocessor: None #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #>  #> 2 Recipe steps. #> 1. step_epi_lag() #> 2. step_epi_ahead() #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #> Linear Regression Model Specification (regression) #>  #> Computational engine: lm  #>  #>   wf <- Remove_model(wf) wf #>  #> ══ Epi Workflow ════════════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: None #> Postprocessor: None #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #>  #> 2 Recipe steps. #> 1. step_epi_lag() #> 2. step_epi_ahead() #>  #>"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/add_epi_recipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Add an epi_recipe to a workflow — add_epi_recipe","title":"Add an epi_recipe to a workflow — add_epi_recipe","text":"Add epi_recipe workflow","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/add_epi_recipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add an epi_recipe to a workflow — add_epi_recipe","text":"","code":"add_epi_recipe(x, recipe, ..., blueprint = default_epi_recipe_blueprint())  remove_epi_recipe(x)  update_epi_recipe(x, recipe, ..., blueprint = default_epi_recipe_blueprint())"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/add_epi_recipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add an epi_recipe to a workflow — add_epi_recipe","text":"x workflow epi_workflow recipe epi recipe recipe ... used blueprint hardhat blueprint used fine tuning preprocessing default_epi_recipe_blueprint() used. Note preprocessing done separate preprocessing might done automatically underlying model.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/add_epi_recipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add an epi_recipe to a workflow — add_epi_recipe","text":"x, updated new recipe preprocessor.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/add_epi_recipe.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add an epi_recipe to a workflow — add_epi_recipe","text":"add_epi_recipe behaviour workflows::add_recipe() sets different default blueprint automatically handle epiprocess::epi_df data.","code":""},{"path":[]},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/add_epi_recipe.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add an epi_recipe to a workflow — add_epi_recipe","text":"","code":"library(dplyr) library(recipes) #>  #> Attaching package: ‘recipes’ #> The following object is masked from ‘package:stats’: #>  #>     step  jhu <- case_death_rate_subset %>%   filter(time_value > \"2021-08-01\") %>%   arrange(geo_value, time_value)  r <- epi_recipe(jhu) %>%   step_epi_lag(death_rate, lag = c(0, 7, 14)) %>%   step_epi_ahead(death_rate, ahead = 7) %>%   step_epi_lag(case_rate, lag = c(0, 7, 14)) %>%   step_naomit(all_predictors()) %>%   step_naomit(all_outcomes(), skip = TRUE)  workflow <- epi_workflow() %>%   add_epi_recipe(r)  workflow #>  #> ══ Epi Workflow ════════════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: None #> Postprocessor: None #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #>  #> 5 Recipe steps. #> 1. step_epi_lag() #> 2. step_epi_ahead() #> 3. step_epi_lag() #> 4. step_naomit() #> 5. step_naomit() #>  #>   r2 <- epi_recipe(jhu) %>%   step_epi_lag(death_rate, lag = c(0, 7, 14)) %>%   step_epi_ahead(death_rate, ahead = 7)  workflow <- update_epi_recipe(workflow, r2)  workflow <- remove_epi_recipe(workflow)  workflow #>  #> ══ Epi Workflow ════════════════════════════════════════════════════════════════ #> Preprocessor: None #> Model: None #> Postprocessor: None #>  #>"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/add_frosting.html","id":null,"dir":"Reference","previous_headings":"","what":"Add frosting to a workflow — add_frosting","title":"Add frosting to a workflow — add_frosting","text":"Add frosting workflow","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/add_frosting.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add frosting to a workflow — add_frosting","text":"","code":"add_frosting(x, frosting, ...)  remove_frosting(x)  update_frosting(x, frosting, ...)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/add_frosting.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add frosting to a workflow — add_frosting","text":"x workflow frosting frosting object created using frosting(). ... used.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/add_frosting.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add frosting to a workflow — add_frosting","text":"x, updated new frosting postprocessor","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/add_frosting.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add frosting to a workflow — add_frosting","text":"","code":"library(dplyr) jhu <- case_death_rate_subset %>%   filter(time_value > \"2021-11-01\", geo_value %in% c(\"ak\", \"ca\", \"ny\")) r <- epi_recipe(jhu) %>%   step_epi_lag(death_rate, lag = c(0, 7, 14)) %>%   step_epi_ahead(death_rate, ahead = 7)  wf <- epi_workflow(r, linear_reg()) %>% fit(jhu) latest <- jhu %>%   filter(time_value >= max(time_value) - 14)  # Add frosting to a workflow and predict f <- frosting() %>%   layer_predict() %>%   layer_naomit(.pred) wf1 <- wf %>% add_frosting(f) p1 <- predict(wf1, latest) p1 #> An `epi_df` object, 3 x 3 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-31 19:08:25.791826 #>  #> # A tibble: 3 × 3 #>   geo_value time_value .pred #> * <chr>     <date>     <dbl> #> 1 ak        2021-12-31 0.245 #> 2 ca        2021-12-31 0.313 #> 3 ny        2021-12-31 0.295  # Update frosting in a workflow and predict f2 <- frosting() %>% layer_predict() wf2 <- wf1 %>% update_frosting(f2) p2 <- predict(wf2, latest) p2 #> An `epi_df` object, 108 x 3 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-31 19:08:25.791826 #>  #> # A tibble: 108 × 3 #>    geo_value time_value .pred #>  * <chr>     <date>     <dbl> #>  1 ak        2021-12-10    NA #>  2 ca        2021-12-10    NA #>  3 ny        2021-12-10    NA #>  4 ak        2021-12-11    NA #>  5 ca        2021-12-11    NA #>  6 ny        2021-12-11    NA #>  7 ak        2021-12-12    NA #>  8 ca        2021-12-12    NA #>  9 ny        2021-12-12    NA #> 10 ak        2021-12-13    NA #> # ℹ 98 more rows  # Remove frosting from the workflow and predict wf3 <- wf2 %>% remove_frosting() p3 <- predict(wf3, latest) p3 #> An `epi_df` object, 108 x 3 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-31 19:08:25.791826 #>  #> # A tibble: 108 × 3 #>    geo_value time_value .pred #>  * <chr>     <date>     <dbl> #>  1 ak        2021-12-10    NA #>  2 ca        2021-12-10    NA #>  3 ny        2021-12-10    NA #>  4 ak        2021-12-11    NA #>  5 ca        2021-12-11    NA #>  6 ny        2021-12-11    NA #>  7 ak        2021-12-12    NA #>  8 ca        2021-12-12    NA #>  9 ny        2021-12-12    NA #> 10 ak        2021-12-13    NA #> # ℹ 98 more rows"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/add_layer.html","id":null,"dir":"Reference","previous_headings":"","what":"Add layer to a frosting object — add_layer","title":"Add layer to a frosting object — add_layer","text":"Add layer frosting object","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/add_layer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add layer to a frosting object — add_layer","text":"","code":"add_layer(frosting, object)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/add_layer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add layer to a frosting object — add_layer","text":"frosting frosting postprocessor object frosting layer","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/add_layer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add layer to a frosting object — add_layer","text":"updated frosting postprocessor","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/add_shifted_columns.html","id":null,"dir":"Reference","previous_headings":"","what":"backend for both bake.step_epi_ahead and bake.step_epi_lag, performs the checks missing in epi_shift_single — add_shifted_columns","title":"backend for both bake.step_epi_ahead and bake.step_epi_lag, performs the checks missing in epi_shift_single — add_shifted_columns","text":"backend bake.step_epi_ahead bake.step_epi_lag, performs checks missing epi_shift_single","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/add_shifted_columns.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"backend for both bake.step_epi_ahead and bake.step_epi_lag, performs the checks missing in epi_shift_single — add_shifted_columns","text":"","code":"add_shifted_columns(new_data, object)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/adjust_epi_recipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Adjust a step in an epi_workflow or epi_recipe — adjust_epi_recipe","title":"Adjust a step in an epi_workflow or epi_recipe — adjust_epi_recipe","text":"Make parameter adjustment step either epi_workflow epi_recipe object.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/adjust_epi_recipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adjust a step in an epi_workflow or epi_recipe — adjust_epi_recipe","text":"","code":"adjust_epi_recipe(   x,   which_step,   ...,   blueprint = default_epi_recipe_blueprint() )  # S3 method for class 'epi_workflow' adjust_epi_recipe(   x,   which_step,   ...,   blueprint = default_epi_recipe_blueprint() )  # S3 method for class 'epi_recipe' adjust_epi_recipe(   x,   which_step,   ...,   blueprint = default_epi_recipe_blueprint() )"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/adjust_epi_recipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adjust a step in an epi_workflow or epi_recipe — adjust_epi_recipe","text":"x epi_workflow epi_recipe object which_step number name step adjust ... Used input parameter adjustment blueprint hardhat blueprint used fine tuning preprocessing.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/adjust_epi_recipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adjust a step in an epi_workflow or epi_recipe — adjust_epi_recipe","text":"x, updated adjustment specified epi_recipe step.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/adjust_epi_recipe.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Adjust a step in an epi_workflow or epi_recipe — adjust_epi_recipe","text":"function can either adjust step epi_recipe object step epi_recipe object epi_workflow. step adjusted indicated either step number name (name used, must unique). either case, argument name update value must inputted .... See examples brief illustrations different types updates.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/adjust_epi_recipe.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Adjust a step in an epi_workflow or epi_recipe — adjust_epi_recipe","text":"","code":"library(dplyr) library(workflows) #>  #> Attaching package: ‘workflows’ #> The following objects are masked from ‘package:epipredict’: #>  #>     add_model, remove_model, update_model  jhu <- case_death_rate_subset %>%   filter(time_value > \"2021-11-01\", geo_value %in% c(\"ak\", \"ca\", \"ny\")) r <- epi_recipe(jhu) %>%   step_epi_lag(death_rate, lag = c(0, 7, 14)) %>%   step_epi_ahead(death_rate, ahead = 7) %>%   step_epi_naomit()  wf <- epi_workflow(r, parsnip::linear_reg()) %>% fit(jhu) latest <- jhu %>%   filter(time_value >= max(time_value) - 14)  # Adjust `step_epi_ahead` to have an ahead value of 14 # in the `epi_workflow` # Option 1. Using the step number: wf2 <- wf %>% adjust_epi_recipe(which_step = 2, ahead = 14) extract_preprocessor(wf2) #>  #> ── Epi Recipe ────────────────────────────────────────────────────────────────── #>  #> ── Inputs  #> Number of variables by role #> raw:        2 #> geo_value:  1 #> time_value: 1 #>  #> ── Operations  #> 1. Lagging: death_rate by 0, 7, 14 #> 2. Leading: death_rate by 14 #> 3. • Removing rows with NA values in: all_predictors() #> 4. • Removing rows with NA values in: all_outcomes() # Option 2. Using the step name: wf3 <- wf %>% adjust_epi_recipe(which_step = \"step_epi_ahead\", ahead = 14) extract_preprocessor(wf3) #>  #> ── Epi Recipe ────────────────────────────────────────────────────────────────── #>  #> ── Inputs  #> Number of variables by role #> raw:        2 #> geo_value:  1 #> time_value: 1 #>  #> ── Operations  #> 1. Lagging: death_rate by 0, 7, 14 #> 2. Leading: death_rate by 14 #> 3. • Removing rows with NA values in: all_predictors() #> 4. • Removing rows with NA values in: all_outcomes()  # Adjust `step_epi_ahead` to have an ahead value of 14 # in the `epi_recipe` # Option 1. Using the step number r2 <- r %>% adjust_epi_recipe(which_step = 2, ahead = 14) r2 #>  #> ── Epi Recipe ────────────────────────────────────────────────────────────────── #>  #> ── Inputs  #> Number of variables by role #> raw:        2 #> geo_value:  1 #> time_value: 1 #>  #> ── Operations  #> 1. Lagging: death_rate by 0, 7, 14 #> 2. Leading: death_rate by 14 #> 3. • Removing rows with NA values in: all_predictors() #> 4. • Removing rows with NA values in: all_outcomes() # Option 2. Using the step name r3 <- r %>% adjust_epi_recipe(which_step = \"step_epi_ahead\", ahead = 14) r3 #>  #> ── Epi Recipe ────────────────────────────────────────────────────────────────── #>  #> ── Inputs  #> Number of variables by role #> raw:        2 #> geo_value:  1 #> time_value: 1 #>  #> ── Operations  #> 1. Lagging: death_rate by 0, 7, 14 #> 2. Leading: death_rate by 14 #> 3. • Removing rows with NA values in: all_predictors() #> 4. • Removing rows with NA values in: all_outcomes()"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/adjust_frosting.html","id":null,"dir":"Reference","previous_headings":"","what":"Adjust a layer in an epi_workflow or frosting — adjust_frosting","title":"Adjust a layer in an epi_workflow or frosting — adjust_frosting","text":"Make parameter adjustment layer either epi_workflow frosting object.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/adjust_frosting.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adjust a layer in an epi_workflow or frosting — adjust_frosting","text":"","code":"adjust_frosting(x, which_layer, ...)  # S3 method for class 'epi_workflow' adjust_frosting(x, which_layer, ...)  # S3 method for class 'frosting' adjust_frosting(x, which_layer, ...)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/adjust_frosting.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adjust a layer in an epi_workflow or frosting — adjust_frosting","text":"x epi_workflow frosting object which_layer number name layer adjust ... Used input parameter adjustment","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/adjust_frosting.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adjust a layer in an epi_workflow or frosting — adjust_frosting","text":"x, updated adjustment specified frosting layer.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/adjust_frosting.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Adjust a layer in an epi_workflow or frosting — adjust_frosting","text":"function can either adjust layer frosting object layer frosting object epi_workflow. layer adjusted indicated either layer number name (name used, must unique). either case, argument name update value must inputted .... See examples brief illustrations different types updates.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/adjust_frosting.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Adjust a layer in an epi_workflow or frosting — adjust_frosting","text":"","code":"library(dplyr) jhu <- case_death_rate_subset %>%   filter(time_value > \"2021-11-01\", geo_value %in% c(\"ak\", \"ca\", \"ny\")) r <- epi_recipe(jhu) %>%   step_epi_lag(death_rate, lag = c(0, 7, 14)) %>%   step_epi_ahead(death_rate, ahead = 7) %>%   step_epi_naomit()  wf <- epi_workflow(r, linear_reg()) %>% fit(jhu)  # in the frosting from the workflow f1 <- frosting() %>%   layer_predict() %>%   layer_threshold(.pred)  wf2 <- wf %>% add_frosting(f1)  # Adjust `layer_threshold` to have an upper bound of 1 # in the `epi_workflow` # Option 1. Using the layer number: wf2 <- wf2 %>% adjust_frosting(which_layer = 2, upper = 1) extract_frosting(wf2) #>  #> ── Frosting ──────────────────────────────────────────────────────────────────── #>  #> ── Layers  #> 1. Creating predictions: \"<calculated>\" #> 2. Thresholding predictions: .pred to [0, 1] # Option 2. Using the layer name: wf3 <- wf2 %>% adjust_frosting(which_layer = \"layer_threshold\", upper = 1) extract_frosting(wf3) #>  #> ── Frosting ──────────────────────────────────────────────────────────────────── #>  #> ── Layers  #> 1. Creating predictions: \"<calculated>\" #> 2. Thresholding predictions: .pred to [0, 1]  # Adjust `layer_threshold` to have an upper bound of 5 # in the `frosting` object # Option 1. Using the layer number: f2 <- f1 %>% adjust_frosting(which_layer = 2, upper = 5) f2 #>  #> ── Frosting ──────────────────────────────────────────────────────────────────── #>  #> ── Layers  #> 1. Creating predictions: \"<calculated>\" #> 2. Thresholding predictions: .pred to [0, 5] # Option 2. Using the layer name f3 <- f1 %>% adjust_frosting(which_layer = \"layer_threshold\", upper = 5) f3 #>  #> ── Frosting ──────────────────────────────────────────────────────────────────── #>  #> ── Layers  #> 1. Creating predictions: \"<calculated>\" #> 2. Thresholding predictions: .pred to [0, 5]"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/apply_frosting.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply postprocessing to a fitted workflow — apply_frosting","title":"Apply postprocessing to a fitted workflow — apply_frosting","text":"function intended internal use. implements postprocessing inside predict() method fitted workflow.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/apply_frosting.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply postprocessing to a fitted workflow — apply_frosting","text":"","code":"apply_frosting(workflow, ...)  # Default S3 method apply_frosting(workflow, components, ...)  # S3 method for class 'epi_workflow' apply_frosting(workflow, components, new_data, type = NULL, opts = list(), ...)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/apply_frosting.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply postprocessing to a fitted workflow — apply_frosting","text":"workflow object class workflow ... additional arguments passed methods components list components containing model information. updated returned layer. mold - output calling hardhat::mold() workflow. contains information preprocessing, including recipe. forged - output calling hardhat::forge() workflow. predictors outcomes new_data. three components predictors, outcomes (new_data), extras (usually rest data, including keys). keys - put keys (time_value, geo_value, others) ease. new_data data frame containing new predictors preprocess predict type, opts forwarded (along ...) predict.model_fit() slather() supported layers","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/arx_args_list.html","id":null,"dir":"Reference","previous_headings":"","what":"ARX forecaster argument constructor — arx_args_list","title":"ARX forecaster argument constructor — arx_args_list","text":"Constructs list arguments arx_forecaster().","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/arx_args_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ARX forecaster argument constructor — arx_args_list","text":"","code":"arx_args_list(   lags = c(0L, 7L, 14L),   ahead = 7L,   n_training = Inf,   forecast_date = NULL,   target_date = NULL,   adjust_latency = c(\"none\", \"extend_ahead\", \"extend_lags\", \"locf\"),   warn_latency = TRUE,   quantile_levels = c(0.05, 0.95),   symmetrize = TRUE,   nonneg = TRUE,   quantile_by_key = character(0L),   check_enough_data_n = NULL,   check_enough_data_epi_keys = NULL,   ... )"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/arx_args_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ARX forecaster argument constructor — arx_args_list","text":"lags Vector List. Positive integers enumerating lags use autoregressive-type models (days). default, unnamed list lags set correspond order predictors. ahead Integer. Number time steps ahead (days) forecast date forecasts produced. n_training Integer. upper limit number rows per key used training (time unit epi_df). forecast_date Date. date forecast occurring. default NULL determine automatically either maximum time value data latency adjustment (default case), as_of date epi_data adjust_latency non-NULL. target_date Date. date forecast. default NULL determine automatically forecast_date + ahead. adjust_latency Character. One methods step_adjust_latency(), \"none\" (case adjustment). forecast_date last day data, determines shift model account difference. options : \"none\" default, assumes forecast_date last day data \"extend_ahead\": increase ahead latency relative last day data. example, last day data 3 days ago, ahead becomes ahead+3. \"extend_lags\": increase lags relative actual forecast date. example, lags c(0,7,14) last day data 3 days ago, lags become c(3,10,17). warn_latency default, step_adjust_latency warns user latency large. FALSE, warning turned . quantile_levels Vector NULL. vector probabilities produce prediction intervals. created computing quantiles training residuals. NULL value result point forecasts . symmetrize Logical. default TRUE calculates symmetric prediction intervals. argument applies residual quantiles used. applicable trainer = quantile_reg(), example. nonneg Logical. default TRUE enforces nonnegative predictions hard-thresholding 0. quantile_by_key Character vector. Groups residuals listed keys calculating residual quantiles. See by_key argument layer_residual_quantiles() information. default, character(0) performs grouping. argument applies residual quantiles used. applicable trainer = quantile_reg(), example. check_enough_data_n Integer. lower limit number rows per epi_key required training. NULL, check ignored. check_enough_data_epi_keys Character vector. character vector column names group data check threshold within group. Useful training per group (example, per geo_value). ... Space handle future expansions (unused).","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/arx_args_list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"ARX forecaster argument constructor — arx_args_list","text":"list containing updated parameter choices class arx_flist.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/arx_args_list.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"ARX forecaster argument constructor — arx_args_list","text":"","code":"arx_args_list() #> • lags : 0, 7, and 14 #> • ahead : 7 #> • n_training : Inf #> • quantile_levels : 0.05 and 0.95 #> • forecast_date : \"NULL\" #> • target_date : \"NULL\" #> • adjust_latency : \"none\" #> • warn_latency : TRUE #> • symmetrize : TRUE #> • nonneg : TRUE #> • max_lags : 14 #> • quantile_by_key : \"_empty_\" #> • check_enough_data_n : \"NULL\" #> • check_enough_data_epi_keys : \"NULL\" arx_args_list(symmetrize = FALSE) #> • lags : 0, 7, and 14 #> • ahead : 7 #> • n_training : Inf #> • quantile_levels : 0.05 and 0.95 #> • forecast_date : \"NULL\" #> • target_date : \"NULL\" #> • adjust_latency : \"none\" #> • warn_latency : TRUE #> • symmetrize : FALSE #> • nonneg : TRUE #> • max_lags : 14 #> • quantile_by_key : \"_empty_\" #> • check_enough_data_n : \"NULL\" #> • check_enough_data_epi_keys : \"NULL\" arx_args_list(quantile_levels = c(.1, .3, .7, .9), n_training = 120) #> • lags : 0, 7, and 14 #> • ahead : 7 #> • n_training : 120 #> • quantile_levels : 0.1, 0.3, 0.7, and 0.9 #> • forecast_date : \"NULL\" #> • target_date : \"NULL\" #> • adjust_latency : \"none\" #> • warn_latency : TRUE #> • symmetrize : TRUE #> • nonneg : TRUE #> • max_lags : 14 #> • quantile_by_key : \"_empty_\" #> • check_enough_data_n : \"NULL\" #> • check_enough_data_epi_keys : \"NULL\""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/arx_class_args_list.html","id":null,"dir":"Reference","previous_headings":"","what":"ARX classifier argument constructor — arx_class_args_list","title":"ARX classifier argument constructor — arx_class_args_list","text":"Constructs list arguments arx_classifier().","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/arx_class_args_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ARX classifier argument constructor — arx_class_args_list","text":"","code":"arx_class_args_list(   lags = c(0L, 7L, 14L),   ahead = 7L,   n_training = Inf,   forecast_date = NULL,   target_date = NULL,   adjust_latency = c(\"none\", \"extend_ahead\", \"extend_lags\", \"locf\"),   warn_latency = TRUE,   outcome_transform = c(\"growth_rate\", \"lag_difference\"),   breaks = 0.25,   horizon = 7L,   method = c(\"rel_change\", \"linear_reg\"),   log_scale = FALSE,   additional_gr_args = list(),   check_enough_data_n = NULL,   check_enough_data_epi_keys = NULL,   ... )"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/arx_class_args_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ARX classifier argument constructor — arx_class_args_list","text":"lags Vector List. Positive integers enumerating lags use autoregressive-type models (days). default, unnamed list lags set correspond order predictors. ahead Integer. Number time steps ahead (days) forecast date forecasts produced. n_training Integer. upper limit number rows per key used training (time unit epi_df). forecast_date Date. date forecast occurring. default NULL determine automatically either maximum time value data latency adjustment (default case), as_of date epi_data adjust_latency non-NULL. target_date Date. date forecast. default NULL determine automatically forecast_date + ahead. adjust_latency Character. One methods step_adjust_latency(), \"none\" (case adjustment). forecast_date last day data, determines shift model account difference. options : \"none\" default, assumes forecast_date last day data \"extend_ahead\": increase ahead latency relative last day data. example, last day data 3 days ago, ahead becomes ahead+3. \"extend_lags\": increase lags relative actual forecast date. example, lags c(0,7,14) last day data 3 days ago, lags become c(3,10,17). warn_latency default, step_adjust_latency warns user latency large. FALSE, warning turned . outcome_transform Scalar character. Whether outcome created using growth rates (predictors ) lagged differences. second case closer requirements 2022-23 CDC Flusight Hospitalization Experimental Target. See Classification Vignette details create reasonable baseline case. Selecting \"growth_rate\" (default) uses epiprocess::growth_rate() create outcome using additional arguments . Choosing \"lag_difference\" instead simply uses change value selected horizon. breaks Vector. vector breaks turn real-valued growth rates discrete classes. default gives binary upswing classification McDonald, Bien, Green, Hu, et al.. coincides default trainer = parsnip::logistic_reg() argument arx_classifier(). However, multiclass classification also supported (e.g. breaks = c(-.2, .25)) provided trainer = parsnip::multinom_reg() (another multiclass trainer) used well. sliently expanded cover entire real line (default become breaks = c(-Inf, .25, Inf)) used discretize response. different behaviour recipes::step_cut() creates classes cover range training data. horizon Scalar integer. passed h argument epiprocess::growth_rate(). determines amount data used calculate growth rate. method Character. Options available growth rate calculation. log_scale Scalar logical. Whether compute growth rates log scale. additional_gr_args List. Optional arguments controlling growth rate calculation. See epiprocess::growth_rate() related Vignette details. check_enough_data_n Integer. lower limit number rows per epi_key required training. NULL, check ignored. check_enough_data_epi_keys Character vector. character vector column names group data check threshold within group. Useful training per group (example, per geo_value). ... Space handle future expansions (unused).","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/arx_class_args_list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"ARX classifier argument constructor — arx_class_args_list","text":"list containing updated parameter choices class arx_clist.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/arx_class_args_list.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"ARX classifier argument constructor — arx_class_args_list","text":"","code":"arx_class_args_list() #> • lags : 0, 7, and 14 #> • ahead : 7 #> • n_training : Inf #> • breaks : -Inf, 0.25, and Inf #> • forecast_date : \"NULL\" #> • target_date : \"NULL\" #> • adjust_latency : \"none\" #> • outcome_transform : \"growth_rate\" #> • max_lags : 14 #> • horizon : 7 #> • method : \"rel_change\" #> • log_scale : FALSE #> • additional_gr_args : \"_empty_\" #> • check_enough_data_n : \"NULL\" #> • check_enough_data_epi_keys : \"NULL\"  # 3-class classsification, # also needs arx_classifier(trainer = parsnip::multinom_reg()) arx_class_args_list(breaks = c(-.2, .25)) #> • lags : 0, 7, and 14 #> • ahead : 7 #> • n_training : Inf #> • breaks : -Inf, -0.2, 0.25, and Inf #> • forecast_date : \"NULL\" #> • target_date : \"NULL\" #> • adjust_latency : \"none\" #> • outcome_transform : \"growth_rate\" #> • max_lags : 14 #> • horizon : 7 #> • method : \"rel_change\" #> • log_scale : FALSE #> • additional_gr_args : \"_empty_\" #> • check_enough_data_n : \"NULL\" #> • check_enough_data_epi_keys : \"NULL\""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/arx_class_epi_workflow.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a template arx_classifier workflow — arx_class_epi_workflow","title":"Create a template arx_classifier workflow — arx_class_epi_workflow","text":"function creates unfit workflow use arx_classifier(). useful want make small modifications classifier fitting predicting. Supplying trainer function may alter returned epi_workflow object can omitted.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/arx_class_epi_workflow.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a template arx_classifier workflow — arx_class_epi_workflow","text":"","code":"arx_class_epi_workflow(   epi_data,   outcome,   predictors,   trainer = parsnip::logistic_reg(),   args_list = arx_class_args_list() )"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/arx_class_epi_workflow.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a template arx_classifier workflow — arx_class_epi_workflow","text":"epi_data epi_df object outcome character (scalar) specifying outcome (epi_df). Note arx_forecaster(), expected real-valued. Conversion data unordered classes handled internally based breaks argument arx_class_args_list(). discrete classes already epi_df, recommended code classifier scratch using epi_recipe(). predictors character vector giving column(s) predictor variables. defaults outcome. However, manually specified, variables specifically mentioned used. (outcome added.) default, equals outcome. manually specified, add outcome variable, make sure specify . trainer {parsnip} model describing type estimation. now, enforce mode = \"classification\". Typical values parsnip::logistic_reg() parsnip::multinom_reg(). complicated trainers like parsnip::naive_Bayes() parsnip::rand_forest() can also used. May NULL like decide later. args_list list customization arguments determine type forecasting model. See arx_class_args_list().","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/arx_class_epi_workflow.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a template arx_classifier workflow — arx_class_epi_workflow","text":"unfit epi_workflow.","code":""},{"path":[]},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/arx_class_epi_workflow.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a template arx_classifier workflow — arx_class_epi_workflow","text":"","code":"library(dplyr) jhu <- case_death_rate_subset %>%   filter(time_value >= as.Date(\"2021-11-01\"))  arx_class_epi_workflow(jhu, \"death_rate\", c(\"case_rate\", \"death_rate\")) #>  #> ══ Epi Workflow ════════════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: logistic_reg() #> Postprocessor: Frosting #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #>  #> 8 Recipe steps. #> 1. step_growth_rate() #> 2. step_epi_lag() #> 3. step_epi_lag() #> 4. step_epi_ahead() #> 5. step_mutate() #> 6. step_naomit() #> 7. step_naomit() #> 8. step_training_window() #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #> Logistic Regression Model Specification (classification) #>  #> Computational engine: glm  #>  #>  #> ── Postprocessor ─────────────────────────────────────────────────────────────── #>  #> 3 Frosting layers. #> 1. layer_predict() #> 2. layer_add_forecast_date() #> 3. layer_add_target_date() #>   arx_class_epi_workflow(   jhu,   \"death_rate\",   c(\"case_rate\", \"death_rate\"),   trainer = multinom_reg(),   args_list = arx_class_args_list(     breaks = c(-.05, .1), ahead = 14,     horizon = 14, method = \"linear_reg\"   ) ) #>  #> ══ Epi Workflow ════════════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: multinom_reg() #> Postprocessor: Frosting #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #>  #> 8 Recipe steps. #> 1. step_growth_rate() #> 2. step_epi_lag() #> 3. step_epi_lag() #> 4. step_epi_ahead() #> 5. step_mutate() #> 6. step_naomit() #> 7. step_naomit() #> 8. step_training_window() #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #> Multinomial Regression Model Specification (classification) #>  #> Computational engine: nnet  #>  #>  #> ── Postprocessor ─────────────────────────────────────────────────────────────── #>  #> 3 Frosting layers. #> 1. layer_predict() #> 2. layer_add_forecast_date() #> 3. layer_add_target_date() #>"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/arx_classifier.html","id":null,"dir":"Reference","previous_headings":"","what":"Direct autoregressive classifier with covariates — arx_classifier","title":"Direct autoregressive classifier with covariates — arx_classifier","text":"autoregressive classification model epiprocess::epi_df data. \"direct\" forecasting, meaning estimates class particular target horizon.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/arx_classifier.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Direct autoregressive classifier with covariates — arx_classifier","text":"","code":"arx_classifier(   epi_data,   outcome,   predictors,   trainer = logistic_reg(),   args_list = arx_class_args_list() )"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/arx_classifier.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Direct autoregressive classifier with covariates — arx_classifier","text":"epi_data epi_df object outcome character (scalar) specifying outcome (epi_df). Note arx_forecaster(), expected real-valued. Conversion data unordered classes handled internally based breaks argument arx_class_args_list(). discrete classes already epi_df, recommended code classifier scratch using epi_recipe(). predictors character vector giving column(s) predictor variables. defaults outcome. However, manually specified, variables specifically mentioned used. (outcome added.) default, equals outcome. manually specified, add outcome variable, make sure specify . trainer {parsnip} model describing type estimation. now, enforce mode = \"classification\". Typical values parsnip::logistic_reg() parsnip::multinom_reg(). complicated trainers like parsnip::naive_Bayes() parsnip::rand_forest() can also used. args_list list customization arguments determine type forecasting model. See arx_class_args_list().","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/arx_classifier.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Direct autoregressive classifier with covariates — arx_classifier","text":"list (1) predictions epi_df predicted classes (2) epi_workflow, list encapsulates entire estimation workflow","code":""},{"path":[]},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/arx_classifier.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Direct autoregressive classifier with covariates — arx_classifier","text":"","code":"library(dplyr) jhu <- case_death_rate_subset %>%   filter(time_value >= as.Date(\"2021-11-01\"))  out <- arx_classifier(jhu, \"death_rate\", c(\"case_rate\", \"death_rate\"))  out <- arx_classifier(   jhu,   \"death_rate\",   c(\"case_rate\", \"death_rate\"),   trainer = parsnip::multinom_reg(),   args_list = arx_class_args_list(     breaks = c(-.05, .1), ahead = 14,     horizon = 14, method = \"linear_reg\"   ) )"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/arx_fcast_epi_workflow.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a template arx_forecaster workflow — arx_fcast_epi_workflow","title":"Create a template arx_forecaster workflow — arx_fcast_epi_workflow","text":"function creates unfit workflow use arx_forecaster(). useful want make small modifications forecaster fitting predicting. Supplying trainer function may alter returned epi_workflow object (e.g., intend use quantile_reg()) can omitted.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/arx_fcast_epi_workflow.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a template arx_forecaster workflow — arx_fcast_epi_workflow","text":"","code":"arx_fcast_epi_workflow(   epi_data,   outcome,   predictors = outcome,   trainer = linear_reg(),   args_list = arx_args_list() )"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/arx_fcast_epi_workflow.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a template arx_forecaster workflow — arx_fcast_epi_workflow","text":"epi_data epi_df object outcome character (scalar) specifying outcome (epi_df). predictors character vector giving column(s) predictor variables. defaults outcome. However, manually specified, variables specifically mentioned used. (outcome added.) default, equals outcome. manually specified, add outcome variable, make sure specify . trainer {parsnip} model describing type estimation. now, enforce mode = \"regression\". May NULL like decide later. args_list list customization arguments determine type forecasting model. See arx_args_list().","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/arx_fcast_epi_workflow.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a template arx_forecaster workflow — arx_fcast_epi_workflow","text":"unfitted epi_workflow.","code":""},{"path":[]},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/arx_fcast_epi_workflow.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a template arx_forecaster workflow — arx_fcast_epi_workflow","text":"","code":"library(dplyr) jhu <- case_death_rate_subset %>%   filter(time_value >= as.Date(\"2021-12-01\"))  arx_fcast_epi_workflow(   jhu, \"death_rate\",   c(\"case_rate\", \"death_rate\") ) #>  #> ══ Epi Workflow ════════════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: linear_reg() #> Postprocessor: Frosting #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #>  #> 6 Recipe steps. #> 1. step_epi_lag() #> 2. step_epi_lag() #> 3. step_epi_ahead() #> 4. step_naomit() #> 5. step_naomit() #> 6. step_training_window() #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #> Linear Regression Model Specification (regression) #>  #> Computational engine: lm  #>  #>  #> ── Postprocessor ─────────────────────────────────────────────────────────────── #>  #> 5 Frosting layers. #> 1. layer_predict() #> 2. layer_residual_quantiles() #> 3. layer_add_forecast_date() #> 4. layer_add_target_date() #> 5. layer_threshold() #>   arx_fcast_epi_workflow(jhu, \"death_rate\",   c(\"case_rate\", \"death_rate\"),   trainer = quantile_reg(),   args_list = arx_args_list(quantile_levels = 1:9 / 10) ) #>  #> ══ Epi Workflow ════════════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: quantile_reg() #> Postprocessor: Frosting #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #>  #> 6 Recipe steps. #> 1. step_epi_lag() #> 2. step_epi_lag() #> 3. step_epi_ahead() #> 4. step_naomit() #> 5. step_naomit() #> 6. step_training_window() #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #> quantile reg Model Specification (regression) #>  #> Main Arguments: #>   quantile_levels = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9) #>   method = br #>  #> Computational engine: rq  #>  #>  #> ── Postprocessor ─────────────────────────────────────────────────────────────── #>  #> 6 Frosting layers. #> 1. layer_predict() #> 2. layer_quantile_distn() #> 3. layer_point_from_distn() #> 4. layer_add_forecast_date() #> 5. layer_add_target_date() #> 6. layer_threshold() #>"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/arx_forecaster.html","id":null,"dir":"Reference","previous_headings":"","what":"Direct autoregressive forecaster with covariates — arx_forecaster","title":"Direct autoregressive forecaster with covariates — arx_forecaster","text":"autoregressive forecasting model epiprocess::epi_df data. \"direct\" forecasting, meaning estimates model particular target horizon.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/arx_forecaster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Direct autoregressive forecaster with covariates — arx_forecaster","text":"","code":"arx_forecaster(   epi_data,   outcome,   predictors = outcome,   trainer = linear_reg(),   args_list = arx_args_list() )"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/arx_forecaster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Direct autoregressive forecaster with covariates — arx_forecaster","text":"epi_data epi_df object outcome character (scalar) specifying outcome (epi_df). predictors character vector giving column(s) predictor variables. defaults outcome. However, manually specified, variables specifically mentioned used. (outcome added.) default, equals outcome. manually specified, add outcome variable, make sure specify . trainer {parsnip} model describing type estimation. now, enforce mode = \"regression\". args_list list customization arguments determine type forecasting model. See arx_args_list().","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/arx_forecaster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Direct autoregressive forecaster with covariates — arx_forecaster","text":"list (1) predictions epi_df predicted values (2) epi_workflow, list encapsulates entire estimation workflow","code":""},{"path":[]},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/arx_forecaster.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Direct autoregressive forecaster with covariates — arx_forecaster","text":"","code":"jhu <- case_death_rate_subset %>%   dplyr::filter(time_value >= as.Date(\"2021-12-01\"))  out <- arx_forecaster(   jhu, \"death_rate\",   c(\"case_rate\", \"death_rate\") )  out <- arx_forecaster(jhu, \"death_rate\",   c(\"case_rate\", \"death_rate\"),   trainer = quantile_reg(),   args_list = arx_args_list(quantile_levels = 1:9 / 10) )"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/augment.epi_workflow.html","id":null,"dir":"Reference","previous_headings":"","what":"Augment data with predictions — augment.epi_workflow","title":"Augment data with predictions — augment.epi_workflow","text":"Augment data predictions","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/augment.epi_workflow.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Augment data with predictions — augment.epi_workflow","text":"","code":"# S3 method for class 'epi_workflow' augment(x, new_data, ...)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/augment.epi_workflow.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Augment data with predictions — augment.epi_workflow","text":"x trained epi_workflow new_data epi_df predictors ... Arguments passed predict method.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/augment.epi_workflow.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Augment data with predictions — augment.epi_workflow","text":"new_data additional columns containing predicted values","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/autoplot-epipred.html","id":null,"dir":"Reference","previous_headings":"","what":"Automatically plot an epi_workflow or canned_epipred object — autoplot-epipred","title":"Automatically plot an epi_workflow or canned_epipred object — autoplot-epipred","text":"fit workflow, training data displayed, response default. predictions NULL point interval forecasts shown well. Unfit workflows result error, (can simply call autoplot() original epi_df).","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/autoplot-epipred.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Automatically plot an epi_workflow or canned_epipred object — autoplot-epipred","text":"","code":"# S3 method for class 'epi_workflow' autoplot(   object,   predictions = NULL,   .levels = c(0.5, 0.8, 0.95),   ...,   .color_by = c(\"all_keys\", \"geo_value\", \"other_keys\", \".response\", \"all\", \"none\"),   .facet_by = c(\".response\", \"other_keys\", \"all_keys\", \"geo_value\", \"all\", \"none\"),   .base_color = \"dodgerblue4\",   .point_pred_color = \"orange\",   .max_facets = Inf )  # S3 method for class 'canned_epipred' autoplot(   object,   ...,   .color_by = c(\"all_keys\", \"geo_value\", \"other_keys\", \".response\", \"all\", \"none\"),   .facet_by = c(\".response\", \"other_keys\", \"all_keys\", \"geo_value\", \"all\", \"none\"),   .base_color = \"dodgerblue4\",   .point_pred_color = \"orange\",   .max_facets = Inf )"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/autoplot-epipred.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Automatically plot an epi_workflow or canned_epipred object — autoplot-epipred","text":"object epi_workflow predictions data frame predictions. NULL, original data shown. .levels numeric vector levels plot prediction bands. 3 levels begins difficult see. ... Ignored .color_by variables determine color(s) used plot lines. Options include: all_keys - default uses interaction key variables including geo_value geo_value - geo_value other_keys - available keys geo_value .response - numeric variables (y-axis) - uses interaction keys numeric variables none - coloring aesthetic applied .facet_by Similar .color_by except default display response. .base_color available, prediction bands shown color. .point_pred_color available, point forecasts shown color. .max_facets Cut number facets displayed. Especially useful testing many geo_value's keys.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/autoplot-epipred.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Automatically plot an epi_workflow or canned_epipred object — autoplot-epipred","text":"","code":"library(dplyr) jhu <- case_death_rate_subset %>%   filter(time_value >= as.Date(\"2021-11-01\"))  r <- epi_recipe(jhu) %>%   step_epi_lag(death_rate, lag = c(0, 7, 14)) %>%   step_epi_ahead(death_rate, ahead = 7) %>%   step_epi_lag(case_rate, lag = c(0, 7, 14)) %>%   step_epi_naomit()  f <- frosting() %>%   layer_residual_quantiles(     quantile_levels = c(.025, .1, .25, .75, .9, .975)   ) %>%   layer_threshold(starts_with(\".pred\")) %>%   layer_add_target_date()  wf <- epi_workflow(r, linear_reg(), f) %>% fit(jhu)  autoplot(wf)   latest <- jhu %>% filter(time_value >= max(time_value) - 14) preds <- predict(wf, latest) autoplot(wf, preds, .max_facets = 4)   # ------- Show multiple horizons  p <- lapply(c(7, 14, 21, 28), function(h) {   r <- epi_recipe(jhu) %>%     step_epi_lag(death_rate, lag = c(0, 7, 14)) %>%     step_epi_ahead(death_rate, ahead = h) %>%     step_epi_lag(case_rate, lag = c(0, 7, 14)) %>%     step_epi_naomit()   ewf <- epi_workflow(r, linear_reg(), f) %>% fit(jhu)   forecast(ewf) })  p <- do.call(rbind, p) autoplot(wf, p, .max_facets = 4)   # ------- Plotting canned forecaster output  jhu <- case_death_rate_subset %>%   filter(time_value >= as.Date(\"2021-11-01\")) flat <- flatline_forecaster(jhu, \"death_rate\") autoplot(flat, .max_facets = 4) #> Warning: Removed 7 rows containing missing values or values outside the scale range #> (`geom_line()`).   arx <- arx_forecaster(jhu, \"death_rate\", c(\"case_rate\", \"death_rate\"),   args_list = arx_args_list(ahead = 14L) ) autoplot(arx, .max_facets = 6)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/case_death_rate_subset.html","id":null,"dir":"Reference","previous_headings":"","what":"Subset of JHU daily state cases and deaths — case_death_rate_subset","title":"Subset of JHU daily state cases and deaths — case_death_rate_subset","text":"data source confirmed COVID-19 cases deaths based reports made available Center Systems Science Engineering Johns Hopkins University. example data ranges Dec 31, 2020 Dec 31, 2021, includes states.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/case_death_rate_subset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subset of JHU daily state cases and deaths — case_death_rate_subset","text":"","code":"case_death_rate_subset"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/case_death_rate_subset.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Subset of JHU daily state cases and deaths — case_death_rate_subset","text":"tibble 20,496 rows 4 variables: geo_value geographic value associated row measurements. time_value time value associated row measurements. case_rate 7-day average signal number new confirmed COVID-19 cases per 100,000 population, daily death_rate 7-day average signal number new confirmed deaths due COVID-19 per 100,000 population, daily","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/case_death_rate_subset.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Subset of JHU daily state cases and deaths — case_death_rate_subset","text":"object contains modified part COVID-19 Data Repository Center Systems Science Engineering (CSSE) Johns Hopkins University republished COVIDcast Epidata API. data set licensed terms Creative Commons Attribution 4.0 International license Johns Hopkins University behalf Center Systems Science Engineering. Copyright Johns Hopkins University 2020. Modifications: COVIDcast Epidata API: signals taken directly JHU CSSE COVID-19 GitHub repository without changes. 7-day average signals computed Delphi calculating moving averages preceding 7 days, signal June 7 average underlying data June 1 7, inclusive.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/cdc_baseline_args_list.html","id":null,"dir":"Reference","previous_headings":"","what":"CDC baseline forecaster argument constructor — cdc_baseline_args_list","title":"CDC baseline forecaster argument constructor — cdc_baseline_args_list","text":"Constructs list arguments cdc_baseline_forecaster().","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/cdc_baseline_args_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"CDC baseline forecaster argument constructor — cdc_baseline_args_list","text":"","code":"cdc_baseline_args_list(   data_frequency = \"1 week\",   aheads = 1:5,   n_training = Inf,   forecast_date = NULL,   quantile_levels = c(0.01, 0.025, 1:19/20, 0.975, 0.99),   nsims = 100000L,   symmetrize = TRUE,   nonneg = TRUE,   quantile_by_key = \"geo_value\",   ... )"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/cdc_baseline_args_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"CDC baseline forecaster argument constructor — cdc_baseline_args_list","text":"data_frequency Integer string. describes frequency input epi_df. typical FluSight forecasts, \"1 week\". Allowable arguments integers (taken mean numbers days) string like \"7 days\" \"2 weeks\". Currently, periods (days weeks) result error. aheads Integer vector. Unlike arx_forecaster(), effect predicted values. Predictions always recent observation. determines set prediction horizons layer_cdc_flatline_quantiles(). interacts data_frequencyargument. , example, data daily want forecasts 1:4 days ahead, use1:4. However, want one-week predictions, set c(7, 14, 21, 28). data_frequencyis\"1 week\", set 1:4`. n_training Integer. upper limit number rows per key used training (time unit epi_df). forecast_date Date. date forecast occurring. default NULL determine automatically either maximum time value data latency adjustment (default case), as_of date epi_data adjust_latency non-NULL. quantile_levels Vector NULL. vector probabilities produce prediction intervals. created computing quantiles training residuals. NULL value result point forecasts . nsims Positive integer. number draws empirical CDF. samples spaced evenly (0, 1) scale, F_X(x) resulting linear interpolation X scale. achieved stats::quantile() Type 7 (default function). symmetrize Logical. default TRUE calculates symmetric prediction intervals. argument applies residual quantiles used. applicable trainer = quantile_reg(), example. nonneg Logical. Force predictive intervals non-negative. non-negativity forced propagating forward, slightly different behaviour occur using layer_threshold(). quantile_by_key Character vector. Groups residuals listed keys calculating residual quantiles. See by_key argument layer_residual_quantiles() information. default, character(0) performs grouping. argument applies residual quantiles used. applicable trainer = quantile_reg(), example. ... Space handle future expansions (unused).","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/cdc_baseline_args_list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"CDC baseline forecaster argument constructor — cdc_baseline_args_list","text":"list containing updated parameter choices class cdc_flat_fcast.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/cdc_baseline_args_list.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"CDC baseline forecaster argument constructor — cdc_baseline_args_list","text":"","code":"cdc_baseline_args_list() #> • data_frequency : 7 #> • aheads : 1, 2, 3, 4, and 5 #> • n_training : Inf #> • forecast_date : \"NULL\" #> • quantile_levels : 0.01, 0.025, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, #>   0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, …, 0.975, and 0.99 #> • nsims : 100000 #> • symmetrize : TRUE #> • nonneg : TRUE #> • quantile_by_key : \"geo_value\" cdc_baseline_args_list(symmetrize = FALSE) #> • data_frequency : 7 #> • aheads : 1, 2, 3, 4, and 5 #> • n_training : Inf #> • forecast_date : \"NULL\" #> • quantile_levels : 0.01, 0.025, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, #>   0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, …, 0.975, and 0.99 #> • nsims : 100000 #> • symmetrize : FALSE #> • nonneg : TRUE #> • quantile_by_key : \"geo_value\" cdc_baseline_args_list(quantile_levels = c(.1, .3, .7, .9), n_training = 120) #> • data_frequency : 7 #> • aheads : 1, 2, 3, 4, and 5 #> • n_training : 120 #> • forecast_date : \"NULL\" #> • quantile_levels : 0.1, 0.3, 0.7, and 0.9 #> • nsims : 100000 #> • symmetrize : TRUE #> • nonneg : TRUE #> • quantile_by_key : \"geo_value\""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/cdc_baseline_forecaster.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict the future with the most recent value — cdc_baseline_forecaster","title":"Predict the future with the most recent value — cdc_baseline_forecaster","text":"simple forecasting model epiprocess::epi_df data. uses recent observation forecast future date, produces intervals shuffling quantiles residuals \"flatline\" forecast incrementing forward available training data.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/cdc_baseline_forecaster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict the future with the most recent value — cdc_baseline_forecaster","text":"","code":"cdc_baseline_forecaster(   epi_data,   outcome,   args_list = cdc_baseline_args_list() )"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/cdc_baseline_forecaster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict the future with the most recent value — cdc_baseline_forecaster","text":"epi_data epiprocess::epi_df outcome scalar character column name wish predict. args_list list additional arguments created cdc_baseline_args_list() constructor function.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/cdc_baseline_forecaster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict the future with the most recent value — cdc_baseline_forecaster","text":"data frame point interval forecasts aheads (unique horizons) unique combination key_vars.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/cdc_baseline_forecaster.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Predict the future with the most recent value — cdc_baseline_forecaster","text":"default, predictive intervals computed separately combination geo_value epi_data argument. forecaster meant produce exactly CDC Baseline used COVID19ForecastHub","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/cdc_baseline_forecaster.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predict the future with the most recent value — cdc_baseline_forecaster","text":"","code":"library(dplyr) weekly_deaths <- case_death_rate_subset %>%   select(geo_value, time_value, death_rate) %>%   left_join(state_census %>% select(pop, abbr), by = c(\"geo_value\" = \"abbr\")) %>%   mutate(deaths = pmax(death_rate / 1e5 * pop * 7, 0)) %>%   select(-pop, -death_rate) %>%   group_by(geo_value) %>%   epi_slide(~ sum(.$deaths), .window_size = 7, .new_col_name = \"deaths_7dsum\") %>%   ungroup() %>%   filter(weekdays(time_value) == \"Saturday\")  cdc <- cdc_baseline_forecaster(weekly_deaths, \"deaths_7dsum\") preds <- pivot_quantiles_wider(cdc$predictions, .pred_distn)  if (require(ggplot2)) {   forecast_date <- unique(preds$forecast_date)   four_states <- c(\"ca\", \"pa\", \"wa\", \"ny\")   preds %>%     filter(geo_value %in% four_states) %>%     ggplot(aes(target_date)) +     geom_ribbon(aes(ymin = `0.1`, ymax = `0.9`), fill = blues9[3]) +     geom_ribbon(aes(ymin = `0.25`, ymax = `0.75`), fill = blues9[6]) +     geom_line(aes(y = .pred), color = \"orange\") +     geom_line(       data = weekly_deaths %>% filter(geo_value %in% four_states),       aes(x = time_value, y = deaths_7dsum)     ) +     scale_x_date(limits = c(forecast_date - 90, forecast_date + 30)) +     labs(x = \"Date\", y = \"Weekly deaths\") +     facet_wrap(~geo_value, scales = \"free_y\") +     theme_bw() +     geom_vline(xintercept = forecast_date) } #> Loading required package: ggplot2 #>  #> Attaching package: ‘ggplot2’ #> The following object is masked from ‘package:epipredict’: #>  #>     layer #> Warning: Removed 1 row containing missing values or values outside the scale range #> (`geom_line()`). #> Warning: Removed 39 rows containing missing values or values outside the scale range #> (`geom_line()`)."},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/check_enough_train_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Check the dataset contains enough data points. — check_enough_train_data","title":"Check the dataset contains enough data points. — check_enough_train_data","text":"check_enough_train_data creates specification recipe operation check variables contain enough data.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/check_enough_train_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check the dataset contains enough data points. — check_enough_train_data","text":"","code":"check_enough_train_data(   recipe,   ...,   n = NULL,   epi_keys = NULL,   drop_na = TRUE,   role = NA,   trained = FALSE,   columns = NULL,   skip = TRUE,   id = rand_id(\"enough_train_data\") )"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/check_enough_train_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check the dataset contains enough data points. — check_enough_train_data","text":"recipe recipe object. check added sequence operations recipe. ... One selector functions choose variables check. See selections() details. usually want use recipes::all_predictors() . n minimum number data points required training. NULL, total number predictors used. epi_keys character vector column names group data check threshold within group. Useful forecaster trains per group (example, per geo_value). drop_na logical whether count NA values valid rows. role used check since new variables created. trained logical whether selectors ... resolved prep(). columns internal argument tracks columns evaluated check. used user. skip logical. check skipped recipe baked bake()? operations baked prep() run, operations may able conducted new data (e.g. processing outcome variable(s)). Care taken using skip = TRUE may affect computations subsequent operations. id character string unique check identify .","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/check_enough_train_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check the dataset contains enough data points. — check_enough_train_data","text":"check break bake function checked columns enough non-NA values. check passes, nothing changed data.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/check_enough_train_data.html","id":"tidy-results","dir":"Reference","previous_headings":"","what":"tidy() results","title":"Check the dataset contains enough data points. — check_enough_train_data","text":"tidy() check, tibble column terms (selectors variables selected) returned.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/check_interminable_latency.html","id":null,"dir":"Reference","previous_headings":"","what":"warn when the latency is larger than would be reasonable — check_interminable_latency","title":"warn when the latency is larger than would be reasonable — check_interminable_latency","text":"warn latency larger reasonable","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/check_interminable_latency.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"warn when the latency is larger than would be reasonable — check_interminable_latency","text":"","code":"check_interminable_latency(   dataset,   latency_table,   target_columns,   forecast_date,   call = caller_env() )"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/check_interminable_latency.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"warn when the latency is larger than would be reasonable — check_interminable_latency","text":"dataset epi_df latency_table whole collection latencies target_columns names columns adjusting, whether unreasonably latent","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/check_pname.html","id":null,"dir":"Reference","previous_headings":"","what":"Check that newly created variable names don't overlap — check_pname","title":"Check that newly created variable names don't overlap — check_pname","text":"check_pname used slather method ensure newly created variable names overlap existing names. Throws warning check fails, creates random string.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/check_pname.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check that newly created variable names don't overlap — check_pname","text":"","code":"check_pname(res, preds, object, newname = NULL)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/check_pname.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check that newly created variable names don't overlap — check_pname","text":"res data frame tibble newly created variables. preds epi_df tibble containing predictions. object layer object passed slather(). newname string variable names object contain $name element","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/clean_f_name.html","id":null,"dir":"Reference","previous_headings":"","what":"Create short function names — clean_f_name","title":"Create short function names — clean_f_name","text":"Create short function names","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/clean_f_name.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create short function names — clean_f_name","text":"","code":"clean_f_name(.f, max_length = 20L)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/clean_f_name.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create short function names — clean_f_name","text":".f function, character string, lambda. example, mean, \"mean\", ~ mean(.x) \\(x) mean(x, na.rm = TRUE). max_length integer determining long names can ","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/clean_f_name.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create short function names — clean_f_name","text":"character string length max_length (partially) describes function.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/clean_f_name.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create short function names — clean_f_name","text":"","code":"clean_f_name(mean) #> [1] \"mean\" clean_f_name(\"mean\") #> [1] \"mean\" clean_f_name(~ mean(.x, na.rm = TRUE)) #> [1] \"mean(.x, na.rm = ...\" clean_f_name(\\(x) mean(x, na.rm = TRUE)) #> [1] \"[ ]{mean(x, na.r...}\" clean_f_name(function(x) mean(x, na.rm = TRUE, trim = 0.2357862)) #> [1] \"[ ]{mean(x, na.r...}\""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/construct_shift_tibble.html","id":null,"dir":"Reference","previous_headings":"","what":"create a table of the columns to modify, their shifts, and their prefixes — construct_shift_tibble","title":"create a table of the columns to modify, their shifts, and their prefixes — construct_shift_tibble","text":"create table columns modify, shifts, prefixes","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/construct_shift_tibble.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"create a table of the columns to modify, their shifts, and their prefixes — construct_shift_tibble","text":"","code":"construct_shift_tibble(terms_used, recipe, rel_step_type, shift_name)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/count_single_column.html","id":null,"dir":"Reference","previous_headings":"","what":"get the location of the last real value — count_single_column","title":"get the location of the last real value — count_single_column","text":"get location last real value","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/count_single_column.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"get the location of the last real value — count_single_column","text":"","code":"count_single_column(col)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/count_single_column.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"get the location of the last real value — count_single_column","text":"col relevant column","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/dist_quantiles.html","id":null,"dir":"Reference","previous_headings":"","what":"A distribution parameterized by a set of quantiles — dist_quantiles","title":"A distribution parameterized by a set of quantiles — dist_quantiles","text":"distribution parameterized set quantiles","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/dist_quantiles.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A distribution parameterized by a set of quantiles — dist_quantiles","text":"","code":"dist_quantiles(values, quantile_levels)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/dist_quantiles.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A distribution parameterized by a set of quantiles — dist_quantiles","text":"values vector (list vectors) values. quantile_levels vector (list vectors) probabilities corresponding values. creating multiple sets values/quantile_levels resulting different distributions, sizes must match. See examples .","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/dist_quantiles.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A distribution parameterized by a set of quantiles — dist_quantiles","text":"vector class \"distribution\".","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/dist_quantiles.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A distribution parameterized by a set of quantiles — dist_quantiles","text":"","code":"dist_quantiles(1:4, 1:4 / 5) #> <distribution[1]> #> [1] quantiles(2.5)[4] dist_quantiles(list(1:3, 1:4), list(1:3 / 4, 1:4 / 5)) #> <distribution[2]> #> [1] quantiles(2)[3]   quantiles(2.5)[4] dstn <- dist_quantiles(list(1:4, 8:11), c(.2, .4, .6, .8)) dstn #> <distribution[2]> #> [1] quantiles(2.5)[4] quantiles(9.5)[4]  quantile(dstn, p = c(.1, .25, .5, .9)) #> [[1]] #> [1] 0.2952896 1.2500000 2.5000000 4.8267802 #>  #> [[2]] #> [1]  7.29529  8.25000  9.50000 11.82678 #>  median(dstn) #> [1] 2.5 9.5  # it's a bit annoying to inspect the data distributional::parameters(dstn[1]) #>       values    quantile_levels #> 1 1, 2, 3, 4 0.2, 0.4, 0.6, 0.8 nested_quantiles(dstn[1])[[1]] #> # A tibble: 4 × 2 #>   values quantile_levels #>    <dbl>           <dbl> #> 1      1             0.2 #> 2      2             0.4 #> 3      3             0.6 #> 4      4             0.8"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/drop_ignored_keys.html","id":null,"dir":"Reference","previous_headings":"","what":"given a list named by key columns, remove any matching key values keys_to_ignore should have the form list(col_name = c(","title":"given a list named by key columns, remove any matching key values keys_to_ignore should have the form list(col_name = c(","text":"given list named key columns, remove matching key values keys_to_ignore form list(col_name = c(\"value_to_ignore\", \"other_value_to_ignore\"))","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/drop_ignored_keys.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"given a list named by key columns, remove any matching key values keys_to_ignore should have the form list(col_name = c(","text":"","code":"drop_ignored_keys(training, keys_to_ignore)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/epi_recipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a epi_recipe for preprocessing data — epi_recipe","title":"Create a epi_recipe for preprocessing data — epi_recipe","text":"recipe description steps applied data set order prepare data analysis. loose wrapper around recipes::recipe() properly handle additional columns present epi_df","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/epi_recipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a epi_recipe for preprocessing data — epi_recipe","text":"","code":"epi_recipe(x, ...)  # Default S3 method epi_recipe(x, ...)  # S3 method for class 'epi_df' epi_recipe(x, formula = NULL, ..., vars = NULL, roles = NULL)  # S3 method for class 'formula' epi_recipe(formula, data, ...)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/epi_recipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a epi_recipe for preprocessing data — epi_recipe","text":"x, data data frame, tibble, epi_df template data set (see ). always coerced first row avoid memory issues ... arguments passed methods (currently used). formula model formula. -line functions used (e.g. log(x), x:y, etc.) minus signs allowed. types transformations enacted using step functions package. Dots allowed simple multivariate outcome terms (.e. need cbind; see Examples). vars character string column names corresponding variables used context (see ) roles character string (length vars) describes single role variable take. value anything common roles \"outcome\", \"predictor\", \"time_value\", \"geo_value\"","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/epi_recipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a epi_recipe for preprocessing data — epi_recipe","text":"object class recipe sub-objects: var_info tibble containing information original data set columns term_info tibble contains current set terms data set. initially defaults data contained var_info. steps list step  check objects define sequence preprocessing operations applied data. default value NULL template tibble data. initialized data given data argument can different recipe trained.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/epi_recipe.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a epi_recipe for preprocessing data — epi_recipe","text":"","code":"library(dplyr) library(recipes) jhu <- case_death_rate_subset %>%   filter(time_value > \"2021-08-01\") %>%   arrange(geo_value, time_value)  r <- epi_recipe(jhu) %>%   step_epi_lag(death_rate, lag = c(0, 7, 14)) %>%   step_epi_ahead(death_rate, ahead = 7) %>%   step_epi_lag(case_rate, lag = c(0, 7, 14)) %>%   step_naomit(all_predictors()) %>%   # below, `skip` means we don't do this at predict time   step_naomit(all_outcomes(), skip = TRUE)  r #>  #> ── Epi Recipe ────────────────────────────────────────────────────────────────── #>  #> ── Inputs  #> Number of variables by role #> raw:        2 #> geo_value:  1 #> time_value: 1 #>  #> ── Operations  #> 1. Lagging: death_rate by 0, 7, 14 #> 2. Leading: death_rate by 7 #> 3. Lagging: case_rate by 0, 7, 14 #> 4. • Removing rows with NA values in: all_predictors() #> 5. • Removing rows with NA values in: all_outcomes()"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/epi_shift_single.html","id":null,"dir":"Reference","previous_headings":"","what":"Shift predictors while maintaining grouping and time_value ordering — epi_shift_single","title":"Shift predictors while maintaining grouping and time_value ordering — epi_shift_single","text":"lower-level function. performs error checking.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/epi_shift_single.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Shift predictors while maintaining grouping and time_value ordering — epi_shift_single","text":"","code":"epi_shift_single(x, col, shift_val, newname, key_cols)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/epi_shift_single.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Shift predictors while maintaining grouping and time_value ordering — epi_shift_single","text":"x Data frame. shift_val single integer. Negative values produce leads. newname name newly shifted column key_cols vector, NULL. Additional grouping vars.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/epi_shift_single.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Shift predictors while maintaining grouping and time_value ordering — epi_shift_single","text":"list tibbles","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/epi_slide_wrapper.html","id":null,"dir":"Reference","previous_headings":"","what":"Wrapper to handle epi_slide particulars — epi_slide_wrapper","title":"Wrapper to handle epi_slide particulars — epi_slide_wrapper","text":"simplify somewhat future can run epi_slide columns. Surprisingly, lapply several orders magnitude faster using roughly equivalent tidy select style.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/epi_slide_wrapper.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wrapper to handle epi_slide particulars — epi_slide_wrapper","text":"","code":"epi_slide_wrapper(   new_data,   .window_size,   .align,   columns,   fns,   fn_names,   group_keys,   name_prefix )"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/epi_slide_wrapper.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wrapper to handle epi_slide particulars — epi_slide_wrapper","text":"fns vector functions, even length 1. group_keys keys group . likely epi_keys (without time_value)","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/epi_workflow.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an epi_workflow — epi_workflow","title":"Create an epi_workflow — epi_workflow","text":"container object unifies preprocessing, fitting, prediction, postprocessing predictive modeling epidemiological data. extends functionality workflows::workflow() handle typical panel data structures found field. extension handled completely internally, invisible user. intents purposes, operates exactly like workflows::workflow(). details numerous examples, see .","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/epi_workflow.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an epi_workflow — epi_workflow","text":"","code":"epi_workflow(preprocessor = NULL, spec = NULL, postprocessor = NULL)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/epi_workflow.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an epi_workflow — epi_workflow","text":"preprocessor optional preprocessor add workflow. One : formula, passed add_formula(). recipe, passed add_recipe(). workflow_variables() object, passed add_variables(). spec optional parsnip model specification add workflow. Passed add_model(). postprocessor optional postprocessor add workflow. Currently frosting allowed using, add_frosting().","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/epi_workflow.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create an epi_workflow — epi_workflow","text":"new epi_workflow object.","code":""},{"path":[]},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/epi_workflow.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create an epi_workflow — epi_workflow","text":"","code":"jhu <- case_death_rate_subset  r <- epi_recipe(jhu) %>%   step_epi_lag(death_rate, lag = c(0, 7, 14)) %>%   step_epi_ahead(death_rate, ahead = 7) %>%   step_epi_lag(case_rate, lag = c(0, 7, 14)) %>%   step_epi_naomit()  wf <- epi_workflow(r, parsnip::linear_reg())  wf #>  #> ══ Epi Workflow ════════════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: linear_reg() #> Postprocessor: None #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #>  #> 5 Recipe steps. #> 1. step_epi_lag() #> 2. step_epi_ahead() #> 3. step_epi_lag() #> 4. step_naomit() #> 5. step_naomit() #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #> Linear Regression Model Specification (regression) #>  #> Computational engine: lm  #>  #>"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/extract_argument.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract an argument made to a frosting layer or recipe step — extract_argument","title":"Extract an argument made to a frosting layer or recipe step — extract_argument","text":"Extract argument made frosting layer recipe step","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/extract_argument.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract an argument made to a frosting layer or recipe step — extract_argument","text":"","code":"extract_argument(x, name, arg, ...)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/extract_argument.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract an argument made to a frosting layer or recipe step — extract_argument","text":"x epi_workflow, epi_recipe, frosting, step, layer object name name layer arg name argument ... used","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/extract_argument.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract an argument made to a frosting layer or recipe step — extract_argument","text":"object originally passed argument layer step","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/extract_argument.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract an argument made to a frosting layer or recipe step — extract_argument","text":"","code":"f <- frosting() %>%   layer_predict() %>%   layer_residual_quantiles(quantile_levels = c(0.0275, 0.975), symmetrize = FALSE) %>%   layer_naomit(.pred)  extract_argument(f, \"layer_residual_quantiles\", \"symmetrize\") #> [1] FALSE"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/extract_frosting.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract the frosting object from a workflow — extract_frosting","title":"Extract the frosting object from a workflow — extract_frosting","text":"Extract frosting object workflow","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/extract_frosting.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract the frosting object from a workflow — extract_frosting","text":"","code":"extract_frosting(x, ...)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/extract_frosting.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract the frosting object from a workflow — extract_frosting","text":"x epi_workflow object ... used","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/extract_frosting.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract the frosting object from a workflow — extract_frosting","text":"frosting object","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/extrapolate_quantiles.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize a distribution with a set of quantiles — extrapolate_quantiles","title":"Summarize a distribution with a set of quantiles — extrapolate_quantiles","text":"Summarize distribution set quantiles","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/extrapolate_quantiles.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize a distribution with a set of quantiles — extrapolate_quantiles","text":"","code":"extrapolate_quantiles(x, probs, replace_na = TRUE, ...)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/extrapolate_quantiles.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize a distribution with a set of quantiles — extrapolate_quantiles","text":"x distribution vector probs vector probabilities calculate quantiles replace_na logical. x contains NA's, imputed possible (TRUE) retained (FALSE). effects elements class dist_quantiles. ... additional arguments passed quantile method","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/extrapolate_quantiles.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize a distribution with a set of quantiles — extrapolate_quantiles","text":"distribution vector containing dist_quantiles. elements x originally dist_quantiles now superset original quantile_values (union probs).","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/extrapolate_quantiles.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarize a distribution with a set of quantiles — extrapolate_quantiles","text":"","code":"library(distributional) dstn <- dist_normal(c(10, 2), c(5, 10)) extrapolate_quantiles(dstn, probs = c(.25, 0.5, .75)) #> <distribution[2]> #> [1] quantiles(10)[3] quantiles(2)[3]   dstn <- dist_quantiles(list(1:4, 8:11), list(c(.2, .4, .6, .8))) # because this distribution is already quantiles, any extra quantiles are # appended extrapolate_quantiles(dstn, probs = c(.25, 0.5, .75)) #> <distribution[2]> #> [1] quantiles(2.5)[7] quantiles(9.5)[7]  dstn <- c(   dist_normal(c(10, 2), c(5, 10)),   dist_quantiles(list(1:4, 8:11), list(c(.2, .4, .6, .8))) ) extrapolate_quantiles(dstn, probs = c(.25, 0.5, .75)) #> <distribution[4]> #> [1] quantiles(10)[3]  quantiles(2)[3]   quantiles(2.5)[7] quantiles(9.5)[7]"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/fit-epi_workflow.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit an epi_workflow object — fit-epi_workflow","title":"Fit an epi_workflow object — fit-epi_workflow","text":"fit() method epi_workflow object estimates parameters given model set data. Fitting epi_workflow involves two main steps, preprocessing data fitting underlying parsnip model.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/fit-epi_workflow.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit an epi_workflow object — fit-epi_workflow","text":"","code":"# S3 method for class 'epi_workflow' fit(object, data, ..., control = workflows::control_workflow())"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/fit-epi_workflow.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit an epi_workflow object — fit-epi_workflow","text":"object epi_workflow object data epi_df predictors outcomes use fitting epi_workflow ... used control workflows::control_workflow() object","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/fit-epi_workflow.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit an epi_workflow object — fit-epi_workflow","text":"epi_workflow object, updated fit parsnip model object$fit$fit slot.","code":""},{"path":[]},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/fit-epi_workflow.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit an epi_workflow object — fit-epi_workflow","text":"","code":"jhu <- case_death_rate_subset %>%   filter(time_value > \"2021-11-01\", geo_value %in% c(\"ak\", \"ca\", \"ny\"))  r <- epi_recipe(jhu) %>%   step_epi_lag(death_rate, lag = c(0, 7, 14)) %>%   step_epi_ahead(death_rate, ahead = 7)  wf <- epi_workflow(r, parsnip::linear_reg()) %>% fit(jhu) wf #>  #> ══ Epi Workflow [trained] ══════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: linear_reg() #> Postprocessor: None #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #>  #> 2 Recipe steps. #> 1. step_epi_lag() #> 2. step_epi_ahead() #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #>  #> Call: #> stats::lm(formula = ..y ~ ., data = data) #>  #> Coefficients: #>       (Intercept)   lag_0_death_rate   lag_7_death_rate  lag_14_death_rate   #>           0.32848           -0.01957           -0.02176           -0.05895   #>  #>"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/flatline.html","id":null,"dir":"Reference","previous_headings":"","what":"(Internal) implementation of the flatline forecaster — flatline","title":"(Internal) implementation of the flatline forecaster — flatline","text":"internal function used create parsnip::linear_reg() model. somewhat odd behaviour (see ).","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/flatline.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"(Internal) implementation of the flatline forecaster — flatline","text":"","code":"flatline(formula, data)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/flatline.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"(Internal) implementation of the flatline forecaster — flatline","text":"formula lhs single variable. standard usage, actually observed time series shifted forward forecast horizon. right hand side must contain keys (locations) panel data separated plus. observed time series must come last. example   Note function shifting, done outside. data data frame containing least variables used formula. must also contain column time_value giving observed time points.","code":"form <- as.formula(lead7_y ~ state + age + y)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/flatline.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"(Internal) implementation of the flatline forecaster — flatline","text":"S3 object class flatline two components: residuals - tibble keys .resid column contains forecast errors. .pred - tibble keys .pred column containing predictions future data (last observed outcome combination keys.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/flatline.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"(Internal) implementation of the flatline forecaster — flatline","text":"","code":"tib <- data.frame(   y = runif(100),   expand.grid(k = letters[1:4], j = letters[5:9], time_value = 1:5) ) %>%   dplyr::group_by(k, j) %>%   dplyr::mutate(y2 = dplyr::lead(y, 2)) # predict 2 steps ahead flat <- flatline(y2 ~ j + k + y, tib) # predictions for 20 locations sum(!is.na(flat$residuals$.resid)) # 100 residuals, but 40 are NA #> [1] 60"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/flatline_args_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Flatline forecaster argument constructor — flatline_args_list","title":"Flatline forecaster argument constructor — flatline_args_list","text":"Constructs list arguments flatline_forecaster().","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/flatline_args_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Flatline forecaster argument constructor — flatline_args_list","text":"","code":"flatline_args_list(   ahead = 7L,   n_training = Inf,   forecast_date = NULL,   target_date = NULL,   quantile_levels = c(0.05, 0.95),   symmetrize = TRUE,   nonneg = TRUE,   quantile_by_key = character(0L),   ... )"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/flatline_args_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Flatline forecaster argument constructor — flatline_args_list","text":"ahead Integer. Unlike arx_forecaster(), effect predicted values. Predictions always recent observation. However, impact residuals stored object. Residuals calculated based number mimic badly done. example, ahead = 7 create residuals comparing values 7 days apart. n_training Integer. upper limit number rows per key used training (time unit epi_df). forecast_date Date. date forecast occurring. default NULL determine automatically either maximum time value data latency adjustment (default case), as_of date epi_data adjust_latency non-NULL. target_date Date. date forecast. default NULL determine automatically forecast_date + ahead. quantile_levels Vector NULL. vector probabilities produce prediction intervals. created computing quantiles training residuals. NULL value result point forecasts . symmetrize Logical. default TRUE calculates symmetric prediction intervals. argument applies residual quantiles used. applicable trainer = quantile_reg(), example. nonneg Logical. default TRUE enforces nonnegative predictions hard-thresholding 0. quantile_by_key Character vector. Groups residuals listed keys calculating residual quantiles. See by_key argument layer_residual_quantiles() information. default, character(0) performs grouping. argument applies residual quantiles used. applicable trainer = quantile_reg(), example. ... Space handle future expansions (unused).","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/flatline_args_list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Flatline forecaster argument constructor — flatline_args_list","text":"list containing updated parameter choices class flatline_alist.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/flatline_args_list.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Flatline forecaster argument constructor — flatline_args_list","text":"","code":"flatline_args_list() #> • ahead : 7 #> • n_training : Inf #> • forecast_date : \"NULL\" #> • target_date : \"NULL\" #> • quantile_levels : 0.05 and 0.95 #> • symmetrize : TRUE #> • nonneg : TRUE #> • quantile_by_key : \"_empty_\" flatline_args_list(symmetrize = FALSE) #> • ahead : 7 #> • n_training : Inf #> • forecast_date : \"NULL\" #> • target_date : \"NULL\" #> • quantile_levels : 0.05 and 0.95 #> • symmetrize : FALSE #> • nonneg : TRUE #> • quantile_by_key : \"_empty_\" flatline_args_list(quantile_levels = c(.1, .3, .7, .9), n_training = 120) #> • ahead : 7 #> • n_training : 120 #> • forecast_date : \"NULL\" #> • target_date : \"NULL\" #> • quantile_levels : 0.1, 0.3, 0.7, and 0.9 #> • symmetrize : TRUE #> • nonneg : TRUE #> • quantile_by_key : \"_empty_\""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/flatline_forecaster.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict the future with today's value — flatline_forecaster","title":"Predict the future with today's value — flatline_forecaster","text":"simple forecasting model epiprocess::epi_df data. uses recent observation forecast future date, produces intervals based quantiles residuals \"flatline\" forecast available training data.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/flatline_forecaster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict the future with today's value — flatline_forecaster","text":"","code":"flatline_forecaster(epi_data, outcome, args_list = flatline_args_list())"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/flatline_forecaster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict the future with today's value — flatline_forecaster","text":"epi_data epiprocess::epi_df outcome scalar character column name wish predict. args_list list dditional arguments created flatline_args_list() constructor function.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/flatline_forecaster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict the future with today's value — flatline_forecaster","text":"data frame point (optionally interval) forecasts single ahead (unique horizon) unique combination key_vars.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/flatline_forecaster.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Predict the future with today's value — flatline_forecaster","text":"default, predictive intervals computed separately combination key values (geo_value + additional keys) epi_data argument. forecaster similar used COVID19ForecastHub","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/flatline_forecaster.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predict the future with today's value — flatline_forecaster","text":"","code":"jhu <- case_death_rate_subset %>%   dplyr::filter(time_value >= as.Date(\"2021-12-01\"))  out <- flatline_forecaster(jhu, \"death_rate\")"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/flusight_hub_formatter.html","id":null,"dir":"Reference","previous_headings":"","what":"Format predictions for submission to FluSight forecast Hub — flusight_hub_formatter","title":"Format predictions for submission to FluSight forecast Hub — flusight_hub_formatter","text":"function converts predictions included forecasters format (nearly) ready submission 2023-24 FluSight-forecast-hub. See documentation required columns. Currently, \"quantile\" forcasts supported, intention support \"quantile\" \"pmf\". reason, adding output_type column done via ... argument. See examples . specific required format forecast task .","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/flusight_hub_formatter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format predictions for submission to FluSight forecast Hub — flusight_hub_formatter","text":"","code":"flusight_hub_formatter(object, ..., .fcast_period = c(\"daily\", \"weekly\"))"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/flusight_hub_formatter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format predictions for submission to FluSight forecast Hub — flusight_hub_formatter","text":"object data.frame predictions object class canned_epipred created , e.g., arx_forecaster() ... <dynamic-dots> Name = value pairs constant columns (mutations) perform results. See examples. .fcast_period Control whether horizon represent days weeks. Depending whether forecaster output target dates layer_add_target_date() , may need compute horizon /target_end_date available columns predictions. ahead target_date available, ignored. ahead aheads exists, target date may need multiplied ahead represents weekly forecasts. Alternatively, , target_date available, horizon days, unless argument \"weekly\". Note can adjusted later ... argument.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/flusight_hub_formatter.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Format predictions for submission to FluSight forecast Hub — flusight_hub_formatter","text":"tibble::tibble. ... empty, result contain columns reference_date, horizon, target_end_date, location, output_type_id, value. ... can perform mutations .","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/flusight_hub_formatter.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Format predictions for submission to FluSight forecast Hub — flusight_hub_formatter","text":"","code":"library(dplyr) weekly_deaths <- case_death_rate_subset %>%   filter(     time_value >= as.Date(\"2021-09-01\"),     geo_value %in% c(\"ca\", \"ny\", \"dc\", \"ga\", \"vt\")   ) %>%   select(geo_value, time_value, death_rate) %>%   left_join(state_census %>% select(pop, abbr), by = c(\"geo_value\" = \"abbr\")) %>%   mutate(deaths = pmax(death_rate / 1e5 * pop * 7, 0)) %>%   select(-pop, -death_rate) %>%   group_by(geo_value) %>%   epi_slide(~ sum(.$deaths), .window_size = 7, .new_col_name = \"deaths_7dsum\") %>%   ungroup() %>%   filter(weekdays(time_value) == \"Saturday\")  cdc <- cdc_baseline_forecaster(weekly_deaths, \"deaths_7dsum\") flusight_hub_formatter(cdc) #> # A tibble: 575 × 7 #>    reference_date horizon target_end_date location output_type_id value .pred #>    <date>           <int> <date>          <chr>             <dbl> <dbl> <dbl> #>  1 2021-12-25           1 2022-01-01      06                0.01  2088. 3164. #>  2 2021-12-25           1 2022-01-01      06                0.025 2113. 3164. #>  3 2021-12-25           1 2022-01-01      06                0.05  2169. 3164. #>  4 2021-12-25           1 2022-01-01      06                0.1   2240. 3164. #>  5 2021-12-25           1 2022-01-01      06                0.15  2514. 3164. #>  6 2021-12-25           1 2022-01-01      06                0.2   2821. 3164. #>  7 2021-12-25           1 2022-01-01      06                0.25  2888. 3164. #>  8 2021-12-25           1 2022-01-01      06                0.3   2922. 3164. #>  9 2021-12-25           1 2022-01-01      06                0.35  2954. 3164. #> 10 2021-12-25           1 2022-01-01      06                0.4   3010. 3164. #> # ℹ 565 more rows flusight_hub_formatter(cdc, target = \"wk inc covid deaths\") #> # A tibble: 575 × 8 #>    reference_date horizon target_end_date location output_type_id value .pred #>    <date>           <int> <date>          <chr>             <dbl> <dbl> <dbl> #>  1 2021-12-25           1 2022-01-01      06                0.01  2088. 3164. #>  2 2021-12-25           1 2022-01-01      06                0.025 2113. 3164. #>  3 2021-12-25           1 2022-01-01      06                0.05  2169. 3164. #>  4 2021-12-25           1 2022-01-01      06                0.1   2240. 3164. #>  5 2021-12-25           1 2022-01-01      06                0.15  2514. 3164. #>  6 2021-12-25           1 2022-01-01      06                0.2   2821. 3164. #>  7 2021-12-25           1 2022-01-01      06                0.25  2888. 3164. #>  8 2021-12-25           1 2022-01-01      06                0.3   2922. 3164. #>  9 2021-12-25           1 2022-01-01      06                0.35  2954. 3164. #> 10 2021-12-25           1 2022-01-01      06                0.4   3010. 3164. #> # ℹ 565 more rows #> # ℹ 1 more variable: target <chr> flusight_hub_formatter(cdc, target = paste(horizon, \"wk inc covid deaths\")) #> # A tibble: 575 × 8 #>    reference_date horizon target_end_date location output_type_id value .pred #>    <date>           <int> <date>          <chr>             <dbl> <dbl> <dbl> #>  1 2021-12-25           1 2022-01-01      06                0.01  2088. 3164. #>  2 2021-12-25           1 2022-01-01      06                0.025 2113. 3164. #>  3 2021-12-25           1 2022-01-01      06                0.05  2169. 3164. #>  4 2021-12-25           1 2022-01-01      06                0.1   2240. 3164. #>  5 2021-12-25           1 2022-01-01      06                0.15  2514. 3164. #>  6 2021-12-25           1 2022-01-01      06                0.2   2821. 3164. #>  7 2021-12-25           1 2022-01-01      06                0.25  2888. 3164. #>  8 2021-12-25           1 2022-01-01      06                0.3   2922. 3164. #>  9 2021-12-25           1 2022-01-01      06                0.35  2954. 3164. #> 10 2021-12-25           1 2022-01-01      06                0.4   3010. 3164. #> # ℹ 565 more rows #> # ℹ 1 more variable: target <chr> flusight_hub_formatter(cdc, target = \"wk inc covid deaths\", output_type = \"quantile\") #> # A tibble: 575 × 9 #>    reference_date horizon target_end_date location output_type_id value .pred #>    <date>           <int> <date>          <chr>             <dbl> <dbl> <dbl> #>  1 2021-12-25           1 2022-01-01      06                0.01  2088. 3164. #>  2 2021-12-25           1 2022-01-01      06                0.025 2113. 3164. #>  3 2021-12-25           1 2022-01-01      06                0.05  2169. 3164. #>  4 2021-12-25           1 2022-01-01      06                0.1   2240. 3164. #>  5 2021-12-25           1 2022-01-01      06                0.15  2514. 3164. #>  6 2021-12-25           1 2022-01-01      06                0.2   2821. 3164. #>  7 2021-12-25           1 2022-01-01      06                0.25  2888. 3164. #>  8 2021-12-25           1 2022-01-01      06                0.3   2922. 3164. #>  9 2021-12-25           1 2022-01-01      06                0.35  2954. 3164. #> 10 2021-12-25           1 2022-01-01      06                0.4   3010. 3164. #> # ℹ 565 more rows #> # ℹ 2 more variables: target <chr>, output_type <chr>"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/forecast.epi_workflow.html","id":null,"dir":"Reference","previous_headings":"","what":"Produce a forecast from an epi workflow — forecast.epi_workflow","title":"Produce a forecast from an epi workflow — forecast.epi_workflow","text":"Produce forecast epi workflow","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/forecast.epi_workflow.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Produce a forecast from an epi workflow — forecast.epi_workflow","text":"","code":"# S3 method for class 'epi_workflow' forecast(object, ..., n_recent = NULL, forecast_date = NULL)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/forecast.epi_workflow.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Produce a forecast from an epi workflow — forecast.epi_workflow","text":"object epi workflow. ... used. n_recent Integer NULL. filling missing data locf = TRUE, far back willing tolerate missing data? Larger values allow filling. default NULL determine recipe. example, suppose n_recent = 3, 3 recent observations geo_value NA’s, won’t able fill anything, error message thrown. (See details.) forecast_date default, set maximum time_value x. data latency recent NA's filled, may last available time_value.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/forecast.epi_workflow.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Produce a forecast from an epi workflow — forecast.epi_workflow","text":"forecast tibble.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/frosting.html","id":null,"dir":"Reference","previous_headings":"","what":"Create frosting for postprocessing predictions — frosting","title":"Create frosting for postprocessing predictions — frosting","text":"generates postprocessing container (much like recipes::recipe()) hold steps postprocessing predictions.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/frosting.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create frosting for postprocessing predictions — frosting","text":"","code":"frosting(layers = NULL, requirements = NULL)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/frosting.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create frosting for postprocessing predictions — frosting","text":"layers Must NULL. requirements Must NULL.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/frosting.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create frosting for postprocessing predictions — frosting","text":"frosting object.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/frosting.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create frosting for postprocessing predictions — frosting","text":"arguments currently placeholders must NULL","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/frosting.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create frosting for postprocessing predictions — frosting","text":"","code":"library(dplyr) # Toy example to show that frosting can be created and added for postprocessing f <- frosting() wf <- epi_workflow() %>% add_frosting(f)  # A more realistic example jhu <- case_death_rate_subset %>%   filter(time_value > \"2021-11-01\", geo_value %in% c(\"ak\", \"ca\", \"ny\"))  r <- epi_recipe(jhu) %>%   step_epi_lag(death_rate, lag = c(0, 7, 14)) %>%   step_epi_ahead(death_rate, ahead = 7) %>%   step_epi_naomit()  wf <- epi_workflow(r, parsnip::linear_reg()) %>% fit(jhu)  f <- frosting() %>%   layer_predict() %>%   layer_naomit(.pred)  wf1 <- wf %>% add_frosting(f)  p <- forecast(wf1) p #> An `epi_df` object, 3 x 3 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-31 19:08:25.791826 #>  #> # A tibble: 3 × 3 #>   geo_value time_value .pred #> * <chr>     <date>     <dbl> #> 1 ak        2021-12-31 0.245 #> 2 ca        2021-12-31 0.313 #> 3 ny        2021-12-31 0.295"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/get_forecast_date.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract the as_of for the forecast date, and make sure there's nothing very off about it. — get_forecast_date","title":"Extract the as_of for the forecast date, and make sure there's nothing very off about it. — get_forecast_date","text":"Extract as_of forecast date, make sure nothing .","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/get_forecast_date.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract the as_of for the forecast date, and make sure there's nothing very off about it. — get_forecast_date","text":"","code":"get_forecast_date(new_data, info, epi_keys_checked, latency, columns = NULL)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/get_forecast_date_in_layer.html","id":null,"dir":"Reference","previous_headings":"","what":"get the target date while in a layer — get_forecast_date_in_layer","title":"get the target date while in a layer — get_forecast_date_in_layer","text":"get target date layer","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/get_forecast_date_in_layer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"get the target date while in a layer — get_forecast_date_in_layer","text":"","code":"get_forecast_date_in_layer(this_recipe, workflow_max_time_value, new_data)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/get_forecast_date_in_layer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"get the target date while in a layer — get_forecast_date_in_layer","text":"this_recipe recipe check step_adjust_latency workflow_max_time_value max_time value coming fit workflow (maximal time value potentially different dataset) new_data data currently working , take potentially different max_time_value","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/get_latency.html","id":null,"dir":"Reference","previous_headings":"","what":"the latency is also the amount the shift is off by — get_latency","title":"the latency is also the amount the shift is off by — get_latency","text":"latency also amount shift ","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/get_latency.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"the latency is also the amount the shift is off by — get_latency","text":"","code":"get_latency(new_data, forecast_date, column, sign_shift, epi_keys_checked)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/get_latency.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"the latency is also the amount the shift is off by — get_latency","text":"sign_shift integer. 1 lag -1 ahead. represent need shift data bring 3 day lagged value today.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/get_latency_table.html","id":null,"dir":"Reference","previous_headings":"","what":"create the latency table This is a table of column names and the latency adjustment necessary for that column. An example: — get_latency_table","title":"create the latency table This is a table of column names and the latency adjustment necessary for that column. An example: — get_latency_table","text":"col_name   latency  1 case_rate        5 2 death_rate       5","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/get_latency_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"create the latency table This is a table of column names and the latency adjustment necessary for that column. An example: — get_latency_table","text":"","code":"get_latency_table(   training,   columns,   forecast_date,   latency,   sign_shift,   epi_keys_checked,   keys_to_ignore,   info,   terms )"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/get_sign.html","id":null,"dir":"Reference","previous_headings":"","what":"lags move columns forward to bring the past up to today, while aheads drag the future back to today — get_sign","title":"lags move columns forward to bring the past up to today, while aheads drag the future back to today — get_sign","text":"lags move columns forward bring past today, aheads drag future back today","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/get_sign.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"lags move columns forward to bring the past up to today, while aheads drag the future back to today — get_sign","text":"","code":"get_sign(object)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/get_test_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Get test data for prediction based on longest lag period — get_test_data","title":"Get test data for prediction based on longest lag period — get_test_data","text":"Based longest lag period recipe, get_test_data() creates epi_df columns geo_value, time_value variables original dataset, used create features necessary produce forecasts.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/get_test_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get test data for prediction based on longest lag period — get_test_data","text":"","code":"get_test_data(recipe, x)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/get_test_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get test data for prediction based on longest lag period — get_test_data","text":"recipe recipe object. x epi_df. typical usage pass data used fitting recipe.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/get_test_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get test data for prediction based on longest lag period — get_test_data","text":"object type x columns geo_value, time_value, additional keys, well variables original dataset.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/get_test_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get test data for prediction based on longest lag period — get_test_data","text":"minimum required (recent) data produce forecast equal maximum lag requested (predictor) plus longest horizon used growth rate calculations requested recipe. calculated internally.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/get_test_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get test data for prediction based on longest lag period — get_test_data","text":"","code":"# create recipe rec <- epi_recipe(case_death_rate_subset) %>%   step_epi_ahead(death_rate, ahead = 7) %>%   step_epi_lag(death_rate, lag = c(0, 7, 14)) %>%   step_epi_lag(case_rate, lag = c(0, 7, 14)) get_test_data(recipe = rec, x = case_death_rate_subset) #> An `epi_df` object, 840 x 4 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-31 19:08:25.791826 #>  #> # A tibble: 840 × 4 #>    geo_value time_value case_rate death_rate #>  * <chr>     <date>         <dbl>      <dbl> #>  1 ak        2021-12-17      23.1      1.19  #>  2 al        2021-12-17      15.6      0.290 #>  3 ar        2021-12-17      23.4      0.467 #>  4 as        2021-12-17       0        0     #>  5 az        2021-12-17      41.2      1.04  #>  6 ca        2021-12-17      16.9      0.158 #>  7 co        2021-12-17      30.5      0.578 #>  8 ct        2021-12-17      64.8      0.120 #>  9 dc        2021-12-17      50.4      0.140 #> 10 de        2021-12-17      67.9      0.333 #> # ℹ 830 more rows"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/grad_employ_subset.html","id":null,"dir":"Reference","previous_headings":"","what":"Subset of Statistics Canada median employment income for postsecondary graduates — grad_employ_subset","title":"Subset of Statistics Canada median employment income for postsecondary graduates — grad_employ_subset","text":"Subset Statistics Canada median employment income postsecondary graduates","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/grad_employ_subset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subset of Statistics Canada median employment income for postsecondary graduates — grad_employ_subset","text":"","code":"grad_employ_subset"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/grad_employ_subset.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Subset of Statistics Canada median employment income for postsecondary graduates — grad_employ_subset","text":"epiprocess::epi_df 10193 rows 8 variables: geo_value province Canada associated row measurements. time_value time value, year integer YYYY format edu_qual education qualification fos field study age_group age group; either 15 34 35 64 num_graduates number graduates given row characteristics med_income_2y median employment income two years graduation med_income_5y median employment income five years graduation","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/grad_employ_subset.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Subset of Statistics Canada median employment income for postsecondary graduates — grad_employ_subset","text":"object contains modified data following Statistics Canada data table:  Characteristics median employment income longitudinal cohorts postsecondary graduates two five years graduation, educational qualification field study (primary groupings) Modifications: provincial-level geo_values kept age group, field study, educational qualification kept covariates. remaining covariates, keep aggregated values drop level-specific rows. modifications made time range data","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/grf_quantiles.html","id":null,"dir":"Reference","previous_headings":"","what":"Random quantile forests via grf — grf_quantiles","title":"Random quantile forests via grf — grf_quantiles","text":"grf::quantile_forest() fits random forests way makes easy calculate quantile forests. Currently, engine provided , since quantile regression typical use-case.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/grf_quantiles.html","id":"tuning-parameters","dir":"Reference","previous_headings":"","what":"Tuning Parameters","title":"Random quantile forests via grf — grf_quantiles","text":"model 3 tuning parameters: mtry: # Randomly Selected Predictors (type: integer, default: see ) trees: # Trees (type: integer, default: 2000L) min_n: Minimal Node Size (type: integer, default: 5) mtry depends number columns design matrix. default grf::quantile_forest() min(ceiling(sqrt(ncol(X)) + 20), ncol(X)). categorical predictors, one-hot encoding always used. makes splitting efficient, implications mtry choice. factor many levels become large number columns design matrix means may selected frequently potential splits. different implementations random forest. details, see grf discussion.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/grf_quantiles.html","id":"translation-from-parsnip-to-the-original-package","dir":"Reference","previous_headings":"","what":"Translation from parsnip to the original package","title":"Random quantile forests via grf — grf_quantiles","text":"","code":"rand_forest(   mode = \"regression\", # you must specify the `mode = regression`   mtry = integer(1),   trees = integer(1),   min_n = integer(1) ) %>%   set_engine(\"grf_quantiles\") %>%   translate() #> Random Forest Model Specification (regression) #> #> Main Arguments: #>   mtry = integer(1) #>   trees = integer(1) #>   min_n = integer(1) #> #> Computational engine: grf_quantiles #> #> Model fit template: #> grf::quantile_forest(X = missing_arg(), Y = missing_arg(), mtry = min_cols(~integer(1), #>     x), num.trees = integer(1), min.node.size = min_rows(~integer(1), #>     x), quantiles = c(0.1, 0.5, 0.9), num.threads = 1L, seed = stats::runif(1, #>     0, .Machine$integer.max))"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/grf_quantiles.html","id":"case-weights","dir":"Reference","previous_headings":"","what":"Case weights","title":"Random quantile forests via grf — grf_quantiles","text":"Case weights supported.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/grf_quantiles.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Random quantile forests via grf — grf_quantiles","text":"","code":"library(grf) tib <- data.frame(   y = rnorm(100), x = rnorm(100), z = rnorm(100),   f = factor(sample(letters[1:3], 100, replace = TRUE)) ) spec <- rand_forest(engine = \"grf_quantiles\", mode = \"regression\") out <- fit(spec, formula = y ~ x + z, data = tib) predict(out, new_data = tib[1:5, ]) %>%   pivot_quantiles_wider(.pred) #> # A tibble: 5 × 3 #>   `0.1`   `0.5` `0.9` #>   <dbl>   <dbl> <dbl> #> 1 -1.34 -0.323  0.894 #> 2 -1.78 -0.284  1.06  #> 3 -1.78 -0.284  1.06  #> 4 -1.22 -0.0208 1.08  #> 5 -1.28 -0.0308 1.32   # -- adjusting the desired quantiles  spec <- rand_forest(mode = \"regression\") %>%   set_engine(engine = \"grf_quantiles\", quantiles = c(1:9 / 10)) out <- fit(spec, formula = y ~ x + z, data = tib) predict(out, new_data = tib[1:5, ]) %>%   pivot_quantiles_wider(.pred) #> # A tibble: 5 × 9 #>   `0.1`  `0.2`  `0.3`  `0.4`   `0.5`   `0.6` `0.7` `0.8` `0.9` #>   <dbl>  <dbl>  <dbl>  <dbl>   <dbl>   <dbl> <dbl> <dbl> <dbl> #> 1 -1.34 -0.887 -0.543 -0.372 -0.323   0.242  0.291 0.597 0.954 #> 2 -1.78 -1.03  -0.620 -0.503 -0.284  -0.0144 0.242 0.538 0.976 #> 3 -1.53 -1.03  -0.620 -0.503 -0.284   0.0701 0.249 0.538 1.06  #> 4 -1.22 -0.668 -0.591 -0.361 -0.0254  0.305  0.597 0.842 1.08  #> 5 -1.28 -0.790 -0.448 -0.279 -0.0308  0.242  0.579 0.842 1.32   # -- a more complicated task  library(dplyr) dat <- case_death_rate_subset %>%   filter(time_value > as.Date(\"2021-10-01\")) rec <- epi_recipe(dat) %>%   step_epi_lag(case_rate, death_rate, lag = c(0, 7, 14)) %>%   step_epi_ahead(death_rate, ahead = 7) %>%   step_epi_naomit() frost <- frosting() %>%   layer_predict() %>%   layer_threshold(.pred) spec <- rand_forest(mode = \"regression\") %>%   set_engine(engine = \"grf_quantiles\", quantiles = c(.25, .5, .75))  ewf <- epi_workflow(rec, spec, frost) %>%   fit(dat) %>%   forecast() ewf %>%   rename(forecast_date = time_value) %>%   mutate(target_date = forecast_date + 7L) %>%   pivot_quantiles_wider(.pred) #> # A tibble: 56 × 6 #>    geo_value forecast_date target_date `0.25` `0.5` `0.75` #>    <chr>     <date>        <date>       <dbl> <dbl>  <dbl> #>  1 ak        2021-12-31    2022-01-07  0.196  0.269  0.420 #>  2 al        2021-12-31    2022-01-07  0.149  0.201  0.301 #>  3 ar        2021-12-31    2022-01-07  0.461  0.507  0.601 #>  4 as        2021-12-31    2022-01-07  0      0      0     #>  5 az        2021-12-31    2022-01-07  0.481  0.654  0.872 #>  6 ca        2021-12-31    2022-01-07  0.178  0.222  0.262 #>  7 co        2021-12-31    2022-01-07  0.472  0.579  0.709 #>  8 ct        2021-12-31    2022-01-07  0.347  0.420  0.458 #>  9 dc        2021-12-31    2022-01-07  0.0811 0.230  0.419 #> 10 de        2021-12-31    2022-01-07  0.235  0.380  0.530 #> # ℹ 46 more rows"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/is_epi_recipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Test for epi_recipe — is_epi_recipe","title":"Test for epi_recipe — is_epi_recipe","text":"Test epi_recipe","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/is_epi_recipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test for epi_recipe — is_epi_recipe","text":"","code":"is_epi_recipe(x)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/is_epi_recipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test for epi_recipe — is_epi_recipe","text":"x object.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/is_epi_recipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test for epi_recipe — is_epi_recipe","text":"TRUE object inherits epi_recipe.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/is_epi_workflow.html","id":null,"dir":"Reference","previous_headings":"","what":"Test for an epi_workflow — is_epi_workflow","title":"Test for an epi_workflow — is_epi_workflow","text":"Test epi_workflow","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/is_epi_workflow.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test for an epi_workflow — is_epi_workflow","text":"","code":"is_epi_workflow(x)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/is_epi_workflow.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test for an epi_workflow — is_epi_workflow","text":"x object.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/is_epi_workflow.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test for an epi_workflow — is_epi_workflow","text":"TRUE object inherits epi_workflow.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer-processors.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract, validate, or detect layers of frosting — extract_layers","title":"Extract, validate, or detect layers of frosting — extract_layers","text":"functions mainly internal. can access validate different layers frosting.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer-processors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract, validate, or detect layers of frosting — extract_layers","text":"","code":"extract_layers(x, ...)  # S3 method for class 'frosting' extract_layers(x, ...)  # S3 method for class 'workflow' extract_layers(x, ...)  is_layer(x)  validate_layer(x, ..., arg = rlang::caller_arg(x), call = caller_env())  detect_layer(x, name, ...)  # S3 method for class 'frosting' detect_layer(x, name, ...)  # S3 method for class 'workflow' detect_layer(x, name, ...)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer-processors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract, validate, or detect layers of frosting — extract_layers","text":"x epi_workflow, frosting, layer object ... additional arguments possible future methods arg name input (error reporting) call environment (error reporting) name layer name detect","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer-processors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract, validate, or detect layers of frosting — extract_layers","text":"logical validators/detectors list layers extractors","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer-processors.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract, validate, or detect layers of frosting — extract_layers","text":"","code":"f <- frosting() %>% layer_predict() wf <- epi_workflow(postprocessor = f)  is_layer(layer(\"what_the_what\")) #> Error: Can't create layer without a stat. detect_layer(f, \"layer_predict\") #> [1] TRUE detect_layer(wf, \"layer_predict\") #> [1] TRUE  extract_layers(f) #> [[1]] #> Creating predictions: \"<calculated>\" #>  extract_layers(wf) #> [[1]] #> Creating predictions: \"<calculated>\" #>"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer.html","id":null,"dir":"Reference","previous_headings":"","what":"layer sets the class of the layer — layer","title":"layer sets the class of the layer — layer","text":"layer sets class layer","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"layer sets the class of the layer — layer","text":"","code":"layer(subclass, ..., .prefix = \"layer_\")"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"layer sets the class of the layer — layer","text":"subclass character string resulting class. example, subclass = \"blah\" layer object returned class layer_blah. ... arguments operator returned. .prefix Prefix subclass created.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"layer sets the class of the layer — layer","text":"updated layer new class","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_add_forecast_date.html","id":null,"dir":"Reference","previous_headings":"","what":"Postprocessing step to add the forecast date — layer_add_forecast_date","title":"Postprocessing step to add the forecast date — layer_add_forecast_date","text":"Postprocessing step add forecast date","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_add_forecast_date.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Postprocessing step to add the forecast date — layer_add_forecast_date","text":"","code":"layer_add_forecast_date(   frosting,   forecast_date = NULL,   id = rand_id(\"add_forecast_date\") )"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_add_forecast_date.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Postprocessing step to add the forecast date — layer_add_forecast_date","text":"frosting frosting postprocessor forecast_date forecast date add column epi_df. cases, specified form \"yyyy-mm-dd\". Note forecast date left unspecified, set one two values.  step_adjust_latency step present, uses forecast_date set function. Otherwise, uses maximum time_value across data used pre-processing, fitting model, postprocessing. id random id string","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_add_forecast_date.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Postprocessing step to add the forecast date — layer_add_forecast_date","text":"updated frosting postprocessor","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_add_forecast_date.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Postprocessing step to add the forecast date — layer_add_forecast_date","text":"use function, either specify forecast date leave forecast date unspecifed . latter case, forecast date set maximum time value data used pre-processing, fitting model, postprocessing. case, forecast date less maximum as_of value (data used pre-processing, model fitting, postprocessing), appropriate warning thrown.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_add_forecast_date.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Postprocessing step to add the forecast date — layer_add_forecast_date","text":"","code":"library(dplyr) jhu <- case_death_rate_subset %>%   filter(time_value > \"2021-11-01\", geo_value %in% c(\"ak\", \"ca\", \"ny\")) r <- epi_recipe(jhu) %>%   step_epi_lag(death_rate, lag = c(0, 7, 14)) %>%   step_epi_ahead(death_rate, ahead = 7) %>%   step_epi_naomit() wf <- epi_workflow(r, linear_reg()) %>% fit(jhu) latest <- jhu %>%   filter(time_value >= max(time_value) - 14)  # Don't specify `forecast_date` (by default, this should be last date in latest) f <- frosting() %>%   layer_predict() %>%   layer_naomit(.pred) wf0 <- wf %>% add_frosting(f) p0 <- predict(wf0, latest) p0 #> An `epi_df` object, 3 x 3 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-31 19:08:25.791826 #>  #> # A tibble: 3 × 3 #>   geo_value time_value .pred #> * <chr>     <date>     <dbl> #> 1 ak        2021-12-31 0.245 #> 2 ca        2021-12-31 0.313 #> 3 ny        2021-12-31 0.295  # Specify a `forecast_date` that is greater than or equal to `as_of` date f <- frosting() %>%   layer_predict() %>%   layer_add_forecast_date(forecast_date = \"2022-05-31\") %>%   layer_naomit(.pred) wf1 <- wf %>% add_frosting(f)  p1 <- predict(wf1, latest) p1 #> An `epi_df` object, 3 x 4 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-31 19:08:25.791826 #>  #> # A tibble: 3 × 4 #>   geo_value time_value .pred forecast_date #> * <chr>     <date>     <dbl> <date>        #> 1 ak        2021-12-31 0.245 2022-05-31    #> 2 ca        2021-12-31 0.313 2022-05-31    #> 3 ny        2021-12-31 0.295 2022-05-31     # Specify a `forecast_date` that is less than `as_of` date f2 <- frosting() %>%   layer_predict() %>%   layer_add_forecast_date(forecast_date = \"2021-12-31\") %>%   layer_naomit(.pred) wf2 <- wf %>% add_frosting(f2)  p2 <- predict(wf2, latest) p2 #> An `epi_df` object, 3 x 4 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-31 19:08:25.791826 #>  #> # A tibble: 3 × 4 #>   geo_value time_value .pred forecast_date #> * <chr>     <date>     <dbl> <date>        #> 1 ak        2021-12-31 0.245 2021-12-31    #> 2 ca        2021-12-31 0.313 2021-12-31    #> 3 ny        2021-12-31 0.295 2021-12-31     # Do not specify a forecast_date f3 <- frosting() %>%   layer_predict() %>%   layer_add_forecast_date() %>%   layer_naomit(.pred) wf3 <- wf %>% add_frosting(f3)  p3 <- predict(wf3, latest) p3 #> An `epi_df` object, 3 x 4 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-31 19:08:25.791826 #>  #> # A tibble: 3 × 4 #>   geo_value time_value .pred forecast_date #> * <chr>     <date>     <dbl> <date>        #> 1 ak        2021-12-31 0.245 2021-12-31    #> 2 ca        2021-12-31 0.313 2021-12-31    #> 3 ny        2021-12-31 0.295 2021-12-31"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_add_target_date.html","id":null,"dir":"Reference","previous_headings":"","what":"Postprocessing step to add the target date — layer_add_target_date","title":"Postprocessing step to add the target date — layer_add_target_date","text":"Postprocessing step add target date","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_add_target_date.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Postprocessing step to add the target date — layer_add_target_date","text":"","code":"layer_add_target_date(   frosting,   target_date = NULL,   id = rand_id(\"add_target_date\") )"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_add_target_date.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Postprocessing step to add the target date — layer_add_target_date","text":"frosting frosting postprocessor target_date target date add column epi_df. forecast date specified upstream (either step_adjust_latency layer_forecast_date), forecast date plus ahead (step_epi_ahead epi_recipe). Otherwise, maximum time_value (data used pre-processing, fitting model, postprocessing) plus ahead, ahead specified preprocessing. user may override specifying target date (form \"yyyy-mm-dd\"). id random id string","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_add_target_date.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Postprocessing step to add the target date — layer_add_target_date","text":"updated frosting postprocessor","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_add_target_date.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Postprocessing step to add the target date — layer_add_target_date","text":"default, function assumes value ahead specified preprocessing step (likely step_epi_ahead). , ahead added forecast_date test data get target date. forecast_date can set 3 ways: step_adjust_latency, typically uses training epi_df's as_of layer_add_forecast_date, inherits 1 manually specifed none case, simply maximum time_value every dataset used (prep, training, prediction).","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_add_target_date.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Postprocessing step to add the target date — layer_add_target_date","text":"","code":"library(dplyr) jhu <- case_death_rate_subset %>%   filter(time_value > \"2021-11-01\", geo_value %in% c(\"ak\", \"ca\", \"ny\")) r <- epi_recipe(jhu) %>%   step_epi_lag(death_rate, lag = c(0, 7, 14)) %>%   step_epi_ahead(death_rate, ahead = 7) %>%   step_epi_naomit()  wf <- epi_workflow(r, linear_reg()) %>% fit(jhu)  # Use ahead + forecast date f <- frosting() %>%   layer_predict() %>%   layer_add_forecast_date(forecast_date = as.Date(\"2022-05-31\")) %>%   layer_add_target_date() %>%   layer_naomit(.pred) wf1 <- wf %>% add_frosting(f)  p <- forecast(wf1) p #> An `epi_df` object, 3 x 5 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-31 19:08:25.791826 #>  #> # A tibble: 3 × 5 #>   geo_value time_value .pred forecast_date target_date #> * <chr>     <date>     <dbl> <date>        <date>      #> 1 ak        2021-12-31 0.245 2022-05-31    2022-06-07  #> 2 ca        2021-12-31 0.313 2022-05-31    2022-06-07  #> 3 ny        2021-12-31 0.295 2022-05-31    2022-06-07   # Use ahead + forecast_date from adjust_latency # setting the `as_of` to something realistic attributes(jhu)$metadata$as_of <- max(jhu$time_value) + 3 r <- epi_recipe(jhu) %>%   step_epi_lag(death_rate, lag = c(0, 7, 14)) %>%   step_epi_ahead(death_rate, ahead = 7) %>%   step_adjust_latency(method = \"extend_ahead\") %>%   step_epi_naomit() #> Warning: If `method` is \"extend_ahead\", then the previous `step_epi_ahead` won't be #> modified. f2 <- frosting() %>%   layer_predict() %>%   layer_add_target_date() %>%   layer_naomit(.pred) wf2 <- wf %>% add_frosting(f2)  p2 <- forecast(wf2) p2 #> An `epi_df` object, 3 x 4 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-31 19:08:25.791826 #>  #> # A tibble: 3 × 4 #>   geo_value time_value .pred target_date #> * <chr>     <date>     <dbl> <date>      #> 1 ak        2021-12-31 0.245 2022-01-07  #> 2 ca        2021-12-31 0.313 2022-01-07  #> 3 ny        2021-12-31 0.295 2022-01-07   # Use ahead + max time value from pre, fit, post # which is the same if include `layer_add_forecast_date()` f3 <- frosting() %>%   layer_predict() %>%   layer_add_target_date() %>%   layer_naomit(.pred) wf3 <- wf %>% add_frosting(f3)  p3 <- forecast(wf2) p2 #> An `epi_df` object, 3 x 4 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-31 19:08:25.791826 #>  #> # A tibble: 3 × 4 #>   geo_value time_value .pred target_date #> * <chr>     <date>     <dbl> <date>      #> 1 ak        2021-12-31 0.245 2022-01-07  #> 2 ca        2021-12-31 0.313 2022-01-07  #> 3 ny        2021-12-31 0.295 2022-01-07   # Specify own target date f4 <- frosting() %>%   layer_predict() %>%   layer_add_target_date(target_date = \"2022-01-08\") %>%   layer_naomit(.pred) wf4 <- wf %>% add_frosting(f4)  p4 <- forecast(wf4) p4 #> An `epi_df` object, 3 x 4 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-31 19:08:25.791826 #>  #> # A tibble: 3 × 4 #>   geo_value time_value .pred target_date #> * <chr>     <date>     <dbl> <date>      #> 1 ak        2021-12-31 0.245 2022-01-08  #> 2 ca        2021-12-31 0.313 2022-01-08  #> 3 ny        2021-12-31 0.295 2022-01-08"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_cdc_flatline_quantiles.html","id":null,"dir":"Reference","previous_headings":"","what":"CDC Flatline Forecast Quantiles — layer_cdc_flatline_quantiles","title":"CDC Flatline Forecast Quantiles — layer_cdc_flatline_quantiles","text":"layer creates quantile forecasts taking sample interpolated CDF flatline residuals, shuffling . added point prediction.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_cdc_flatline_quantiles.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"CDC Flatline Forecast Quantiles — layer_cdc_flatline_quantiles","text":"","code":"layer_cdc_flatline_quantiles(   frosting,   ...,   aheads = 1:4,   quantile_levels = c(0.01, 0.025, 1:19/20, 0.975, 0.99),   nsims = 1000,   by_key = \"geo_value\",   symmetrize = FALSE,   nonneg = TRUE,   id = rand_id(\"cdc_baseline_bands\") )"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_cdc_flatline_quantiles.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"CDC Flatline Forecast Quantiles — layer_cdc_flatline_quantiles","text":"frosting frosting postprocessor ... Unused, include consistency layers. aheads Numeric vector desired forecast horizons. given \"units training data\". , example, data typically observed daily (possibly missing values), weekly forecast targets, use c(7, 14, 21, 28). weekly data, use 1:4. quantile_levels Numeric vector probabilities values (0,1) referring desired predictive intervals. default standard set COVID Forecast Hub. nsims Positive integer. number draws empirical CDF. samples spaced evenly (0, 1) scale, F_X(x) resulting linear interpolation X scale. achieved stats::quantile() Type 7 (default function). by_key character vector keys group residuals calculating quantiles. default, c() performs grouping. symmetrize Scalar logical. TRUE, two things: () forces \"empirical\" CDF residuals symmetric pretending every actually-observed residual X also observed another residual -X, (ii) ahead, forces median simulated value equal point prediction adding subtracting amount every simulated value. Adjustments (ii) take place propagating forward simulating next ahead. forces 1-ahead predictive intervals symmetric point prediction, encourages larger aheads symmetric. nonneg Scalar logical. Force predictive intervals non-negative. non-negativity forced propagating forward, slightly different behaviour occur using layer_threshold(). Thresholding ahead takes place shifting symmetrize. id random id string","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_cdc_flatline_quantiles.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"CDC Flatline Forecast Quantiles — layer_cdc_flatline_quantiles","text":"updated frosting postprocessor. Calling predict() result additional <list-col> named .pred_distn_all containing 2-column tibble::tibble()'s. desired combination key's, tibble contain one row per ahead associated dist_quantiles().","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_cdc_flatline_quantiles.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"CDC Flatline Forecast Quantiles — layer_cdc_flatline_quantiles","text":"layer intended used concert flatline(). can also used anything else. long residuals available fitted model, layer useful. Like layer_residual_quantiles() uses residuals fitted model object. However, propagates forward aheads, iteratively shuffling (randomly), adding previous set. contrast happens flatline_forecaster(). using flatline() underlying engine (), result predictions (recent observed value), model calculates separate residuals ahead comparing observations future. version continues use set residuals, adds produce wider intervals ahead increases.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_cdc_flatline_quantiles.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"CDC Flatline Forecast Quantiles — layer_cdc_flatline_quantiles","text":"","code":"library(dplyr) r <- epi_recipe(case_death_rate_subset) %>%   # data is \"daily\", so we fit this to 1 ahead, the result will contain   # 1 day ahead residuals   step_epi_ahead(death_rate, ahead = 1L, skip = TRUE) %>%   recipes::update_role(death_rate, new_role = \"predictor\") %>%   recipes::add_role(time_value, geo_value, new_role = \"predictor\")  forecast_date <- max(case_death_rate_subset$time_value)  f <- frosting() %>%   layer_predict() %>%   layer_cdc_flatline_quantiles(aheads = c(7, 14, 21, 28), symmetrize = TRUE)  eng <- linear_reg(engine = \"flatline\")  wf <- epi_workflow(r, eng, f) %>% fit(case_death_rate_subset) preds <- forecast(wf) %>%   select(-time_value) %>%   mutate(forecast_date = forecast_date) preds #> # A tibble: 56 × 4 #>    geo_value  .pred .pred_distn_all  forecast_date #>    <chr>      <dbl> <list>           <date>        #>  1 ak        0.0395 <tibble [4 × 2]> 2021-12-31    #>  2 al        0.107  <tibble [4 × 2]> 2021-12-31    #>  3 ar        0.490  <tibble [4 × 2]> 2021-12-31    #>  4 as        0      <tibble [4 × 2]> 2021-12-31    #>  5 az        0.608  <tibble [4 × 2]> 2021-12-31    #>  6 ca        0.142  <tibble [4 × 2]> 2021-12-31    #>  7 co        0.485  <tibble [4 × 2]> 2021-12-31    #>  8 ct        0.333  <tibble [4 × 2]> 2021-12-31    #>  9 dc        0.0802 <tibble [4 × 2]> 2021-12-31    #> 10 de        0.217  <tibble [4 × 2]> 2021-12-31    #> # ℹ 46 more rows  preds <- preds %>%   tidyr::unnest(.pred_distn_all) %>%   pivot_quantiles_wider(.pred_distn) %>%   mutate(target_date = forecast_date + ahead)  if (require(\"ggplot2\")) {   four_states <- c(\"ca\", \"pa\", \"wa\", \"ny\")   preds %>%     filter(geo_value %in% four_states) %>%     ggplot(aes(target_date)) +     geom_ribbon(aes(ymin = `0.1`, ymax = `0.9`), fill = blues9[3]) +     geom_ribbon(aes(ymin = `0.25`, ymax = `0.75`), fill = blues9[6]) +     geom_line(aes(y = .pred), color = \"orange\") +     geom_line(       data = case_death_rate_subset %>% filter(geo_value %in% four_states),       aes(x = time_value, y = death_rate)     ) +     scale_x_date(limits = c(forecast_date - 90, forecast_date + 30)) +     labs(x = \"Date\", y = \"Death rate\") +     facet_wrap(~geo_value, scales = \"free_y\") +     theme_bw() +     geom_vline(xintercept = forecast_date) } #> Warning: Removed 275 rows containing missing values or values outside the scale range #> (`geom_line()`)."},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_naomit.html","id":null,"dir":"Reference","previous_headings":"","what":"Omit NAs from predictions or other columns — layer_naomit","title":"Omit NAs from predictions or other columns — layer_naomit","text":"Omit NAs predictions columns","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_naomit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Omit NAs from predictions or other columns — layer_naomit","text":"","code":"layer_naomit(frosting, ..., id = rand_id(\"naomit\"))"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_naomit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Omit NAs from predictions or other columns — layer_naomit","text":"frosting frosting postprocessor ... <tidy-select> One unquoted expressions separated commas. Variable names can used positions data frame, expressions like x:y can used select range variables. Typical usage .pred remove rows NA predictions. id random id string","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_naomit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Omit NAs from predictions or other columns — layer_naomit","text":"updated frosting postprocessor","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_naomit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Omit NAs from predictions or other columns — layer_naomit","text":"","code":"library(dplyr) jhu <- case_death_rate_subset %>%   filter(time_value > \"2021-11-01\", geo_value %in% c(\"ak\", \"ca\", \"ny\"))  r <- epi_recipe(jhu) %>%   step_epi_lag(death_rate, lag = c(0, 7, 14)) %>%   step_epi_ahead(death_rate, ahead = 7)  wf <- epi_workflow(r, linear_reg()) %>% fit(jhu)  f <- frosting() %>%   layer_predict() %>%   layer_naomit(.pred)  wf1 <- wf %>% add_frosting(f)  p <- forecast(wf1) p #> An `epi_df` object, 3 x 3 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-31 19:08:25.791826 #>  #> # A tibble: 3 × 3 #>   geo_value time_value .pred #> * <chr>     <date>     <dbl> #> 1 ak        2021-12-31 0.245 #> 2 ca        2021-12-31 0.313 #> 3 ny        2021-12-31 0.295"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_point_from_distn.html","id":null,"dir":"Reference","previous_headings":"","what":"Converts distributional forecasts to point forecasts — layer_point_from_distn","title":"Converts distributional forecasts to point forecasts — layer_point_from_distn","text":"function adds postprocessing layer extract point forecast distributional forecast. NOTE: default arguments, remove information, one usually call layer_quantile_distn() set name argument something specific.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_point_from_distn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Converts distributional forecasts to point forecasts — layer_point_from_distn","text":"","code":"layer_point_from_distn(   frosting,   ...,   type = c(\"median\", \"mean\"),   name = NULL,   id = rand_id(\"point_from_distn\") )"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_point_from_distn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Converts distributional forecasts to point forecasts — layer_point_from_distn","text":"frosting frosting postprocessor ... Unused, include consistency layers. type character. Either mean median. name character. name output column. default NULL overwrite .pred column, removing distribution information. id random id string","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_point_from_distn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Converts distributional forecasts to point forecasts — layer_point_from_distn","text":"updated frosting postprocessor.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_point_from_distn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Converts distributional forecasts to point forecasts — layer_point_from_distn","text":"","code":"library(dplyr) jhu <- case_death_rate_subset %>%   filter(time_value > \"2021-11-01\", geo_value %in% c(\"ak\", \"ca\", \"ny\"))  r <- epi_recipe(jhu) %>%   step_epi_lag(death_rate, lag = c(0, 7, 14)) %>%   step_epi_ahead(death_rate, ahead = 7) %>%   step_epi_naomit()  wf <- epi_workflow(r, quantile_reg(quantile_levels = c(.25, .5, .75))) %>%   fit(jhu)  f1 <- frosting() %>%   layer_predict() %>%   layer_quantile_distn() %>% # puts the other quantiles in a different col   layer_point_from_distn() %>% # mutate `.pred` to contain only a point prediction   layer_naomit(.pred) wf1 <- wf %>% add_frosting(f1)  p1 <- forecast(wf1) p1 #> An `epi_df` object, 3 x 4 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-31 19:08:25.791826 #>  #> # A tibble: 3 × 4 #>   geo_value time_value .pred        .pred_distn #> * <chr>     <date>     <dbl>             <dist> #> 1 ak        2021-12-31 0.167 quantiles(0.12)[2] #> 2 ca        2021-12-31 0.177 quantiles(0.21)[2] #> 3 ny        2021-12-31 0.272 quantiles(0.25)[2]  f2 <- frosting() %>%   layer_predict() %>%   layer_point_from_distn() %>% # mutate `.pred` to contain only a point prediction   layer_naomit(.pred) wf2 <- wf %>% add_frosting(f2)  p2 <- forecast(wf2) p2 #> An `epi_df` object, 3 x 3 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-31 19:08:25.791826 #>  #> # A tibble: 3 × 3 #>   geo_value time_value .pred #> * <chr>     <date>     <dbl> #> 1 ak        2021-12-31 0.167 #> 2 ca        2021-12-31 0.177 #> 3 ny        2021-12-31 0.272"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_population_scaling.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert per-capita predictions to raw scale — layer_population_scaling","title":"Convert per-capita predictions to raw scale — layer_population_scaling","text":"layer_population_scaling creates specification frosting layer \"undo\" per-capita scaling. Typical usage load dataset contains state-level population, use convert predictions made rate-scale model raw scale multiplying population. Although, worth noting nothing special \"population\". function can used scale variable. Population standard use case epidemiology forecasting scenario. value passed multiply selected variables rate_rescaling argument common divisor selected variables.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_population_scaling.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert per-capita predictions to raw scale — layer_population_scaling","text":"","code":"layer_population_scaling(   frosting,   ...,   df,   by = NULL,   df_pop_col,   rate_rescaling = 1,   create_new = TRUE,   suffix = \"_scaled\",   id = rand_id(\"population_scaling\") )"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_population_scaling.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert per-capita predictions to raw scale — layer_population_scaling","text":"frosting frosting postprocessor. layer added sequence operations frosting. ... One selector functions scale variables step. See recipes::selections() details. df data frame contains population data used inverting existing scaling. (possibly named) character vector variables join . NULL, default, function perform natural join, using variables common across epi_df produced predict() call user-provided dataset. columns epi_df df name (included ), .df added one user-provided data disambiguate. join different variables epi_df df, use named vector. example, = c(\"geo_value\" = \"states\") match epi_df$geo_value df$states. join multiple variables, use vector length > 1. example, = c(\"geo_value\" = \"states\", \"county\" = \"county\") match epi_df$geo_value df$states epi_df$county df$county. See dplyr::left_join() details. df_pop_col name column data frame df contains population data used scaling. rate_rescaling Sometimes rates \"per 100K\" \"per 1M\" rather \"per person\". Adjustments can made . example, original rate \"per 100K\", set rate_rescaling = 1e5 get counts back. create_new TRUE create new column keep original column epi_df. suffix character. suffix added column name create_new = TRUE. Default \"_scaled\". id random id string","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_population_scaling.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert per-capita predictions to raw scale — layer_population_scaling","text":"updated frosting postprocessor","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_population_scaling.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert per-capita predictions to raw scale — layer_population_scaling","text":"","code":"library(dplyr) jhu <- jhu_csse_daily_subset %>%   filter(time_value > \"2021-11-01\", geo_value %in% c(\"ca\", \"ny\")) %>%   select(geo_value, time_value, cases)  pop_data <- data.frame(states = c(\"ca\", \"ny\"), value = c(20000, 30000))  r <- epi_recipe(jhu) %>%   step_population_scaling(     df = pop_data,     df_pop_col = \"value\",     by = c(\"geo_value\" = \"states\"),     cases, suffix = \"_scaled\"   ) %>%   step_epi_lag(cases_scaled, lag = c(0, 7, 14)) %>%   step_epi_ahead(cases_scaled, ahead = 7, role = \"outcome\") %>%   step_epi_naomit()  f <- frosting() %>%   layer_predict() %>%   layer_threshold(.pred) %>%   layer_naomit(.pred) %>%   layer_population_scaling(.pred,     df = pop_data,     by = c(\"geo_value\" = \"states\"),     df_pop_col = \"value\"   )  wf <- epi_workflow(r, linear_reg()) %>%   fit(jhu) %>%   add_frosting(f)  forecast(wf) #> An `epi_df` object, 2 x 4 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2024-08-23 02:40:48.296938 #>  #> # A tibble: 2 × 4 #>   geo_value time_value .pred .pred_scaled #> * <chr>     <date>     <dbl>        <dbl> #> 1 ca        2021-12-31  4.25       84938. #> 2 ny        2021-12-31  5.93      177766."},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_predict.html","id":null,"dir":"Reference","previous_headings":"","what":"Prediction layer for postprocessing — layer_predict","title":"Prediction layer for postprocessing — layer_predict","text":"Implements prediction fitted epi_workflow. One may want different types prediction, potentially apply amount postprocessing. typically first layer frosting postprocessor.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_predict.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prediction layer for postprocessing — layer_predict","text":"","code":"layer_predict(   frosting,   type = NULL,   opts = list(),   ...,   id = rand_id(\"predict_default\") )"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_predict.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prediction layer for postprocessing — layer_predict","text":"frosting frosting object type single character value NULL. Possible values \"numeric\", \"class\", \"prob\", \"conf_int\", \"pred_int\", \"quantile\", \"time\", \"hazard\", \"survival\", \"raw\". NULL, predict() choose appropriate value based model's mode. opts list optional arguments underlying predict function used type = \"raw\". list include options model object new data predicted. ... Additional parsnip-related options, depending value type. Arguments underlying model's prediction function passed (use opts argument instead). Possible arguments : interval: type equal \"survival\" \"quantile\", interval estimates added, available? Options \"none\" \"confidence\". level: type equal \"conf_int\", \"pred_int\", \"survival\", parameter tail area intervals (e.g. confidence level confidence intervals). Default value 0.95. std_error: type equal \"conf_int\" \"pred_int\", add standard error fit prediction (scale linear predictors). Default value FALSE. quantile: type equal quantile, quantiles distribution. Default (1:9)/10. eval_time: type equal \"survival\" \"hazard\", time points survival probability hazard estimated. id string identifying layer","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_predict.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prediction layer for postprocessing — layer_predict","text":"updated frosting object","code":""},{"path":[]},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_predict.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prediction layer for postprocessing — layer_predict","text":"","code":"library(dplyr) jhu <- case_death_rate_subset %>%   filter(time_value > \"2021-11-01\", geo_value %in% c(\"ak\", \"ca\", \"ny\"))  r <- epi_recipe(jhu) %>%   step_epi_lag(death_rate, lag = c(0, 7, 14)) %>%   step_epi_ahead(death_rate, ahead = 7) %>%   step_epi_naomit()  wf <- epi_workflow(r, linear_reg()) %>% fit(jhu) latest <- jhu %>% filter(time_value >= max(time_value) - 14)  # Predict layer alone f <- frosting() %>% layer_predict() wf1 <- wf %>% add_frosting(f)  p1 <- predict(wf1, latest) p1 #> An `epi_df` object, 3 x 3 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-31 19:08:25.791826 #>  #> # A tibble: 3 × 3 #>   geo_value time_value .pred #> * <chr>     <date>     <dbl> #> 1 ak        2021-12-31 0.245 #> 2 ca        2021-12-31 0.313 #> 3 ny        2021-12-31 0.295  # Prediction with interval f <- frosting() %>% layer_predict(type = \"pred_int\") wf2 <- wf %>% add_frosting(f)  p2 <- predict(wf2, latest) p2 #> An `epi_df` object, 3 x 4 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-31 19:08:25.791826 #>  #> # A tibble: 3 × 4 #>   geo_value time_value .pred_lower .pred_upper #> * <chr>     <date>           <dbl>       <dbl> #> 1 ak        2021-12-31      -0.366       0.856 #> 2 ca        2021-12-31      -0.284       0.910 #> 3 ny        2021-12-31      -0.301       0.891"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_predictive_distn.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns predictive distributions — layer_predictive_distn","title":"Returns predictive distributions — layer_predictive_distn","text":"function calculates approximation parametric predictive distribution. Predictive distributions linear models require x* (X'X)^{-1} x* along degrees freedom. function approximates . reasonably accurate models fit using lm new point x* far bulk data.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_predictive_distn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns predictive distributions — layer_predictive_distn","text":"","code":"layer_predictive_distn(   frosting,   ...,   dist_type = c(\"gaussian\", \"student_t\"),   truncate = c(-Inf, Inf),   name = \".pred_distn\",   id = rand_id(\"predictive_distn\") )"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_predictive_distn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Returns predictive distributions — layer_predictive_distn","text":"frosting frosting postprocessor ... Unused, include consistency layers. dist_type Gaussian Student's t predictive intervals truncate truncate distribution interval name character. name output column. id random id string","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_predictive_distn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Returns predictive distributions — layer_predictive_distn","text":"updated frosting postprocessor additional columns residual quantiles added prediction","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_predictive_distn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Returns predictive distributions — layer_predictive_distn","text":"","code":"library(dplyr) jhu <- case_death_rate_subset %>%   filter(time_value > \"2021-11-01\", geo_value %in% c(\"ak\", \"ca\", \"ny\"))  r <- epi_recipe(jhu) %>%   step_epi_lag(death_rate, lag = c(0, 7, 14)) %>%   step_epi_ahead(death_rate, ahead = 7) %>%   step_epi_naomit()  wf <- epi_workflow(r, linear_reg()) %>% fit(jhu)  f <- frosting() %>%   layer_predict() %>%   layer_predictive_distn() %>%   layer_naomit(.pred) wf1 <- wf %>% add_frosting(f)  p <- forecast(wf1) p #> An `epi_df` object, 3 x 4 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-31 19:08:25.791826 #>  #> # A tibble: 3 × 4 #>   geo_value time_value .pred #> * <chr>     <date>     <dbl> #> 1 ak        2021-12-31 0.245 #> 2 ca        2021-12-31 0.313 #> 3 ny        2021-12-31 0.295 #> # ℹ 1 more variable: .pred_distn <dist>"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_quantile_distn.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns predictive quantiles — layer_quantile_distn","title":"Returns predictive quantiles — layer_quantile_distn","text":"function calculates quantiles prediction distributional.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_quantile_distn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns predictive quantiles — layer_quantile_distn","text":"","code":"layer_quantile_distn(   frosting,   ...,   quantile_levels = c(0.25, 0.75),   truncate = c(-Inf, Inf),   name = \".pred_distn\",   id = rand_id(\"quantile_distn\") )"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_quantile_distn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Returns predictive quantiles — layer_quantile_distn","text":"frosting frosting postprocessor ... Unused, include consistency layers. quantile_levels vector probabilities extract truncate truncate distribution interval name character. name output column. id random id string","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_quantile_distn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Returns predictive quantiles — layer_quantile_distn","text":"updated frosting postprocessor. additional column predictive quantiles added predictions.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_quantile_distn.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Returns predictive quantiles — layer_quantile_distn","text":"Currently, distributional modes/engines quantile_reg() smooth_quantile_reg() rand_forest(mode = \"regression\") %>% set_engine(\"grf_quantiles\") engines used, layer grab estimated (extrapolated) quantiles requested quantile values.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_quantile_distn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Returns predictive quantiles — layer_quantile_distn","text":"","code":"library(dplyr) jhu <- case_death_rate_subset %>%   filter(time_value > \"2021-11-01\", geo_value %in% c(\"ak\", \"ca\", \"ny\"))  r <- epi_recipe(jhu) %>%   step_epi_lag(death_rate, lag = c(0, 7, 14)) %>%   step_epi_ahead(death_rate, ahead = 7) %>%   step_epi_naomit()  wf <- epi_workflow(r, quantile_reg(quantile_levels = c(.25, .5, .75))) %>%   fit(jhu)  f <- frosting() %>%   layer_predict() %>%   layer_quantile_distn() %>%   layer_naomit(.pred) wf1 <- wf %>% add_frosting(f)  p <- forecast(wf1) p #> An `epi_df` object, 3 x 4 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-31 19:08:25.791826 #>  #> # A tibble: 3 × 4 #>   geo_value time_value              .pred        .pred_distn #> * <chr>     <date>                 <dist>             <dist> #> 1 ak        2021-12-31 quantiles(0.17)[3] quantiles(0.12)[2] #> 2 ca        2021-12-31 quantiles(0.18)[3] quantiles(0.21)[2] #> 3 ny        2021-12-31 quantiles(0.27)[3] quantiles(0.25)[2]"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_residual_quantiles.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates predictions based on residual quantiles — layer_residual_quantiles","title":"Creates predictions based on residual quantiles — layer_residual_quantiles","text":"Creates predictions based residual quantiles","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_residual_quantiles.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates predictions based on residual quantiles — layer_residual_quantiles","text":"","code":"layer_residual_quantiles(   frosting,   ...,   quantile_levels = c(0.05, 0.95),   symmetrize = TRUE,   by_key = character(0L),   name = \".pred_distn\",   id = rand_id(\"residual_quantiles\") )"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_residual_quantiles.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates predictions based on residual quantiles — layer_residual_quantiles","text":"frosting frosting postprocessor ... Unused, include consistency layers. quantile_levels numeric vector probabilities values (0,1) referring desired quantile. symmetrize logical. TRUE interval symmetric. by_key character vector keys group residuals calculating quantiles. default, c() performs grouping. name character. name output column. id random id string","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_residual_quantiles.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates predictions based on residual quantiles — layer_residual_quantiles","text":"updated frosting postprocessor additional columns residual quantiles added prediction","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_residual_quantiles.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates predictions based on residual quantiles — layer_residual_quantiles","text":"","code":"library(dplyr) jhu <- case_death_rate_subset %>%   filter(time_value > \"2021-11-01\", geo_value %in% c(\"ak\", \"ca\", \"ny\"))  r <- epi_recipe(jhu) %>%   step_epi_lag(death_rate, lag = c(0, 7, 14)) %>%   step_epi_ahead(death_rate, ahead = 7) %>%   step_epi_naomit()  wf <- epi_workflow(r, linear_reg()) %>% fit(jhu)  f <- frosting() %>%   layer_predict() %>%   layer_residual_quantiles(     quantile_levels = c(0.0275, 0.975),     symmetrize = FALSE   ) %>%   layer_naomit(.pred) wf1 <- wf %>% add_frosting(f)  p <- forecast(wf1)  f2 <- frosting() %>%   layer_predict() %>%   layer_residual_quantiles(     quantile_levels = c(0.3, 0.7),     by_key = \"geo_value\"   ) %>%   layer_naomit(.pred) wf2 <- wf %>% add_frosting(f2)  p2 <- forecast(wf2) #> Warning: Some grouping keys are not in data.frame returned by the `residuals()` method. #> Groupings may not be correct."},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_threshold.html","id":null,"dir":"Reference","previous_headings":"","what":"Lower and upper thresholds for predicted values — layer_threshold","title":"Lower and upper thresholds for predicted values — layer_threshold","text":"postprocessing step used set prediction values smaller lower threshold higher upper threshold equal threshold values.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_threshold.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lower and upper thresholds for predicted values — layer_threshold","text":"","code":"layer_threshold(   frosting,   ...,   lower = 0,   upper = Inf,   id = rand_id(\"threshold\") )"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_threshold.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Lower and upper thresholds for predicted values — layer_threshold","text":"frosting frosting postprocessor ... <tidy-select> One unquoted expressions separated commas. Variable names can used positions data frame, expressions like x:y can used select range variables. Typical usage .pred threshold predictions range (say, nonnegative). lower Lower threshold prediction values. , predictions less lower bound set . Default value 0. upper Upper threshold prediction values. , predictions greater upper bound set . Default value Inf. id random id string","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_threshold.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Lower and upper thresholds for predicted values — layer_threshold","text":"updated frosting postprocessor","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_threshold.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Lower and upper thresholds for predicted values — layer_threshold","text":"","code":"library(dplyr) jhu <- case_death_rate_subset %>%   filter(time_value < \"2021-03-08\", geo_value %in% c(\"ak\", \"ca\", \"ar\")) r <- epi_recipe(jhu) %>%   step_epi_lag(death_rate, lag = c(0, 7, 14)) %>%   step_epi_ahead(death_rate, ahead = 7) %>%   step_epi_naomit() wf <- epi_workflow(r, linear_reg()) %>% fit(jhu)  f <- frosting() %>%   layer_predict() %>%   layer_threshold(.pred, lower = 0.180, upper = 0.310) wf <- wf %>% add_frosting(f) p <- forecast(wf) p #> An `epi_df` object, 3 x 3 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-31 19:08:25.791826 #>  #> # A tibble: 3 × 3 #>   geo_value time_value .pred #> * <chr>     <date>     <dbl> #> 1 ak        2021-03-07  0.18 #> 2 ar        2021-03-07  0.18 #> 3 ca        2021-03-07  0.31"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_unnest.html","id":null,"dir":"Reference","previous_headings":"","what":"Unnest prediction list-cols — layer_unnest","title":"Unnest prediction list-cols — layer_unnest","text":"Unnest prediction list-cols","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_unnest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unnest prediction list-cols — layer_unnest","text":"","code":"layer_unnest(frosting, ..., id = rand_id(\"unnest\"))"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_unnest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unnest prediction list-cols — layer_unnest","text":"frosting frosting postprocessor ... <tidy-select> One unquoted expressions separated commas. Variable names can used positions data frame, expressions like x:y can used select range variables. id random id string","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/layer_unnest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Unnest prediction list-cols — layer_unnest","text":"updated frosting postprocessor","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/nested_quantiles.html","id":null,"dir":"Reference","previous_headings":"","what":"Turn a vector of quantile distributions into a list-col — nested_quantiles","title":"Turn a vector of quantile distributions into a list-col — nested_quantiles","text":"Turn vector quantile distributions list-col","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/nested_quantiles.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Turn a vector of quantile distributions into a list-col — nested_quantiles","text":"","code":"nested_quantiles(x)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/nested_quantiles.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Turn a vector of quantile distributions into a list-col — nested_quantiles","text":"x distribution containing dist_quantiles","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/nested_quantiles.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Turn a vector of quantile distributions into a list-col — nested_quantiles","text":"list-col","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/nested_quantiles.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Turn a vector of quantile distributions into a list-col — nested_quantiles","text":"","code":"library(dplyr) library(tidyr) edf <- case_death_rate_subset[1:3, ] edf$q <- dist_quantiles(list(1:5, 2:4, 3:10), list(1:5 / 6, 2:4 / 5, 3:10 / 11))  edf_nested <- edf %>% mutate(q = nested_quantiles(q)) edf_nested %>% unnest(q) #> An `epi_df` object, 16 x 6 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-31 19:08:25.791826 #>  #> # A tibble: 16 × 6 #>    geo_value time_value case_rate death_rate values quantile_levels #>  * <chr>     <date>         <dbl>      <dbl>  <dbl>           <dbl> #>  1 ak        2020-12-31      35.9      0.158      1           0.167 #>  2 ak        2020-12-31      35.9      0.158      2           0.333 #>  3 ak        2020-12-31      35.9      0.158      3           0.5   #>  4 ak        2020-12-31      35.9      0.158      4           0.667 #>  5 ak        2020-12-31      35.9      0.158      5           0.833 #>  6 al        2020-12-31      65.1      0.438      2           0.4   #>  7 al        2020-12-31      65.1      0.438      3           0.6   #>  8 al        2020-12-31      65.1      0.438      4           0.8   #>  9 ar        2020-12-31      66.0      1.27       3           0.273 #> 10 ar        2020-12-31      66.0      1.27       4           0.364 #> 11 ar        2020-12-31      66.0      1.27       5           0.455 #> 12 ar        2020-12-31      66.0      1.27       6           0.545 #> 13 ar        2020-12-31      66.0      1.27       7           0.636 #> 14 ar        2020-12-31      66.0      1.27       8           0.727 #> 15 ar        2020-12-31      66.0      1.27       9           0.818 #> 16 ar        2020-12-31      66.0      1.27      10           0.909"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/new_epi_recipe_blueprint.html","id":null,"dir":"Reference","previous_headings":"","what":"Recipe blueprint that accounts for epi_df panel data — new_epi_recipe_blueprint","title":"Recipe blueprint that accounts for epi_df panel data — new_epi_recipe_blueprint","text":"Used simplicity. See hardhat::new_recipe_blueprint() hardhat::default_recipe_blueprint() details.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/new_epi_recipe_blueprint.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Recipe blueprint that accounts for epi_df panel data — new_epi_recipe_blueprint","text":"","code":"new_epi_recipe_blueprint(   intercept = FALSE,   allow_novel_levels = FALSE,   fresh = TRUE,   composition = \"tibble\",   ptypes = NULL,   recipe = NULL,   ...,   subclass = character() )  epi_recipe_blueprint(   intercept = FALSE,   allow_novel_levels = FALSE,   fresh = TRUE,   composition = \"tibble\" )  default_epi_recipe_blueprint(   intercept = FALSE,   allow_novel_levels = FALSE,   fresh = TRUE,   composition = \"tibble\" )  new_default_epi_recipe_blueprint(   intercept = FALSE,   allow_novel_levels = FALSE,   fresh = TRUE,   composition = \"tibble\",   ptypes = NULL,   recipe = NULL,   extra_role_ptypes = NULL,   ...,   subclass = character() )"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/new_epi_recipe_blueprint.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Recipe blueprint that accounts for epi_df panel data — new_epi_recipe_blueprint","text":"intercept logical. intercept included processed data? information used process function mold forge function list. allow_novel_levels logical. novel factor levels allowed prediction time? information used clean function forge function list, passed scream(). fresh already trained operations re-trained prep() called? composition Either \"tibble\", \"matrix\", \"dgCMatrix\" format processed predictors. \"matrix\" \"dgCMatrix\" chosen, predictors must numeric preprocessing method applied; otherwise error thrown. ptypes Either NULL, named list 2 elements, predictors outcomes, 0-row tibbles. ptypes generated automatically mold() time used validate new_data prediction time. recipe Either NULL, unprepped recipe. argument set automatically mold() time. ... Name-value pairs additional elements blueprints subclass blueprint. subclass character vector. subclasses blueprint. extra_role_ptypes named list. names unique non-standard recipe roles (.e. everything except \"predictors\" \"outcomes\"). values prototypes original columns role. used validation forge().","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/new_epi_recipe_blueprint.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Recipe blueprint that accounts for epi_df panel data — new_epi_recipe_blueprint","text":"recipe blueprint.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/new_epi_recipe_blueprint.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Recipe blueprint that accounts for epi_df panel data — new_epi_recipe_blueprint","text":"bake_dependent_roles automatically set epi_df defaults.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/pad_to_end.html","id":null,"dir":"Reference","previous_headings":"","what":"pad every group at the right interval — pad_to_end","title":"pad every group at the right interval — pad_to_end","text":"Perform last observation carried forward group group basis. uses guess_period find appropriate interval fill-forward . maintains grouping structure recieves. fill \"interior\" NA values occurring data beforehand.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/pad_to_end.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"pad every group at the right interval — pad_to_end","text":"","code":"pad_to_end(x, groups, end_date, columns_to_complete = NULL)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/pad_to_end.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"pad every group at the right interval — pad_to_end","text":"x epi_df filled forward. groups grouping fill forward columns_to_complete columns apply completion . default every non-key column epi_df","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/pivot_quantiles_longer.html","id":null,"dir":"Reference","previous_headings":"","what":"Pivot columns containing dist_quantile longer — pivot_quantiles_longer","title":"Pivot columns containing dist_quantile longer — pivot_quantiles_longer","text":"Selected columns contain dist_quantiles \"lengthened\" quantile levels serving 1 column values another. multiple columns selected, prefixed column name.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/pivot_quantiles_longer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pivot columns containing dist_quantile longer — pivot_quantiles_longer","text":"","code":"pivot_quantiles_longer(.data, ..., .ignore_length_check = FALSE)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/pivot_quantiles_longer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pivot columns containing dist_quantile longer — pivot_quantiles_longer","text":".data data frame, data frame extension tibble epi_df. ... <tidy-select> One unquoted expressions separated commas. Variable names can used positions data frame, expressions like x:y can used select range variables. .ignore_length_check multiple columns selected, long row contains number quantiles, result reasonable. , example, var1[1] 5 quantiles var2[1] 7, option recycle everything, creating long result. default, throw error. really goal, error can bypassed setting argument TRUE. quantiles first selected column vary fastest.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/pivot_quantiles_longer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pivot columns containing dist_quantile longer — pivot_quantiles_longer","text":"object class .data.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/pivot_quantiles_longer.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pivot columns containing dist_quantile longer — pivot_quantiles_longer","text":"","code":"d1 <- c(dist_quantiles(1:3, 1:3 / 4), dist_quantiles(2:4, 1:3 / 4)) d2 <- c(dist_quantiles(2:4, 2:4 / 5), dist_quantiles(3:5, 2:4 / 5)) tib <- tibble(g = c(\"a\", \"b\"), d1 = d1, d2 = d2)  pivot_quantiles_longer(tib, \"d1\") #> # A tibble: 6 × 4 #>   g     values quantile_levels                d2 #>   <chr>  <dbl>           <dbl>            <dist> #> 1 a          1            0.25 quantiles(2.5)[3] #> 2 a          2            0.5  quantiles(2.5)[3] #> 3 a          3            0.75 quantiles(2.5)[3] #> 4 b          2            0.25 quantiles(3.5)[3] #> 5 b          3            0.5  quantiles(3.5)[3] #> 6 b          4            0.75 quantiles(3.5)[3] pivot_quantiles_longer(tib, dplyr::ends_with(\"1\")) #> # A tibble: 6 × 4 #>   g     values quantile_levels                d2 #>   <chr>  <dbl>           <dbl>            <dist> #> 1 a          1            0.25 quantiles(2.5)[3] #> 2 a          2            0.5  quantiles(2.5)[3] #> 3 a          3            0.75 quantiles(2.5)[3] #> 4 b          2            0.25 quantiles(3.5)[3] #> 5 b          3            0.5  quantiles(3.5)[3] #> 6 b          4            0.75 quantiles(3.5)[3] pivot_quantiles_longer(tib, d1, d2) #> # A tibble: 6 × 5 #>   g     d1_values d1_quantile_levels d2_values d2_quantile_levels #>   <chr>     <dbl>              <dbl>     <dbl>              <dbl> #> 1 a             1               0.25         2                0.4 #> 2 a             2               0.5          3                0.6 #> 3 a             3               0.75         4                0.8 #> 4 b             2               0.25         3                0.4 #> 5 b             3               0.5          4                0.6 #> 6 b             4               0.75         5                0.8"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/pivot_quantiles_wider.html","id":null,"dir":"Reference","previous_headings":"","what":"Pivot columns containing dist_quantile wider — pivot_quantiles_wider","title":"Pivot columns containing dist_quantile wider — pivot_quantiles_wider","text":"selected columns contain dist_quantiles \"widened\" \"taus\" (quantile) serving names values data frame. pivoting multiple columns, original column name used prefix.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/pivot_quantiles_wider.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pivot columns containing dist_quantile wider — pivot_quantiles_wider","text":"","code":"pivot_quantiles_wider(.data, ...)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/pivot_quantiles_wider.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pivot columns containing dist_quantile wider — pivot_quantiles_wider","text":".data data frame, data frame extension tibble epi_df. ... <tidy-select> One unquoted expressions separated commas. Variable names can used positions data frame, expressions like x:y can used select range variables.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/pivot_quantiles_wider.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pivot columns containing dist_quantile wider — pivot_quantiles_wider","text":"object class .data","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/pivot_quantiles_wider.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pivot columns containing dist_quantile wider — pivot_quantiles_wider","text":"","code":"d1 <- c(dist_quantiles(1:3, 1:3 / 4), dist_quantiles(2:4, 1:3 / 4)) d2 <- c(dist_quantiles(2:4, 2:4 / 5), dist_quantiles(3:5, 2:4 / 5)) tib <- tibble::tibble(g = c(\"a\", \"b\"), d1 = d1, d2 = d2)  pivot_quantiles_wider(tib, c(\"d1\", \"d2\")) #> # A tibble: 2 × 7 #>   g     d1_0.25 d1_0.5 d1_0.75 d2_0.4 d2_0.6 d2_0.8 #>   <chr>   <dbl>  <dbl>   <dbl>  <dbl>  <dbl>  <dbl> #> 1 a           1      2       3      2      3      4 #> 2 b           2      3       4      3      4      5 pivot_quantiles_wider(tib, dplyr::starts_with(\"d\")) #> # A tibble: 2 × 7 #>   g     d1_0.25 d1_0.5 d1_0.75 d2_0.4 d2_0.6 d2_0.8 #>   <chr>   <dbl>  <dbl>   <dbl>  <dbl>  <dbl>  <dbl> #> 1 a           1      2       3      2      3      4 #> 2 b           2      3       4      3      4      5 pivot_quantiles_wider(tib, d2) #> # A tibble: 2 × 5 #>   g                  d1 `0.4` `0.6` `0.8` #>   <chr>          <dist> <dbl> <dbl> <dbl> #> 1 a     quantiles(2)[3]     2     3     4 #> 2 b     quantiles(3)[3]     3     4     5"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/predict-epi_workflow.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict from an epi_workflow — predict-epi_workflow","title":"Predict from an epi_workflow — predict-epi_workflow","text":"predict() method fit epi_workflow object. nice thing predicting epi_workflow : Preprocess new_data using preprocessing method specified workflow created fit. accomplished using hardhat::forge(), apply formula preprocessing call recipes::bake() recipe supplied. Call parsnip::predict.model_fit() using underlying fit parsnip model. Ensure returned object epiprocess::epi_df possible. Specifically, output time_value geo_value columns well prediction.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/predict-epi_workflow.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict from an epi_workflow — predict-epi_workflow","text":"","code":"# S3 method for class 'epi_workflow' predict(object, new_data, type = NULL, opts = list(), ...)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/predict-epi_workflow.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict from an epi_workflow — predict-epi_workflow","text":"object epi_workflow fit workflows::fit.workflow() new_data data frame containing new predictors preprocess predict type single character value NULL. Possible values \"numeric\", \"class\", \"prob\", \"conf_int\", \"pred_int\", \"quantile\", \"time\", \"hazard\", \"survival\", \"raw\". NULL, predict() choose appropriate value based model's mode. opts list optional arguments underlying predict function used type = \"raw\". list include options model object new data predicted. ... Additional parsnip-related options, depending value type. Arguments underlying model's prediction function passed (use opts argument instead). Possible arguments : interval: type equal \"survival\" \"quantile\", interval estimates added, available? Options \"none\" \"confidence\". level: type equal \"conf_int\", \"pred_int\", \"survival\", parameter tail area intervals (e.g. confidence level confidence intervals). Default value 0.95. std_error: type equal \"conf_int\" \"pred_int\", add standard error fit prediction (scale linear predictors). Default value FALSE. quantile: type equal quantile, quantiles distribution. Default (1:9)/10. eval_time: type equal \"survival\" \"hazard\", time points survival probability hazard estimated.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/predict-epi_workflow.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict from an epi_workflow — predict-epi_workflow","text":"data frame model predictions, many rows new_data . new_data epi_df data frame time_value geo_value columns, result well.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/predict-epi_workflow.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predict from an epi_workflow — predict-epi_workflow","text":"","code":"jhu <- case_death_rate_subset  r <- epi_recipe(jhu) %>%   step_epi_lag(death_rate, lag = c(0, 7, 14)) %>%   step_epi_ahead(death_rate, ahead = 7) %>%   step_epi_lag(case_rate, lag = c(0, 7, 14)) %>%   step_epi_naomit()  wf <- epi_workflow(r, parsnip::linear_reg()) %>% fit(jhu) latest <- jhu %>% dplyr::filter(time_value >= max(time_value) - 14)  preds <- predict(wf, latest) preds #> An `epi_df` object, 56 x 3 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-31 19:08:25.791826 #>  #> # A tibble: 56 × 3 #>    geo_value time_value     .pred #>  * <chr>     <date>         <dbl> #>  1 ak        2021-12-31  0.378    #>  2 al        2021-12-31  0.280    #>  3 ar        2021-12-31  0.452    #>  4 as        2021-12-31 -0.000475 #>  5 az        2021-12-31  0.657    #>  6 ca        2021-12-31  0.293    #>  7 co        2021-12-31  0.569    #>  8 ct        2021-12-31  0.641    #>  9 dc        2021-12-31  1.02     #> 10 de        2021-12-31  0.733    #> # ℹ 46 more rows"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/quantile_reg.html","id":null,"dir":"Reference","previous_headings":"","what":"Quantile regression — quantile_reg","title":"Quantile regression — quantile_reg","text":"quantile_reg() generates quantile regression model specification tidymodels framework. Currently, supported engines \"rq\", uses quantreg::rq(). Quantile regression also possible combining parsnip::rand_forest() grf engine. See grf_quantiles.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/quantile_reg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quantile regression — quantile_reg","text":"","code":"quantile_reg(   mode = \"regression\",   engine = \"rq\",   quantile_levels = 0.5,   method = \"br\" )"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/quantile_reg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quantile regression — quantile_reg","text":"mode single character string type model. possible value model \"regression\". engine Character string naming fitting function. Currently, \"rq\" \"grf\" supported. quantile_levels scalar vector values (0, 1) determine quantiles estimate (default 0.5). method fitting method used quantreg::rq(). See documentation list options.","code":""},{"path":[]},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/quantile_reg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quantile regression — quantile_reg","text":"","code":"library(quantreg) #> Loading required package: SparseM tib <- data.frame(y = rnorm(100), x1 = rnorm(100), x2 = rnorm(100)) rq_spec <- quantile_reg(quantile_levels = c(.2, .8)) %>% set_engine(\"rq\") ff <- rq_spec %>% fit(y ~ ., data = tib) predict(ff, new_data = tib) #> # A tibble: 100 × 1 #>                  .pred #>                 <dist> #>  1  quantiles(0.05)[2] #>  2 quantiles(-0.05)[2] #>  3   quantiles(0.3)[2] #>  4 quantiles(-0.41)[2] #>  5  quantiles(0.21)[2] #>  6 quantiles(-0.05)[2] #>  7  quantiles(-0.3)[2] #>  8 quantiles(-0.25)[2] #>  9 quantiles(-0.23)[2] #> 10  quantiles(0.05)[2] #> # ℹ 90 more rows"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. generics fit, forecast, tidy ggplot2 autoplot recipes bake, prep, rand_id tibble tibble","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/seq_forward.html","id":null,"dir":"Reference","previous_headings":"","what":"seq, but returns null if from is larger — seq_forward","title":"seq, but returns null if from is larger — seq_forward","text":"seq, returns null larger","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/seq_forward.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"seq, but returns null if from is larger — seq_forward","text":"","code":"seq_forward(from, to, by)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/slather.html","id":null,"dir":"Reference","previous_headings":"","what":"Spread a layer of frosting on a fitted workflow — slather","title":"Spread a layer of frosting on a fitted workflow — slather","text":"Slathering frosting means implement postprocessing layer. creating new postprocessing layer, must implement S3 method function","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/slather.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Spread a layer of frosting on a fitted workflow — slather","text":"","code":"slather(object, components, workflow, new_data, ...)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/slather.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Spread a layer of frosting on a fitted workflow — slather","text":"object workflow frosting postprocessing steps components list components containing model information. updated returned layer. mold - output calling hardhat::mold() workflow. contains information preprocessing, including recipe. forged - output calling hardhat::forge() workflow. predictors outcomes new_data. three components predictors, outcomes (new_data), extras (usually rest data, including keys). keys - put keys (time_value, geo_value, others) ease. workflow object class workflow new_data data frame containing new predictors preprocess predict ... additional arguments used methods. Currently unused.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/slather.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Spread a layer of frosting on a fitted workflow — slather","text":"components list. format applying updates.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/smooth_quantile_reg.html","id":null,"dir":"Reference","previous_headings":"","what":"Smooth quantile regression — smooth_quantile_reg","title":"Smooth quantile regression — smooth_quantile_reg","text":"smooth_quantile_reg() generates quantile regression model specification tidymodels framework. Currently, supported engine smoothqr::smooth_qr().","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/smooth_quantile_reg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Smooth quantile regression — smooth_quantile_reg","text":"","code":"smooth_quantile_reg(   mode = \"regression\",   engine = \"smoothqr\",   outcome_locations = NULL,   quantile_levels = 0.5,   degree = 3L )"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/smooth_quantile_reg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Smooth quantile regression — smooth_quantile_reg","text":"mode single character string type model. possible value model \"regression\". engine Character string naming fitting function. Currently, \"smooth_qr\" supported. outcome_locations Defaults vector 1:ncol(y) responses observed different spacing (appear different order), information used . argument mapped ahead argument smoothqr::smooth_qr(). quantile_levels scalar vector values (0, 1) determine quantiles estimate (default 0.5). degree number polynomials used response smoothing. Must number responses.","code":""},{"path":[]},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/smooth_quantile_reg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Smooth quantile regression — smooth_quantile_reg","text":"","code":"library(smoothqr) tib <- data.frame(   y1 = rnorm(100), y2 = rnorm(100), y3 = rnorm(100),   y4 = rnorm(100), y5 = rnorm(100), y6 = rnorm(100),   x1 = rnorm(100), x2 = rnorm(100) ) qr_spec <- smooth_quantile_reg(quantile_levels = c(.2, .5, .8), outcome_locations = 1:6) ff <- qr_spec %>% fit(cbind(y1, y2, y3, y4, y5, y6) ~ ., data = tib) p <- predict(ff, new_data = tib)  x <- -99:99 / 100 * 2 * pi y <- sin(x) + rnorm(length(x), sd = .1) fd <- x[length(x) - 20] XY <- smoothqr::lagmat(y[1:(length(y) - 20)], c(-20:20)) XY <- tibble::as_tibble(XY) qr_spec <- smooth_quantile_reg(quantile_levels = c(.2, .5, .8), outcome_locations = 20:1) tt <- qr_spec %>% fit_xy(x = XY[, 21:41], y = XY[, 1:20])  library(tidyr) library(dplyr) pl <- predict(   object = tt,   new_data = XY[max(which(complete.cases(XY[, 21:41]))), 21:41] ) pl <- pl %>%   unnest(.pred) %>%   mutate(distn = nested_quantiles(distn)) %>%   unnest(distn) %>%   mutate(     x = x[length(x) - 20] + ahead / 100 * 2 * pi,     ahead = NULL   ) %>%   pivot_wider(names_from = quantile_levels, values_from = values) plot(x, y, pch = 16, xlim = c(pi, 2 * pi), col = \"lightgrey\") curve(sin(x), add = TRUE) abline(v = fd, lty = 2) lines(pl$x, pl$`0.2`, col = \"blue\") lines(pl$x, pl$`0.8`, col = \"blue\") lines(pl$x, pl$`0.5`, col = \"red\")   library(ggplot2) ggplot(data.frame(x = x, y = y), aes(x)) +   geom_ribbon(data = pl, aes(ymin = `0.2`, ymax = `0.8`), fill = \"lightblue\") +   geom_point(aes(y = y), colour = \"grey\") + # observed data   geom_function(fun = sin, colour = \"black\") + # truth   geom_vline(xintercept = fd, linetype = \"dashed\") + # end of training data   geom_line(data = pl, aes(y = `0.5`), colour = \"red\") + # median prediction   theme_bw() +   coord_cartesian(xlim = c(0, NA)) +   ylab(\"y\")"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/state_census.html","id":null,"dir":"Reference","previous_headings":"","what":"State population data — state_census","title":"State population data — state_census","text":"Data set state populations, 2019 US Census.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/state_census.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"State population data — state_census","text":"","code":"state_census"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/state_census.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"State population data — state_census","text":"Data frame 57 rows (including one United States whole, plus District Columbia, Puerto Rico Commonwealth, American Samoa, Guam, U.S. Virgin Islands, Northern Mariana, Islands). fips FIPS code name Full name state territory pop Estimate location's resident population 2019. abbr Postal abbreviation location","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/state_census.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"State population data — state_census","text":"United States Census Bureau, https://www2.census.gov/programs-surveys/popest/datasets/2010-2019/counties/totals/co-est2019-alldata.pdf, https://www.census.gov/data/tables/time-series/demo/popest/2010s-total-puerto-rico-municipios.html, https://www.census.gov/data/tables/2010/dec/2010-island-areas.html","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_adjust_latency.html","id":null,"dir":"Reference","previous_headings":"","what":"Adapt the model to latent data — step_adjust_latency","title":"Adapt the model to latent data — step_adjust_latency","text":"standard case, arx models assume last observation also day forecast made. data latency, may wish adjust predictors (lags) /outcome (ahead) compensate. useful realtime pseudo-prospective forecasting data delay event occurring event reported.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_adjust_latency.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adapt the model to latent data — step_adjust_latency","text":"","code":"step_adjust_latency(   recipe,   ...,   method = c(\"extend_ahead\", \"locf\", \"extend_lags\"),   epi_keys_checked = NULL,   keys_to_ignore = c(),   fixed_latency = NULL,   fixed_forecast_date = NULL,   check_latency_length = TRUE,   id = rand_id(\"adjust_latency\") )"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_adjust_latency.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adapt the model to latent data — step_adjust_latency","text":"recipe recipe object. step added sequence operations recipe. ... One selector functions choose variables step. See selections() details. method character. Determines method forecast handles latency. options : \"extend_ahead\": Lengthen ahead forecasting last observation results forecast ahead forecast_date date. E.g. 3 days latency last observation forecast_date date 4 day ahead forecast, ahead used practice actually 7. \"locf\": carries forward last observed value(s) forecast date. \"extend_lags\": per epi_key predictor, adjusts lag shortest lag predict time last observation. E.g. lags c(0,7,14) data 3 days latent, actual lags used become c(3,10,17). epi_keys_checked character vector. list keys group finding max_time_value (last day data), defaulting geo_value. Different locations may different latencies; produce forecast every location, need guarantee data every location using largest latency across every location; means taking max_time_value minimum max_time_values set key values (earliest date).  NULL empty character vector, take maximum across values, irrespective keys. Note separate concern different latencies across different data columns, handled choice method. keys_to_ignore list character vectors. Set avoid using specific key values epi_keys_checked set latency. example, say two locations pr gu useful training data, stopped providing --date information, longer part test set. Setting keys_to_ignore = list(geo_value = c(\"pr\", \"gu\")) exclude latency calculation. fixed_latency either positive integer, labeled positive integer vector. set time fixed_forecast_date. non-NULL, amount offset ahead lag . single integer, used columns; labeled vector, labels must correspond base column names (lags/aheads).  NULL, latency distance epi_df's max_time_value forecast_date. fixed_forecast_date either date kind used epi_df, NULL. Exclusive fixed_latency. date, gives date forecast actually occurring. NULL, forecast_date determined either via fixed_latency, set epi_df's as_of value fixed_latency also NULL. check_latency_length bool, determines whether warn latency unusually high. Turn know forecast going far future. id character string unique step identify .","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_adjust_latency.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adapt the model to latent data — step_adjust_latency","text":"updated version recipe new step added sequence existing operations.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_adjust_latency.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Adapt the model to latent data — step_adjust_latency","text":"step allows user create models recent data, automatically accounting latency patterns. Instead using last observation date, step_adjust_latency uses as_of date epi_df forecast_date, adjusts model data available. demonstrate subtleties, consider toy dataset:   looking predict value 15th, forecasting 14th (as_of date ), two issues need address: \"ca\" latent 2 days, whereas \"ma\" latent 1 want use b exogenous variable, \"ma\" latent 3 days instead just 1. Regardless method, epi_keys_checked=\"geo_value\" guarantees tha difference \"ma\" \"ca\" accounted making  latency adjustment least 2. comparison, various methods :","code":"toy_df <- tribble(  ~geo_value, ~time_value, ~a, ~b,  \"ma\", as.Date(\"2015-01-11\"), 20, 6,  \"ma\", as.Date(\"2015-01-12\"), 23, NA,  \"ma\", as.Date(\"2015-01-13\"), 25, NA,  \"ca\", as.Date(\"2015-01-11\"), 100, 5,  \"ca\", as.Date(\"2015-01-12\"), 103, 10, ) %>%    as_epi_df(as_of = as.Date(\"2015-01-14\"))"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_adjust_latency.html","id":"locf","dir":"Reference","previous_headings":"","what":"locf","title":"Adapt the model to latent data — step_adjust_latency","text":"Short \"last observation carried forward\", locf assumes every day last observation forecast day exactly . straightforward assumption, wrecks features depend changes value time, growth rate, even adjacent lags. robust version falls heading nowcasting, eventual aim package. toy dataset, matter day trying predict, since just fills forward forecast_date:","code":"toy_recipe <- epi_recipe(toy_df) %>%   step_adjust_latency(method=\"locf\")  toy_recipe %>%   prep(toy_df) %>%   bake(toy_df) %>%   arrange(geo_value, time_value) #> An `epi_df` object, 8 x 4 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2015-01-14 #> #> # A tibble: 8 x 4 #>   geo_value time_value     a     b #> * <chr>     <date>     <dbl> <dbl> #> 1 ca        2015-01-11   100     5 #> 2 ca        2015-01-12   103    10 #> 3 ca        2015-01-13   103    10 #> 4 ca        2015-01-14   103    10 #> 5 ma        2015-01-11    20     6 #> 6 ma        2015-01-12    23     6 #> 7 ma        2015-01-13    25     6 #> 8 ma        2015-01-14    25     6"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_adjust_latency.html","id":"extend-lags","dir":"Reference","previous_headings":"","what":"extend_lags","title":"Adapt the model to latent data — step_adjust_latency","text":"extend_lags increases lags guaranteed data. advantage applicable per-column basis; cases deaths reported different latencies, lags adjusted separately. toy example:   maximum latency column 2 days, lag increased 3, max latency column b 3, lag increased 4; changes reflected column names. Meanwhile ahead uneffected. side-note, lag/ahead can somewhat ambiguous direction. , values brought forward time, given row, column lag_3_a represents value 3 days .","code":"toy_recipe <- epi_recipe(toy_df) %>%   step_adjust_latency(method=\"extend_lags\") %>%   step_epi_lag(a,lag=1) %>%   step_epi_lag(b,lag=1) %>%   step_epi_ahead(a, ahead=1)  toy_recipe %>%   prep(toy_df) %>%   bake(toy_df) %>%   arrange(geo_value, time_value) #> An `epi_df` object, 21 x 7 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2015-01-14 #> #> # A tibble: 21 x 7 #>    geo_value time_value     a     b lag_3_a lag_4_b ahead_1_a #>  * <chr>     <date>     <dbl> <dbl>   <dbl>   <dbl>     <dbl> #>  1 ca        2015-01-10    NA    NA      NA      NA       100 #>  2 ca        2015-01-11   100     5      NA      NA       103 #>  3 ca        2015-01-12   103    10      NA      NA        NA #>  4 ca        2015-01-13    NA    NA      NA      NA        NA #>  5 ca        2015-01-14    NA    NA     100      NA        NA #>  6 ca        2015-01-15    NA    NA     103       5        NA #>  7 ca        2015-01-16    NA    NA      NA      10        NA #>  8 ca        2015-01-17    NA    NA      NA      NA        NA #>  9 ca        2015-01-18    NA    NA      NA      NA        NA #> 10 ca        2015-01-19    NA    NA      NA      NA        NA #> # i 11 more rows"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_adjust_latency.html","id":"extend-ahead","dir":"Reference","previous_headings":"","what":"extend_ahead","title":"Adapt the model to latent data — step_adjust_latency","text":"extend_ahead increases ahead, turning 3 day ahead forecast 7 day one; advantage simplicity reflective actual modelling task, potentially leaves information unused different data sources different latencies; must use latency latent data insure data available. toy example:   Even though 1 day ahead forecast, worst latency 3 days column b's \"ma\" data, outcome column ahead_4_a (4 days ahead). want ignore latency column b, need explicitly set columns consider adjusting like : step_adjust_latency(, method=\"extend_ahead\").","code":"toy_recipe <- epi_recipe(toy_df) %>%   step_adjust_latency(method=\"extend_ahead\") %>%   step_epi_lag(a,lag=0) %>%   step_epi_ahead(a, ahead=1)  toy_recipe %>%   prep(toy_df) %>%   bake(toy_df) %>%   arrange(geo_value, time_value) #> An `epi_df` object, 10 x 6 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2015-01-14 #> #> # A tibble: 10 x 6 #>    geo_value time_value     a     b lag_0_a ahead_3_a #>  * <chr>     <date>     <dbl> <dbl>   <dbl>     <dbl> #>  1 ca        2015-01-08    NA    NA      NA       100 #>  2 ca        2015-01-09    NA    NA      NA       103 #>  3 ca        2015-01-11   100     5     100        NA #>  4 ca        2015-01-12   103    10     103        NA #>  5 ma        2015-01-08    NA    NA      NA        20 #>  6 ma        2015-01-09    NA    NA      NA        23 #>  7 ma        2015-01-10    NA    NA      NA        25 #>  8 ma        2015-01-11    20     6      20        NA #>  9 ma        2015-01-12    23    NA      23        NA #> 10 ma        2015-01-13    25    NA      25        NA"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_adjust_latency.html","id":"programmatic-details","dir":"Reference","previous_headings":"","what":"Programmatic details","title":"Adapt the model to latent data — step_adjust_latency","text":"step_adjust_latency uses metadata, time_type as_of, epi_df used initial prep step, rather baking prediction. means reusing forecaster new data advised, though typically advised general. latency adjustment applies columns created step, step go step_epi_ahead step_epi_lag. work:   :   create columns apply lags (step_growth_rate()), created step_adjust_latency, subseqent latency can addressed.","code":"toy_recipe <- epi_recipe(toy_df) %>%    # non-lag steps    step_adjust_latency(a, method = \"extend_lags\") %>%    step_epi_lag(a, lag=0) # other steps toy_recipe <- epi_recipe(toy_df) %>%    step_epi_lag(a, lag=0) %>%    step_adjust_latency(a, method = \"extend_lags\") #> Warning: If `method` is \"extend_lags\" or \"locf\", then the previous `step_epi_lag`s won't work with #> modified data."},{"path":[]},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_adjust_latency.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Adapt the model to latent data — step_adjust_latency","text":"","code":"jhu <- case_death_rate_subset %>%   dplyr::filter(time_value > \"2021-11-01\", geo_value %in% c(\"ak\", \"ca\", \"ny\")) # setting the `as_of` to something realistic attributes(jhu)$metadata$as_of <- max(jhu$time_value) + 3  r <- epi_recipe(case_death_rate_subset) %>%   step_adjust_latency(method = \"extend_ahead\") %>%   step_epi_ahead(death_rate, ahead = 7) %>%   step_epi_lag(death_rate, lag = c(0, 7, 14)) r #>  #> ── Epi Recipe ────────────────────────────────────────────────────────────────── #>  #> ── Inputs  #> Number of variables by role #> raw:        2 #> geo_value:  1 #> time_value: 1 #>  #> ── Operations  #> 1. extend_ahead: all future predictors with latency set at train time #> 2. Leading: death_rate by 7 #> 3. Lagging: death_rate by 0, 7, 14  jhu_fit <- epi_workflow() %>%   add_epi_recipe(r) %>%   add_model(linear_reg()) %>%   fit(data = jhu) jhu_fit #>  #> ══ Epi Workflow [trained] ══════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: linear_reg() #> Postprocessor: None #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #>  #> 3 Recipe steps. #> 1. step_adjust_latency() #> 2. step_epi_ahead() #> 3. step_epi_lag() #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #>  #> Call: #> stats::lm(formula = ..y ~ ., data = data) #>  #> Coefficients: #>       (Intercept)   lag_0_death_rate   lag_7_death_rate  lag_14_death_rate   #>           0.38227           -0.22270           -0.04121           -0.04057   #>  #>"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_adjust_latency_checks.html","id":null,"dir":"Reference","previous_headings":"","what":"checks: the recipe type, whether a previous step is the relevant epi_shift, that either fixed_latency or fixed_forecast_date is non-null, and that fixed_latency only references columns that exist at the time of the step inclusion — step_adjust_latency_checks","title":"checks: the recipe type, whether a previous step is the relevant epi_shift, that either fixed_latency or fixed_forecast_date is non-null, and that fixed_latency only references columns that exist at the time of the step inclusion — step_adjust_latency_checks","text":"checks: recipe type, whether previous step relevant epi_shift, either fixed_latency fixed_forecast_date non-null, fixed_latency references columns exist time step inclusion","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_adjust_latency_checks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"checks: the recipe type, whether a previous step is the relevant epi_shift, that either fixed_latency or fixed_forecast_date is non-null, and that fixed_latency only references columns that exist at the time of the step inclusion — step_adjust_latency_checks","text":"","code":"step_adjust_latency_checks(   id,   method,   recipe,   fixed_latency,   fixed_forecast_date,   call = caller_env() )"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_epi_naomit.html","id":null,"dir":"Reference","previous_headings":"","what":"Unified NA omission wrapper function for recipes — step_epi_naomit","title":"Unified NA omission wrapper function for recipes — step_epi_naomit","text":"Unified NA omission wrapper function recipes","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_epi_naomit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unified NA omission wrapper function for recipes — step_epi_naomit","text":"","code":"step_epi_naomit(recipe)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_epi_naomit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unified NA omission wrapper function for recipes — step_epi_naomit","text":"recipe Recipe used omission steps","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_epi_naomit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Unified NA omission wrapper function for recipes — step_epi_naomit","text":"Omits NA's predictors outcomes training time fit model. Also omits associated predictors outcomes prediction time due lack response avoidance data loss.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_epi_naomit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Unified NA omission wrapper function for recipes — step_epi_naomit","text":"","code":"case_death_rate_subset %>%   epi_recipe() %>%   step_epi_naomit() #>  #> ── Epi Recipe ────────────────────────────────────────────────────────────────── #>  #> ── Inputs  #> Number of variables by role #> raw:        2 #> geo_value:  1 #> time_value: 1 #>  #> ── Operations  #> 1. • Removing rows with NA values in: all_predictors() #> 2. • Removing rows with NA values in: all_outcomes()"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_epi_shift.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a shifted predictor — step_epi_lag","title":"Create a shifted predictor — step_epi_lag","text":"step_epi_lag step_epi_ahead create specification recipe step add new columns shifted data. former created lag column, latter create lead column. Shifted data default include NA values shift induced. can properly removed step_epi_naomit(), may specify alternative filler value default argument.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_epi_shift.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a shifted predictor — step_epi_lag","text":"","code":"step_epi_lag(   recipe,   ...,   lag,   role = \"predictor\",   prefix = \"lag_\",   default = NA,   skip = FALSE,   id = rand_id(\"epi_lag\") )  step_epi_ahead(   recipe,   ...,   ahead,   role = \"outcome\",   prefix = \"ahead_\",   default = NA,   skip = FALSE,   id = rand_id(\"epi_ahead\") )"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_epi_shift.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a shifted predictor — step_epi_lag","text":"recipe recipe object. step added sequence operations recipe. ... One selector functions choose variables step. See recipes::selections() details. lag, ahead vector integers. specified column lag lead value vector. Lag integers must nonnegative, ahead integers must positive. role model terms created step, analysis role assigned? lag default predictor ahead outcome. prefix character string prefixed new column. default Determines fills empty rows left leading/lagging (defaults NA). skip logical. step skipped recipe baked bake()? operations baked prep() run, operations may able conducted new data (e.g. processing outcome variable(s)). Care taken using skip = TRUE may affect computations subsequent operations. id unique identifier step","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_epi_shift.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a shifted predictor — step_epi_lag","text":"updated version recipe new step added sequence existing operations.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_epi_shift.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a shifted predictor — step_epi_lag","text":"step assumes data already proper sequential order shifting. prefix id arguments unchangeable ensure code runs properly avoid inconsistency naming. step_epi_ahead, always set \"ahead_\" \"epi_ahead\" respectively, step_epi_lag, set \"lag_\" \"epi_lag, respectively.","code":""},{"path":[]},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_epi_shift.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a shifted predictor — step_epi_lag","text":"","code":"r <- epi_recipe(case_death_rate_subset) %>%   step_epi_ahead(death_rate, ahead = 7) %>%   step_epi_lag(death_rate, lag = c(0, 7, 14)) r #>  #> ── Epi Recipe ────────────────────────────────────────────────────────────────── #>  #> ── Inputs  #> Number of variables by role #> raw:        2 #> geo_value:  1 #> time_value: 1 #>  #> ── Operations  #> 1. Leading: death_rate by 7 #> 2. Lagging: death_rate by 0, 7, 14"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_epi_slide.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate a rolling window transformation — step_epi_slide","title":"Calculate a rolling window transformation — step_epi_slide","text":"step_epi_slide() creates specification recipe step generate one new columns derived data \"sliding\" computation along existing data.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_epi_slide.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate a rolling window transformation — step_epi_slide","text":"","code":"step_epi_slide(   recipe,   ...,   .f,   .window_size = NULL,   .align = c(\"right\", \"center\", \"left\"),   role = \"predictor\",   prefix = \"epi_slide_\",   f_name = clean_f_name(.f),   skip = FALSE,   id = rand_id(\"epi_slide\") )"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_epi_slide.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate a rolling window transformation — step_epi_slide","text":"recipe recipe object. step added sequence operations recipe. ... One selector functions choose variables step. See recipes::selections() details. .f function one following formats: unquoted function name arguments, e.g., mean character string name function, e.g., \"mean\". Note can difficult examine mistakes (misspelling \"maen\" produce error try actually fit model) base R lambda function, e.g., function(x) mean(x, na.rm = TRUE) new-style base R lambda function, e.g., \\(x) mean(x, na.rm = TRUE) one-sided formula like ~ mean(.x, na.rm = TRUE). Note cases 3 4, x can variable name like (example \\(dog) mean(dog, na.rm = TRUE) work). case 5, argument must named .x. common, though difficult debug error using something like function(x) mean. work returns function mean, rather mean(x) .window_size size sliding window, required. Usually non-negative integer suffice (e.g. data indexed date, restrictive time_type cases (see epiprocess::epi_slide() details). example, set 7 7-day window. .align character string indicating window aligned. default, \"right\", meaning slide_window anchored right end point reference date. (see epiprocess::epi_slide() details). role model terms created step, analysis role assigned? lag default predictor ahead outcome. prefix character string prefixed new column. f_name character string 20 characters describes function. combined prefix columns ... name result using {prefix}{f_name}_{column}. default determined automatically using clean_f_name(). skip logical. step skipped recipe baked bake()? operations baked prep() run, operations may able conducted new data (e.g. processing outcome variable(s)). Care taken using skip = TRUE may affect computations subsequent operations. id unique identifier step","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_epi_slide.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate a rolling window transformation — step_epi_slide","text":"updated version recipe new step added sequence existing operations.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_epi_slide.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate a rolling window transformation — step_epi_slide","text":"","code":"library(dplyr) jhu <- case_death_rate_subset %>%   filter(time_value >= as.Date(\"2021-01-01\"), geo_value %in% c(\"ca\", \"ny\")) rec <- epi_recipe(jhu) %>%   step_epi_slide(case_rate, death_rate,     .f = \\(x) mean(x, na.rm = TRUE),     .window_size = 7L   ) bake(prep(rec, jhu), new_data = NULL) #> An `epi_df` object, 730 x 6 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-31 19:08:25.791826 #>  #> # A tibble: 730 × 6 #>    geo_value time_value case_rate death_rate epi_slide__.f_case_rate #>  * <chr>     <date>         <dbl>      <dbl>                   <dbl> #>  1 ca        2021-01-01      104.      0.850                    104. #>  2 ca        2021-01-02      103.      0.857                    103. #>  3 ca        2021-01-03      102.      0.860                    103. #>  4 ca        2021-01-04      102.      0.911                    103. #>  5 ca        2021-01-05      101.      0.908                    102. #>  6 ca        2021-01-06      108.      0.893                    103. #>  7 ca        2021-01-07      106.      0.941                    104. #>  8 ca        2021-01-08      106.      1.02                     104. #>  9 ca        2021-01-09      107.      1.11                     105. #> 10 ca        2021-01-10      110.      1.22                     106. #> # ℹ 720 more rows #> # ℹ 1 more variable: epi_slide__.f_death_rate <dbl>"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_growth_rate.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate a growth rate — step_growth_rate","title":"Calculate a growth rate — step_growth_rate","text":"step_growth_rate() creates specification recipe step generate one new columns derived data.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_growth_rate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate a growth rate — step_growth_rate","text":"","code":"step_growth_rate(   recipe,   ...,   role = \"predictor\",   horizon = 7,   method = c(\"rel_change\", \"linear_reg\"),   log_scale = FALSE,   replace_Inf = NA,   prefix = \"gr_\",   skip = FALSE,   id = rand_id(\"growth_rate\"),   additional_gr_args_list = list() )"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_growth_rate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate a growth rate — step_growth_rate","text":"recipe recipe object. step added sequence operations recipe. ... One selector functions choose variables step. See recipes::selections() details. role model terms created step, analysis role assigned? lag default predictor ahead outcome. horizon Bandwidth sliding window, method \"rel_change\" \"linear_reg\". See epiprocess::growth_rate() details. method Either \"rel_change\" \"linear_reg\", indicating method use growth rate calculation. local methods: run sliding fashion sequence (order estimate derivatives hence growth rates). See epiprocess::growth_rate() details. log_scale growth rates estimated using parameterization log scale? See details explanation. Default FALSE. replace_Inf Sometimes, growth rate calculation can result infinite values (denominator zero, example). case, prediction methods fail. argument specifies potential replacement values. default (NA) likely result rows removed data. Alternatively, specify arbitrary large values, perhaps zero. Setting argument NULL result replacement. prefix character string prefixed new column. skip logical. step skipped recipe baked bake()? operations baked prep() run, operations may able conducted new data (e.g. processing outcome variable(s)). Care taken using skip = TRUE may affect computations subsequent operations. id unique identifier step additional_gr_args_list list additional arguments used epiprocess::growth_rate(). ... arguments may passed along dup_rm na_rm.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_growth_rate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate a growth rate — step_growth_rate","text":"updated version recipe new step added sequence existing operations.","code":""},{"path":[]},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_growth_rate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate a growth rate — step_growth_rate","text":"","code":"r <- epi_recipe(case_death_rate_subset) %>%   step_growth_rate(case_rate, death_rate) r #>  #> ── Epi Recipe ────────────────────────────────────────────────────────────────── #>  #> ── Inputs  #> Number of variables by role #> raw:        2 #> geo_value:  1 #> time_value: 1 #>  #> ── Operations  #> 1. Calculating growth_rate for: case_rate and death_rate by rel_change  r %>%   prep(case_death_rate_subset) %>%   bake(case_death_rate_subset) #> An `epi_df` object, 20,496 x 6 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-31 19:08:25.791826 #>  #> # A tibble: 20,496 × 6 #>    geo_value time_value case_rate death_rate gr_7_rel_change_case_rate #>  * <chr>     <date>         <dbl>      <dbl>                     <dbl> #>  1 ak        2020-12-31      35.9      0.158                        NA #>  2 al        2020-12-31      65.1      0.438                        NA #>  3 ar        2020-12-31      66.0      1.27                         NA #>  4 as        2020-12-31       0        0                            NA #>  5 az        2020-12-31      76.8      1.10                         NA #>  6 ca        2020-12-31      96.0      0.751                        NA #>  7 co        2020-12-31      35.8      0.649                        NA #>  8 ct        2020-12-31      52.1      0.819                        NA #>  9 dc        2020-12-31      31.0      0.601                        NA #> 10 de        2020-12-31      65.2      0.807                        NA #> # ℹ 20,486 more rows #> # ℹ 1 more variable: gr_7_rel_change_death_rate <dbl>"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_lag_difference.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate a lagged difference — step_lag_difference","title":"Calculate a lagged difference — step_lag_difference","text":"step_lag_difference() creates specification recipe step generate one new columns derived data.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_lag_difference.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate a lagged difference — step_lag_difference","text":"","code":"step_lag_difference(   recipe,   ...,   role = \"predictor\",   horizon = 7,   prefix = \"lag_diff_\",   skip = FALSE,   id = rand_id(\"lag_diff\") )"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_lag_difference.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate a lagged difference — step_lag_difference","text":"recipe recipe object. step added sequence operations recipe. ... One selector functions choose variables step. See recipes::selections() details. role model terms created step, analysis role assigned? lag default predictor ahead outcome. horizon Scalar vector. Time period(s) calculate differences. prefix character string prefixed new column. skip logical. step skipped recipe baked bake()? operations baked prep() run, operations may able conducted new data (e.g. processing outcome variable(s)). Care taken using skip = TRUE may affect computations subsequent operations. id unique identifier step","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_lag_difference.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate a lagged difference — step_lag_difference","text":"updated version recipe new step added sequence existing operations.","code":""},{"path":[]},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_lag_difference.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate a lagged difference — step_lag_difference","text":"","code":"r <- epi_recipe(case_death_rate_subset) %>%   step_lag_difference(case_rate, death_rate, horizon = c(7, 14)) %>%   step_epi_naomit() r #>  #> ── Epi Recipe ────────────────────────────────────────────────────────────────── #>  #> ── Inputs  #> Number of variables by role #> raw:        2 #> geo_value:  1 #> time_value: 1 #>  #> ── Operations  #> 1. Calculating lag_difference for: case_rate and death_rate by 7, 14 #> 2. • Removing rows with NA values in: all_predictors() #> 3. • Removing rows with NA values in: all_outcomes()  r %>%   prep(case_death_rate_subset) %>%   bake(case_death_rate_subset) #> An `epi_df` object, 19,712 x 8 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-31 19:08:25.791826 #>  #> # A tibble: 19,712 × 8 #>    geo_value time_value case_rate death_rate lag_diff_7_case_rate #>  * <chr>     <date>         <dbl>      <dbl>                <dbl> #>  1 ak        2021-01-14      37.4     0.0988               -4.07  #>  2 al        2021-01-14      73.6     2.51                 -7.70  #>  3 ar        2021-01-14      87.7     1.42                -10.3   #>  4 as        2021-01-14       0       0                     0     #>  5 az        2021-01-14     124.      2.14                  0.117 #>  6 ca        2021-01-14     108.      1.21                  2.37  #>  7 co        2021-01-14      40.0     0.526                -6.33  #>  8 ct        2021-01-14      75.4     1.07                  6.97  #>  9 dc        2021-01-14      41.5     0.681                 6.07  #> 10 de        2021-01-14      75.1     0.792                -5.53  #> # ℹ 19,702 more rows #> # ℹ 3 more variables: lag_diff_14_case_rate <dbl>, lag_diff_7_death_rate <dbl>, #> #   lag_diff_14_death_rate <dbl>"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_population_scaling.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert raw scale predictions to per-capita — step_population_scaling","title":"Convert raw scale predictions to per-capita — step_population_scaling","text":"step_population_scaling creates specification recipe step perform per-capita scaling. Typical usage load dataset contains state-level population, use convert predictions made raw scale model rate-scale dividing population. Although, worth noting nothing special \"population\". function can used scale variable. Population standard use case epidemiology forecasting scenario. value passed divide selected variables rate_rescaling argument common multiplier selected variables.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_population_scaling.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert raw scale predictions to per-capita — step_population_scaling","text":"","code":"step_population_scaling(   recipe,   ...,   role = \"raw\",   df,   by = NULL,   df_pop_col,   rate_rescaling = 1,   create_new = TRUE,   suffix = \"_scaled\",   skip = FALSE,   id = rand_id(\"population_scaling\") )"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_population_scaling.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert raw scale predictions to per-capita — step_population_scaling","text":"recipe recipe object. step added sequence operations recipe. ... One selector functions choose variables step. See recipes::selections() details. role model terms created step, analysis role assigned? lag default predictor ahead outcome. df data frame contains population data used inverting existing scaling. (possibly named) character vector variables join . NULL, default, function perform natural join, using variables common across epi_df produced predict() call user-provided dataset. columns epi_df df name (included ), .df added one user-provided data disambiguate. join different variables epi_df df, use named vector. example, = c(\"geo_value\" = \"states\") match epi_df$geo_value df$states. join multiple variables, use vector length > 1. example, = c(\"geo_value\" = \"states\", \"county\" = \"county\") match epi_df$geo_value df$states epi_df$county df$county. See dplyr::left_join() details. df_pop_col name column data frame df contains population data used scaling. one column. rate_rescaling Sometimes raw scales \"per 100K\" \"per 1M\". Adjustments can made . example, original scale \"per 100K\", set rate_rescaling = 1e5 get rates. create_new TRUE create new column keep original column epi_df suffix character. suffix added column name create_new = TRUE. Default \"_scaled\". skip logical. step skipped recipe baked bake()? operations baked prep() run, operations may able conducted new data (e.g. processing outcome variable(s)). Care taken using skip = TRUE may affect computations subsequent operations. id unique identifier step","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_population_scaling.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert raw scale predictions to per-capita — step_population_scaling","text":"Scales raw data population","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_population_scaling.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert raw scale predictions to per-capita — step_population_scaling","text":"","code":"library(dplyr) jhu <- jhu_csse_daily_subset %>%   filter(time_value > \"2021-11-01\", geo_value %in% c(\"ca\", \"ny\")) %>%   select(geo_value, time_value, cases)  pop_data <- data.frame(states = c(\"ca\", \"ny\"), value = c(20000, 30000))  r <- epi_recipe(jhu) %>%   step_population_scaling(     df = pop_data,     df_pop_col = \"value\",     by = c(\"geo_value\" = \"states\"),     cases, suffix = \"_scaled\"   ) %>%   step_epi_lag(cases_scaled, lag = c(0, 7, 14)) %>%   step_epi_ahead(cases_scaled, ahead = 7, role = \"outcome\") %>%   step_epi_naomit()  f <- frosting() %>%   layer_predict() %>%   layer_threshold(.pred) %>%   layer_naomit(.pred) %>%   layer_population_scaling(.pred,     df = pop_data,     by = c(\"geo_value\" = \"states\"),     df_pop_col = \"value\"   )  wf <- epi_workflow(r, linear_reg()) %>%   fit(jhu) %>%   add_frosting(f)  forecast(wf) #> An `epi_df` object, 2 x 4 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2024-08-23 02:40:48.296938 #>  #> # A tibble: 2 × 4 #>   geo_value time_value .pred .pred_scaled #> * <chr>     <date>     <dbl>        <dbl> #> 1 ca        2021-12-31  4.25       84938. #> 2 ny        2021-12-31  5.93      177766."},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_training_window.html","id":null,"dir":"Reference","previous_headings":"","what":"Limits the size of the training window to the most recent observations — step_training_window","title":"Limits the size of the training window to the most recent observations — step_training_window","text":"step_training_window creates specification recipe step limits size training window n_recent recent observations time_value per group, groups formed based remaining epi_keys.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_training_window.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Limits the size of the training window to the most recent observations — step_training_window","text":"","code":"step_training_window(   recipe,   role = NA,   n_recent = 50,   epi_keys = NULL,   id = rand_id(\"training_window\") )"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_training_window.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Limits the size of the training window to the most recent observations — step_training_window","text":"recipe recipe object. step added sequence operations recipe. role model terms created step, analysis role assigned? lag default predictor ahead outcome. n_recent integer value represents number recent observations kept training window per key default value 50. epi_keys optional character vector specifying \"key\" variables group . default, NULL, ensures every key combination limited. id unique identifier step","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_training_window.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Limits the size of the training window to the most recent observations — step_training_window","text":"updated version recipe new step added sequence existing operations.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_training_window.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Limits the size of the training window to the most recent observations — step_training_window","text":"Note step_epi_lead() step_epi_lag() come filtering step.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/step_training_window.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Limits the size of the training window to the most recent observations — step_training_window","text":"","code":"tib <- tibble(   x = 1:10,   y = 1:10,   time_value = rep(seq(as.Date(\"2020-01-01\"), by = 1, length.out = 5), 2),   geo_value = rep(c(\"ca\", \"hi\"), each = 5) ) %>%   as_epi_df()  epi_recipe(y ~ x, data = tib) %>%   step_training_window(n_recent = 3) %>%   prep(tib) %>%   bake(new_data = NULL) #> An `epi_df` object, 6 x 4 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2024-10-09 20:15:21.740851 #>  #> # A tibble: 6 × 4 #>   geo_value time_value     x     y #> * <chr>     <date>     <int> <int> #> 1 ca        2020-01-03     3     3 #> 2 ca        2020-01-04     4     4 #> 3 ca        2020-01-05     5     5 #> 4 hi        2020-01-03     8     8 #> 5 hi        2020-01-04     9     9 #> 6 hi        2020-01-05    10    10  epi_recipe(y ~ x, data = tib) %>%   step_epi_naomit() %>%   step_training_window(n_recent = 3) %>%   prep(tib) %>%   bake(new_data = NULL) #> An `epi_df` object, 6 x 4 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2024-10-09 20:15:21.740851 #>  #> # A tibble: 6 × 4 #>   geo_value time_value     x     y #> * <chr>     <date>     <int> <int> #> 1 ca        2020-01-03     3     3 #> 2 ca        2020-01-04     4     4 #> 3 ca        2020-01-05     5     5 #> 4 hi        2020-01-03     8     8 #> 5 hi        2020-01-04     9     9 #> 6 hi        2020-01-05    10    10"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/tidy.frosting.html","id":null,"dir":"Reference","previous_headings":"","what":"Tidy the result of a frosting object — tidy.frosting","title":"Tidy the result of a frosting object — tidy.frosting","text":"tidy return data frame contains information regarding frosting operation within frosting (tidy method operation exists). Note modified version tidy method recipe.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/tidy.frosting.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tidy the result of a frosting object — tidy.frosting","text":"","code":"# S3 method for class 'frosting' tidy(x, number = NA, id = NA, ...)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/tidy.frosting.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tidy the result of a frosting object — tidy.frosting","text":"x frosting layer object number integer NA. missing, id provided, return value list operations frosting. number given, tidy method executed operation frosting (exists). number must provided id . id character string NA. missing number provided, return value list operations frosting. character string given, tidy method executed operation frosting (exists). id must provided number . ... currently used.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/tidy.frosting.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tidy the result of a frosting object — tidy.frosting","text":"tibble columns vary depending tidy method executed. number, id NA, tibble columns number (operation iteration), operation (\"layer\"), type (method, e.g. \"predict\", \"naomit\"), character column id.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/tidy.frosting.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tidy the result of a frosting object — tidy.frosting","text":"","code":"library(dplyr) jhu <- case_death_rate_subset %>%   filter(time_value > \"2021-11-01\", geo_value %in% c(\"ak\", \"ca\", \"ny\"))  r <- epi_recipe(jhu) %>%   step_epi_lag(death_rate, lag = c(0, 7, 14)) %>%   step_epi_ahead(death_rate, ahead = 7) %>%   step_epi_naomit()  wf <- epi_workflow(r, parsnip::linear_reg()) %>% fit(jhu) latest <- get_test_data(recipe = r, x = jhu) f <- frosting() %>%   layer_predict() %>%   layer_naomit(.pred)  tidy(f) #> # A tibble: 2 × 4 #>   number operation type    id                    #>    <int> <chr>     <chr>   <chr>                 #> 1      1 layer     predict predict_default_Yd5NX #> 2      2 layer     naomit  naomit_qfEOY"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/update.layer.html","id":null,"dir":"Reference","previous_headings":"","what":"Update post-processing layer — update.layer","title":"Update post-processing layer — update.layer","text":"layer method update() takes named arguments ... whose values replace elements name actual post-processing layer. Analogous update.step() recipes package.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/update.layer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update post-processing layer — update.layer","text":"","code":"# S3 method for class 'layer' update(object, ...)"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/update.layer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update post-processing layer — update.layer","text":"object post-processing layer. ... Key-value pairs keys match names elements layer, values new values update layer .","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/update.layer.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Update post-processing layer — update.layer","text":"","code":"library(dplyr) jhu <- case_death_rate_subset %>%   filter(time_value > \"2021-11-01\", geo_value %in% c(\"ak\", \"ca\", \"ny\")) r <- epi_recipe(jhu) %>%   step_epi_lag(death_rate, lag = c(0, 7, 14)) %>%   step_epi_ahead(death_rate, ahead = 7) %>%   step_epi_naomit() wf <- epi_workflow(r, linear_reg()) %>% fit(jhu) latest <- jhu %>% filter(time_value >= max(time_value) - 14)  # Specify a `forecast_date` that is greater than or equal to `as_of` date f <- frosting() %>%   layer_predict() %>%   layer_add_forecast_date(forecast_date = \"2022-05-31\") %>%   layer_naomit(.pred)  wf1 <- wf %>% add_frosting(f)  p1 <- predict(wf1, latest) p1 #> An `epi_df` object, 3 x 4 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-31 19:08:25.791826 #>  #> # A tibble: 3 × 4 #>   geo_value time_value .pred forecast_date #> * <chr>     <date>     <dbl> <date>        #> 1 ak        2021-12-31 0.245 2022-05-31    #> 2 ca        2021-12-31 0.313 2022-05-31    #> 3 ny        2021-12-31 0.295 2022-05-31     # Update forecast date f$layers[[2]] <- update(f$layers[[2]], forecast_date = \"2021-06-01\")  # Need to still update workflow if only update a layer in frosting wf2 <- wf %>% add_frosting(f) wf2$post # Check that wf1 has update #> $actions #> $actions$frosting #> $frosting #>  #> ── Frosting ──────────────────────────────────────────────────────────────────── #>  #> ── Layers  #> 1. Creating predictions: \"<calculated>\" #> 2. Adding forecast date: \"2021-06-01\" #> 3. Removing na predictions from: .pred #>  #> attr(,\"class\") #> [1] \"action_post\" \"action\"      #>  #>  #> attr(,\"class\") #> [1] \"stage_post\" \"stage\"      p1 <- predict(wf2, latest) p1 #> An `epi_df` object, 3 x 4 with metadata: #> * geo_type  = state #> * time_type = day #> * as_of     = 2022-05-31 19:08:25.791826 #>  #> # A tibble: 3 × 4 #>   geo_value time_value .pred forecast_date #> * <chr>     <date>     <dbl> <date>        #> 1 ak        2021-12-31 0.245 2021-06-01    #> 2 ca        2021-12-31 0.313 2021-06-01    #> 3 ny        2021-12-31 0.295 2021-06-01"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/weighted_interval_score.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute weighted interval score — weighted_interval_score","title":"Compute weighted interval score — weighted_interval_score","text":"Weighted interval score (WIS), well-known quantile-based approximation commonly-used continuous ranked probability score (CRPS). WIS proper score, can thought distributional generalization absolute error. example, see Bracher et al. (2020) discussion context COVID-19 forecasting.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/weighted_interval_score.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute weighted interval score — weighted_interval_score","text":"","code":"weighted_interval_score(x, actual, quantile_levels = NULL, ...)  # S3 method for class 'dist_quantiles' weighted_interval_score(   x,   actual,   quantile_levels = NULL,   na_handling = c(\"impute\", \"drop\", \"propagate\", \"fail\"),   ... )"},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/weighted_interval_score.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute weighted interval score — weighted_interval_score","text":"x distribution. vector class distribution. Ideally, vector contains dist_quantiles(), though distributions supported quantile_levels specified. See . actual double. Actual value(s) quantile_levels probabilities. specified, score computed set levels. ... used na_handling character. Determines quantile_levels without corresponding value handled. \"impute\", missing values calculated possible using available quantiles. \"drop\", explicitly missing values ignored calculation score, implicitly missing values imputed possible. \"propogate\", resulting score NA missing values exist original quantile_levels. Finally, quantile_levels specified, \"fail\" result score NA required quantile levels (implicit explicit) corresponding values.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/weighted_interval_score.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute weighted interval score — weighted_interval_score","text":"vector nonnegative scores.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/weighted_interval_score.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"Compute weighted interval score — weighted_interval_score","text":"weighted_interval_score(dist_quantiles): Weighted interval score dist_quantiles allows different NA behaviours.","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/reference/weighted_interval_score.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute weighted interval score — weighted_interval_score","text":"","code":"quantile_levels <- c(.2, .4, .6, .8) predq_1 <- 1:4 # predq_2 <- 8:11 dstn <- dist_quantiles(list(predq_1, predq_2), quantile_levels) actual <- c(3.3, 7.1) weighted_interval_score(dstn, actual) #> [1] 0.65 1.90 weighted_interval_score(dstn, actual, c(.25, .5, .75)) #> [1] 0.6833333 1.9833333  library(distributional) dstn <- dist_normal(c(.75, 2)) weighted_interval_score(dstn, 1, c(.25, .5, .75)) #> [1] 0.3081633 0.7751701  # Missing value behaviours dstn <- dist_quantiles(c(1, 2, NA, 4), 1:4 / 5) weighted_interval_score(dstn, 2.5) #> [1] 0.5 weighted_interval_score(dstn, 2.5, 1:9 / 10) #> [1] 0.455656 weighted_interval_score(dstn, 2.5, 1:9 / 10, na_handling = \"drop\") #> [1] 0.462613 weighted_interval_score(dstn, 2.5, na_handling = \"propagate\") #> [1] NA weighted_interval_score(dist_quantiles(1:4, 1:4 / 5), 2.5, 1:9 / 10,   na_handling = \"fail\" ) #> [1] NA   # Using some actual forecasts -------- library(dplyr) jhu <- case_death_rate_subset %>%   filter(time_value >= \"2021-10-01\", time_value <= \"2021-12-01\") preds <- flatline_forecaster(   jhu, \"death_rate\",   flatline_args_list(quantile_levels = c(.01, .025, 1:19 / 20, .975, .99)) )$predictions actuals <- case_death_rate_subset %>%   filter(time_value == as.Date(\"2021-12-01\") + 7) %>%   select(geo_value, time_value, actual = death_rate) preds <- left_join(preds, actuals,   by = c(\"target_date\" = \"time_value\", \"geo_value\") ) %>%   mutate(wis = weighted_interval_score(.pred_distn, actual)) preds #> # A tibble: 56 × 7 #>    geo_value .pred         .pred_distn forecast_date target_date actual    wis #>    <chr>     <dbl>              <dist> <date>        <date>       <dbl>  <dbl> #>  1 ak        0.217 quantiles(0.22)[23] 2021-12-01    2021-12-08  0.0988 0.0673 #>  2 al        0.119 quantiles(0.12)[23] 2021-12-01    2021-12-08  0.174  0.0364 #>  3 ar        0.207 quantiles(0.21)[23] 2021-12-01    2021-12-08  0.514  0.196  #>  4 as        0        quantiles(0)[23] 2021-12-01    2021-12-08  0      0.0146 #>  5 az        0.485 quantiles(0.49)[23] 2021-12-01    2021-12-08  0.826  0.223  #>  6 ca        0.173 quantiles(0.17)[23] 2021-12-01    2021-12-08  0.183  0.0272 #>  7 co        0.521 quantiles(0.52)[23] 2021-12-01    2021-12-08  0.539  0.0302 #>  8 ct        0.177 quantiles(0.18)[23] 2021-12-01    2021-12-08  0.149  0.0302 #>  9 dc        0        quantiles(0)[23] 2021-12-01    2021-12-08  0.0200 0.0166 #> 10 de        0.217 quantiles(0.22)[23] 2021-12-01    2021-12-08  0.391  0.101  #> # ℹ 46 more rows"},{"path":[]},{"path":"https://cmu-delphi.github.io/epipredict/dev/news/index.html","id":"features-0-2","dir":"Changelog","previous_headings":"","what":"features","title":"epipredict 0.2","text":"Add step_adjust_latency, give several methods adjust forecast forecast_date last day data. (temporary) ahead negative allowed step_epi_ahead step_epi_shift","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/news/index.html","id":"bugfixes-0-2","dir":"Changelog","previous_headings":"","what":"bugfixes","title":"epipredict 0.2","text":"shifting columns results error either step_epi_ahead step_epi_lag","code":""},{"path":"https://cmu-delphi.github.io/epipredict/dev/news/index.html","id":"epipredict-01","dir":"Changelog","previous_headings":"","what":"epipredict 0.1","title":"epipredict 0.1","text":"simplify layer_residual_quantiles() avoid timesuck utils::methods() rename dist_quantiles() descriptive, breaking change removes previous pivot_quantiles() (now *_wider(), breaking change) add pivot_quantiles_wider() easier plotting add complement pivot_quantiles_longer() add cdc_baseline_forecaster() flusight_hub_formatter() add smooth_quantile_reg() improved printing various methods / internals canned forecasters get class fixed quantile bug flatline_forecaster() add functionality output unfit workflow canned forecasters add quantile_reg() clean documentation bugs add smooth_quantile_reg() add classifier training window step debugged min_train_window argument removed canned forecasters add forecasters implement postprocessing vignettes avaliable arx_forecaster pkgdown Publish public easy navigation Two simple forecasters test beds Working vignette use checkmate input validation refactor quantile extrapolation (possibly creates different results) force target_date + forecast_date handling match time_type epi_df. allows annual weekly data add check_enough_train_data() error training data small added check_enough_train_data() arx_forecaster() layer_residual_quantiles() now error residual quantiles NA *_args_list() functions now warn forecast_date + ahead != target_date predictor argument arx_forecaster() now defaults value outcome argument arx_fcast_epi_workflow() arx_class_epi_workflow() now default trainer = parsnip::logistic_reg() match canned versions. add forecast() method simplify generating forecasts refactor bake.epi_recipe() remove epi_juice(). Revise compat-purrr use r-lang standalone-* version (via usethis) Replaced old version-faithful example sliding AR & ARX forecasters vignette epi_recipe() now warn given non-epi_df data layer_predict() predict.epi_workflow() now appropriately forward ... args intended predict.model_fit() bake.epi_recipe() now re-infer geo time type case baking steps changed appropriate values produce length 0 dist_quantiles() add functionality calculate weighted interval scores dist_quantiles() Add step_epi_slide produce generic sliding computations epi_df Add quantile random forests (via grf) parsnip engine Replace epi_keys() epiprocess::key_colnames(), #352 descriptive error messages arg_is_*(), #287 Fix bug fit() drops epi_workflow class (also error non-epi_df data given epi_recipe()), #363 Try retain epi_df class baking extent possible, #376","code":""}]
